dat/sim: batch_size = 2**6. num_epochs = 100. lr = 1e-2. (0.66; decent)
dat2: batch_size 2**7. num_epochs = 200. lr = 1e-3, (0.55; really good)
sim2: batch_size 2**7. num_epochs = 100. lr = 1e-4. (sucked)
dat3: batch_size 2**7. num_epochs = 400. lr = 1e-3. (0.54; really good)
dat4: batch_size 2**7. num_epochs = 200. lr = 1e-4. (0.74; sucked)
dat5: batch_size 2**7. num_epochs = 200. lr = 1e-2. (okay ? still waiting)
dat6: batch_size 2**7. num_epochs = 600. lr = 1e-3 (0.57; best)
sim3: batch_size 2**7. num_epochs = 600. lr = 1e-3 (0.55; best)
dat7: batch_size 2**7. num_epochs = 1000. lr = 1e-3 (0.5359; not as good as previous)
dat4: batch_size 2**7. num_epochs = 1000. lr = 1e-3 (not as good as previous)
dat8: batch_size 2**6. num_epochs = 1000. lr = 1e-3. num_hidden = 16. (0.5434; not as good as previous?)
dat9: batch_size 2**7. num_epochs = 1000. lr = 1e-3. num_ffjords = 8. (0.5409)
dat10: batch_size 2**7. num_epochs = 2000. lr = 1e-3. (0.5234)
dat11: batch_size 2**7. num_epochs = 4000. lr = 1e-3. (0.5561; didn't finish training)
dat12: batch_size 2**8. num_epochs = 4000. lr = 1e-3. (0.567; didn't finish training)
sim5: batch_size: 2**10. num_epochs = 2000. lr = 1e-3. (0.531)
sim6: batch_size: 2**7. num_epochs = 2000. lr = 1e-3. (0.5835)
sim7: batch_size: 2**10. num_epochs = 4000. lr = 1e-3. (0.5433 / 100 hours)