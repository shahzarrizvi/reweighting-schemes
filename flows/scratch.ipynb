{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from flows import *\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density(data):\n",
    "    x, y = np.squeeze(np.split(data, 2, axis=1))\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = stats.gaussian_kde(values)\n",
    "\n",
    "    xmin, xmax = min(x), max(x)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "\n",
    "    # Peform the kernel density estimate\n",
    "    xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    f = np.reshape(kernel(positions).T, xx.shape)\n",
    "    \n",
    "    # Plot the kernel density estimate\n",
    "    plt.contourf(xx, yy, f, cmap='viridis')\n",
    "    plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000000\n",
    "data = np.sin(stats.multivariate_normal.rvs([0, 0], [1, 1], size = N))\n",
    "plot_density(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = flow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = target.sample(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities\n",
    "target.prob(target_data).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import sklearn.datasets as skd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kde\n",
    "\n",
    "# tf and friends\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "import sonnet as snt\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "\n",
    "def make_grid(xmin, xmax, ymin, ymax, gridlines, pts):\n",
    "    xpts = np.linspace(xmin, xmax, pts)\n",
    "    ypts = np.linspace(ymin, ymax, pts)\n",
    "    xgrid = np.linspace(xmin, xmax, gridlines)\n",
    "    ygrid = np.linspace(ymin, ymax, gridlines)\n",
    "    xlines = np.stack([a.ravel() for a in np.meshgrid(xpts, ygrid)])\n",
    "    ylines = np.stack([a.ravel() for a in np.meshgrid(xgrid, ypts)])\n",
    "    return np.concatenate([xlines, ylines], 1).T\n",
    "\n",
    "grid = make_grid(-3, 3, -3, 3, 4, 100)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 20:26:05.671257: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-08 20:26:06.283221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22824 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:81:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "base_distribution = tfd.MultivariateNormalDiag([0, 0], [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_ODE(snt.Module):\n",
    "    \"\"\"Multi-layer NN ode_fn.\"\"\"\n",
    "    def __init__(self, num_hidden, num_layers, num_output, name='mlp_ode'):\n",
    "        super(MLP_ODE, self).__init__(name=name)\n",
    "        self._num_hidden = num_hidden\n",
    "        self._num_output = num_output\n",
    "        self._num_layers = num_layers\n",
    "        self._modules = []\n",
    "        for _ in range(self._num_layers - 1):\n",
    "            self._modules.append(snt.Linear(self._num_hidden))\n",
    "            self._modules.append(tf.math.tanh)\n",
    "        self._modules.append(snt.Linear(self._num_output))\n",
    "        self._model = snt.Sequential(self._modules)\n",
    "\n",
    "    def __call__(self, t, inputs):\n",
    "        inputs = tf.concat([tf.broadcast_to(t, inputs.shape), inputs], -1)\n",
    "        return self._model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-2 \n",
    "NUM_EPOCHS = 80 \n",
    "STACKED_FFJORDS = 4 \n",
    "NUM_HIDDEN = 8 \n",
    "NUM_LAYERS = 3 \n",
    "NUM_OUTPUT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = tfp.math.ode.DormandPrince(atol=1e-5)\n",
    "ode_solve_fn = solver.solve\n",
    "trace_augmentation_fn = tfb.ffjord.trace_jacobian_exact\n",
    "\n",
    "bijectors = []\n",
    "for _ in range(STACKED_FFJORDS):\n",
    "    mlp_model = MLP_ODE(NUM_HIDDEN, NUM_LAYERS, NUM_OUTPUT)\n",
    "    next_ffjord = tfb.FFJORD(\n",
    "        state_time_derivative_fn=mlp_model,ode_solve_fn=ode_solve_fn,\n",
    "        trace_augmentation_fn=trace_augmentation_fn)\n",
    "    bijectors.append(next_ffjord)\n",
    "\n",
    "stacked_ffjord = tfb.Chain(bijectors[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_distribution = tfd.TransformedDistribution(\n",
    "    distribution=base_distribution, bijector=stacked_ffjord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(optimizer, target_sample):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = -tf.reduce_mean(transformed_distribution.log_prob(target_sample))\n",
    "    variables = tape.watched_variables()\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply(gradients, variables)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = np.load(\"../data/zenodo/Pythia21_Zjet_pTZ-200GeV_0.npz\")\n",
    "\n",
    "sim_pt =  mc['sim_jets'][:, 0]\n",
    "sim_eta = mc['sim_jets'][:, 1]\n",
    "sim_phi = mc['sim_jets'][:, 2]\n",
    "sim_m =   mc['sim_jets'][:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([sim_pt, sim_eta]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data.shape[0]\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(data.astype(np.float32)) \\\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE) \\\n",
    "            .cache() \\\n",
    "            .shuffle(N) \\\n",
    "            .batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow_probability/python/math/ode/base.py:459: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [1:26:02<3:46:54, 486.24s/it]"
     ]
    }
   ],
   "source": [
    "learning_rate = tf.Variable(LR, trainable=False)\n",
    "optimizer = snt.optimizers.Adam(learning_rate)\n",
    "\n",
    "for epoch in tqdm.trange(NUM_EPOCHS // 2):\n",
    "    for batch in dataset:\n",
    "        _ = train_step(optimizer, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data.shape[0]\n",
    "sample = transformed_distribution.sample(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:, 0], data[:, 1], alpha = 0.05)\n",
    "plt.scatter(sample[:, 0], sample[:, 1], alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FFJORD Demo",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "multifold",
   "language": "python",
   "name": "multifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
