{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c913b40d-0cab-4126-a697-7f9dcb77da76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "32e4adb9-f5a3-47a7-b013-6da24e29d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "\n",
    "# Utility imports\n",
    "from utils.losses import *\n",
    "from utils.plotting import *\n",
    "from utils.training import *\n",
    "\n",
    "from flows.flows import *\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8816cc5e-528f-416d-adf1-8e98f8c0dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306c891-2979-4d9b-ac19-20ad3a6d36be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# BCE $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf47a8f-61ec-4c44-a96d-41cda631935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':bce, 'd':4}\n",
    "params_2 = {'loss':tanh_bce, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_bce, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_bce/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'sigmoid/'):\n",
    "    os.mkdir(filestr + 'sigmoid/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'tanh/'):\n",
    "    os.mkdir(filestr + 'tanh/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'arctan/'):\n",
    "    os.mkdir(filestr + 'arctan/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd23de1-cfa5-4896-b9d5-47073ec28015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6135596632957458 \t 100\t0.6134998798370361 \t 100\t0.6154569387435913 \t 100\t\n",
      "1 0.6137897372245789 \t 100\t0.6143745183944702 \t 100\t0.6147382855415344 \t 100\t\n",
      "2 0.61311274766922 \t 100\t0.6142220497131348 \t 100\t0.6143563985824585 \t 100\t\n",
      "3 0.6133688688278198 \t 100\t0.6138599514961243 \t 100\t0.6138262152671814 \t 100\t\n",
      "4 0.6136549115180969 \t 100\t0.6146882772445679 \t 100\t0.6145879030227661 \t 100\t\n",
      "5 0.6132753491401672 \t 100\t0.6136282682418823 \t 100\t0.6145490407943726 \t 100\t\n",
      "6 0.6134077310562134 \t 100\t0.6135149598121643 \t 100\t0.6147461533546448 \t 100\t\n",
      "7 0.6136646270751953 \t 100\t0.6133566498756409 \t 100\t0.6152427792549133 \t 100\t\n",
      "8 0.6129323840141296 \t 100\t0.6136286854743958 \t 100\t0.6147916316986084 \t 100\t\n",
      "9 0.6133783459663391 \t 100\t0.6133272051811218 \t 100\t0.6145686507225037 \t 100\t\n",
      "10 0.613294243812561 \t 100\t0.613235354423523 \t 100\t0.6143259406089783 \t 100\t\n",
      "11 0.6141030192375183 \t 100\t0.6129085421562195 \t 100\t0.6145983934402466 \t 100\t\n",
      "12 0.6141424179077148 \t 100\t0.6135497093200684 \t 100\t0.6146641373634338 \t 100\t\n",
      "13 0.6134760975837708 \t 100\t0.6136017441749573 \t 100\t0.6139547228813171 \t 100\t\n",
      "14 0.6133173108100891 \t 100\t0.6131189465522766 \t 100\t0.6143484115600586 \t 100\t\n",
      "15 0.6133042573928833 \t 100\t0.6130051016807556 \t 100\t0.6141365170478821 \t 100\t\n",
      "16 0.6138789653778076 \t 100\t0.6138151288032532 \t 100\t0.6144826412200928 \t 100\t\n",
      "17 0.613204836845398 \t 100\t0.614680826663971 \t 100\t0.6148260235786438 \t 100\t\n",
      "18 0.6132155656814575 \t 100\t0.6141679286956787 \t 100\t0.6146990060806274 \t 100\t\n",
      "19 0.6134617924690247 \t 100\t0.6133307218551636 \t 100\t0.6152489185333252 \t 100\t\n",
      "20 0.6130590438842773 \t 100\t0.6134930849075317 \t 100\t0.613827645778656 \t 100\t\n",
      "21 0.6134496331214905 \t 100\t0.6139464378356934 \t 100\t0.6145387887954712 \t 100\t\n",
      "22 0.6140878200531006 \t 100\t0.6136921048164368 \t 100\t0.6156161427497864 \t 100\t\n",
      "23 0.6133043169975281 \t 100\t0.6132189035415649 \t 100\t0.6150375008583069 \t 100\t\n",
      "24 0.6138498187065125 \t 100\t0.6141338348388672 \t 100\t0.6153644323348999 \t 94\t\n",
      "25 0.6135022640228271 \t 100\t0.6145998239517212 \t 100\t0.6145816445350647 \t 100\t\n",
      "26 0.6135648488998413 \t 100\t0.6135908961296082 \t 100\t0.6139996647834778 \t 100\t\n",
      "27 0.6135373711585999 \t 100\t0.6147952675819397 \t 100\t0.6149396300315857 \t 100\t\n",
      "28 0.6131230592727661 \t 100\t0.613365113735199 \t 100\t0.6141386032104492 \t 100\t\n",
      "29 0.6132897734642029 \t 100\t0.6141032576560974 \t 100\t0.6148526072502136 \t 100\t\n",
      "30 0.6135580539703369 \t 100\t0.6142926812171936 \t 100\t0.6151362061500549 \t 100\t\n",
      "31 0.6134135127067566 \t 100\t0.6131095290184021 \t 100\t0.6146957874298096 \t 100\t\n",
      "32 0.6139749884605408 \t 100\t0.614517867565155 \t 100\t0.6146084666252136 \t 100\t\n",
      "33 0.6133759021759033 \t 100\t0.6143632531166077 \t 100\t0.6149774789810181 \t 100\t\n",
      "34 0.6138041615486145 \t 100\t0.6142025589942932 \t 100\t0.6144176125526428 \t 100\t\n",
      "35 0.6133185029029846 \t 100\t0.6145342588424683 \t 96\t0.6150892376899719 \t 100\t\n",
      "36 0.613652765750885 \t 100\t0.6137654781341553 \t 100\t0.6143040657043457 \t 100\t\n",
      "37 0.6136271953582764 \t 100\t0.614690363407135 \t 100\t0.6144115328788757 \t 100\t\n",
      "38 0.6139029860496521 \t 100\t0.6145696043968201 \t 100\t0.6142202615737915 \t 100\t\n",
      "39 0.6138108968734741 \t 100\t0.6138474941253662 \t 100\t0.6145041584968567 \t 100\t\n",
      "40 0.6132622361183167 \t 100\t0.6134926676750183 \t 100\t0.6148571968078613 \t 100\t\n",
      "41 0.6133847236633301 \t 100\t0.6137200593948364 \t 100\t0.6140748262405396 \t 100\t\n",
      "42 0.6136606335639954 \t 100\t0.6150835156440735 \t 100\t0.6142654418945312 \t 100\t\n",
      "43 0.6129407286643982 \t 100\t0.6130200028419495 \t 100\t0.6148378849029541 \t 100\t\n",
      "44 0.6135455965995789 \t 100\t0.6143047213554382 \t 100\t0.6140620708465576 \t 100\t\n",
      "45 0.6136341094970703 \t 100\t0.6134905815124512 \t 100\t0.6148441433906555 \t 100\t\n",
      "46 0.6134111285209656 \t 100\t0.613662600517273 \t 100\t0.6152823567390442 \t 100\t\n",
      "47 0.6131883263587952 \t 100\t0.613203763961792 \t 100\t0.6141363978385925 \t 100\t\n",
      "48 0.6138380765914917 \t 100\t0.6138805150985718 \t 100\t0.6144480109214783 \t 100\t\n",
      "49 0.6136001348495483 \t 100\t0.6135542392730713 \t 100\t0.6140839457511902 \t 100\t\n",
      "50 0.6129182577133179 \t 100\t0.6144586801528931 \t 100\t0.6145988702774048 \t 100\t\n",
      "51 0.6132290959358215 \t 100\t0.6135022640228271 \t 100\t0.6142393350601196 \t 100\t\n",
      "52 0.6137176156044006 \t 100\t0.6127448678016663 \t 100\t0.61463463306427 \t 100\t\n",
      "53 0.6127722859382629 \t 100\t0.6144264936447144 \t 100\t0.6148433089256287 \t 100\t\n",
      "54 0.6140517592430115 \t 100\t0.6133596301078796 \t 100\t0.6146223545074463 \t 100\t\n",
      "55 0.6129864454269409 \t 100\t0.6134763360023499 \t 100\t0.6145538091659546 \t 100\t\n",
      "56 0.613760232925415 \t 100\t0.6144726276397705 \t 100\t0.6143630743026733 \t 100\t\n",
      "57 0.6138564348220825 \t 100\t0.6136998534202576 \t 95\t0.6142644882202148 \t 100\t\n",
      "58 0.6138242483139038 \t 100\t0.6140709519386292 \t 100\t0.6142905354499817 \t 100\t\n",
      "59 0.6134752035140991 \t 100\t0.6131251454353333 \t 100\t0.6149568557739258 \t 100\t\n",
      "60 0.6140978336334229 \t 100\t0.6138245463371277 \t 100\t0.6145416498184204 \t 100\t\n",
      "61 0.6136250495910645 \t 100\t0.6142335534095764 \t 100\t0.614163339138031 \t 98\t\n",
      "62 0.6136387586593628 \t 100\t0.6128262281417847 \t 100\t0.6143987774848938 \t 100\t\n",
      "63 0.6136907935142517 \t 100\t0.6134114861488342 \t 100\t0.6143655180931091 \t 100\t\n",
      "64 0.6136096119880676 \t 100\t0.6148809194564819 \t 100\t0.6143144965171814 \t 100\t\n",
      "65 0.6131621599197388 \t 100\t0.6142182350158691 \t 92\t0.614460289478302 \t 100\t\n",
      "66 0.6133328080177307 \t 100\t0.6138502359390259 \t 100\t0.6142855882644653 \t 100\t\n",
      "67 0.6142261624336243 \t 100\t0.6140055060386658 \t 100\t0.6144976019859314 \t 100\t\n",
      "68 0.6134737730026245 \t 100\t0.6141698360443115 \t 100\t0.6156433820724487 \t 100\t\n",
      "69 0.6136336326599121 \t 100\t0.6135580539703369 \t 100\t0.6146031618118286 \t 100\t\n",
      "70 0.6133168339729309 \t 100\t0.6135420203208923 \t 100\t0.6146502494812012 \t 100\t\n",
      "71 0.613621711730957 \t 100\t0.613746166229248 \t 100\t0.6148788928985596 \t 100\t\n",
      "72 0.6132050156593323 \t 100\t0.6137040257453918 \t 100\t0.6142992973327637 \t 100\t\n",
      "73 0.6134650707244873 \t 100\t0.6136361956596375 \t 100\t0.6149600148200989 \t 100\t\n",
      "74 0.6136125922203064 \t 100\t0.6137650012969971 \t 100\t0.6148028373718262 \t 100\t\n",
      "75 0.6131396293640137 \t 100\t0.613223135471344 \t 100\t0.6144725680351257 \t 100\t\n",
      "76 0.6128891706466675 \t 100\t0.6146013140678406 \t 100\t0.6146835088729858 \t 100\t\n",
      "77 0.6139329671859741 \t 100\t0.6136797666549683 \t 100\t0.6156324148178101 \t 100\t\n",
      "78 0.6132907867431641 \t 100\t0.6138800382614136 \t 100\t0.61476069688797 \t 100\t\n",
      "79 0.6129823327064514 \t 100\t0.6140434145927429 \t 100\t0.6139562726020813 \t 100\t\n",
      "80 0.613529622554779 \t 100\t0.6129105091094971 \t 100\t0.614067792892456 \t 100\t\n",
      "81 0.6132305264472961 \t 100\t0.6150600910186768 \t 100\t0.6145392656326294 \t 100\t\n",
      "82 0.6137762665748596 \t 100\t0.6134371757507324 \t 100\t0.6142892241477966 \t 100\t\n",
      "83 0.6145232915878296 \t 86\t0.6138216257095337 \t 100\t0.6150082349777222 \t 100\t\n",
      "84 0.6134846806526184 \t 100\t0.6139073371887207 \t 100\t0.614945113658905 \t 100\t\n",
      "85 0.6132046580314636 \t 100\t0.6141810417175293 \t 100\t0.6142043471336365 \t 100\t\n",
      "86 0.613116443157196 \t 100\t0.613791823387146 \t 94\t0.6144853830337524 \t 100\t\n",
      "87 0.6135438084602356 \t 100\t0.6134793758392334 \t 100\t0.6149158477783203 \t 100\t\n",
      "88 0.6141898036003113 \t 100\t0.6138957738876343 \t 100\t0.6144394278526306 \t 100\t\n",
      "89 0.6134966611862183 \t 100\t0.6137421131134033 \t 100\t0.6145760416984558 \t 100\t\n",
      "90 0.6132527589797974 \t 100\t0.6140392422676086 \t 100\t0.614300012588501 \t 100\t\n",
      "91 0.6134520173072815 \t 100\t0.614342451095581 \t 100\t0.6147301197052002 \t 100\t\n",
      "92 0.6135972142219543 \t 100\t0.6140326857566833 \t 98\t0.614980161190033 \t 100\t\n",
      "93 0.6133722066879272 \t 100\t0.6140300631523132 \t 100\t0.6147051453590393 \t 100\t\n",
      "94 0.6128463745117188 \t 100\t0.614515483379364 \t 100\t0.6142750978469849 \t 100\t\n",
      "95 0.613084077835083 \t 100\t0.6140502691268921 \t 100\t0.6143644452095032 \t 100\t\n",
      "96 0.6138299107551575 \t 100\t0.6127918362617493 \t 100\t0.6148244738578796 \t 100\t\n",
      "97 0.613838791847229 \t 100\t0.6131048202514648 \t 100\t0.6146070957183838 \t 100\t\n",
      "98 0.6134244799613953 \t 100\t0.6133613586425781 \t 100\t0.6146121025085449 \t 100\t\n",
      "99 0.6141596436500549 \t 100\t0.6144605278968811 \t 100\t0.6141395568847656 \t 100\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9638f4ac-8128-458b-a8b5-bdaf2b0ab509",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MSE $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b2afea-448e-4859-9769-d45efeb72fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mse, 'd':4}\n",
    "params_2 = {'loss':tanh_mse, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_mse, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mse/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'sigmoid/'):\n",
    "    os.mkdir(filestr + 'sigmoid/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'tanh/'):\n",
    "    os.mkdir(filestr + 'tanh/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'arctan/'):\n",
    "    os.mkdir(filestr + 'arctan/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d82ce72c-c192-46a2-bf81-fe9387d4c720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2139073759317398 \t 100\t0.2141829878091812 \t 100\t0.21404290199279785 \t 100\t\n",
      "1 0.2136995494365692 \t 100\t0.21399156749248505 \t 100\t0.21402409672737122 \t 100\t\n",
      "2 0.21394039690494537 \t 100\t0.21383507549762726 \t 100\t0.2140907496213913 \t 100\t\n",
      "3 0.2142161875963211 \t 100\t0.21392668783664703 \t 100\t0.21421325206756592 \t 100\t\n",
      "4 0.2141457200050354 \t 100\t0.21414437890052795 \t 100\t0.2139241099357605 \t 100\t\n",
      "5 0.21392115950584412 \t 100\t0.2141987383365631 \t 100\t0.2143034040927887 \t 100\t\n",
      "6 0.2138678878545761 \t 100\t0.21439948678016663 \t 100\t0.21439228951931 \t 100\t\n",
      "7 0.2141367495059967 \t 100\t0.21423940360546112 \t 100\t0.21419934928417206 \t 100\t\n",
      "8 0.2140088677406311 \t 96\t0.21401050686836243 \t 100\t0.21393239498138428 \t 100\t\n",
      "9 0.21376068890094757 \t 100\t0.21389102935791016 \t 100\t0.214279904961586 \t 100\t\n",
      "10 0.21413186192512512 \t 100\t0.2140643149614334 \t 100\t0.21414272487163544 \t 100\t\n",
      "11 0.2138526290655136 \t 100\t0.214345782995224 \t 100\t0.21403804421424866 \t 100\t\n",
      "12 0.21397727727890015 \t 100\t0.21405190229415894 \t 100\t0.21413587033748627 \t 100\t\n",
      "13 0.2139032930135727 \t 100\t0.21465368568897247 \t 100\t0.213890939950943 \t 100\t\n",
      "14 0.21393047273159027 \t 100\t0.2139601707458496 \t 100\t0.21416591107845306 \t 100\t\n",
      "15 0.21422384679317474 \t 100\t0.21412865817546844 \t 92\t0.2140001654624939 \t 100\t\n",
      "16 0.21396106481552124 \t 100\t0.21403439342975616 \t 100\t0.21404053270816803 \t 100\t\n",
      "17 0.21395659446716309 \t 100\t0.21429680287837982 \t 100\t0.2144300639629364 \t 100\t\n",
      "18 0.21376456320285797 \t 100\t0.21424324810504913 \t 100\t0.21394403278827667 \t 100\t\n",
      "19 0.2137138396501541 \t 100\t0.21431781351566315 \t 100\t0.214225634932518 \t 100\t\n",
      "20 0.21410219371318817 \t 100\t0.21387451887130737 \t 100\t0.2140319049358368 \t 100\t\n",
      "21 0.21385245025157928 \t 100\t0.21386881172657013 \t 100\t0.2140824943780899 \t 100\t\n",
      "22 0.21389316022396088 \t 100\t0.21403934061527252 \t 100\t0.21433883905410767 \t 100\t\n",
      "23 0.2139483392238617 \t 100\t0.21397128701210022 \t 100\t0.2141972780227661 \t 100\t\n",
      "24 0.2139614075422287 \t 100\t0.21406808495521545 \t 100\t0.21434612572193146 \t 100\t\n",
      "25 0.21398238837718964 \t 100\t0.2146870195865631 \t 100\t0.21426601707935333 \t 100\t\n",
      "26 0.21393844485282898 \t 100\t0.2139073759317398 \t 100\t0.21416673064231873 \t 100\t\n",
      "27 0.2140522599220276 \t 100\t0.21414802968502045 \t 100\t0.21420377492904663 \t 100\t\n",
      "28 0.2139870673418045 \t 100\t0.214082732796669 \t 100\t0.2139752060174942 \t 100\t\n",
      "29 0.21401546895503998 \t 100\t0.21410565078258514 \t 100\t0.21396049857139587 \t 100\t\n",
      "30 0.21400122344493866 \t 100\t0.2140265256166458 \t 100\t0.21425575017929077 \t 100\t\n",
      "31 0.21388337016105652 \t 100\t0.21399807929992676 \t 100\t0.21407637000083923 \t 100\t\n",
      "32 0.21392159163951874 \t 100\t0.2140941619873047 \t 100\t0.21408149600028992 \t 100\t\n",
      "33 0.21395383775234222 \t 100\t0.21440500020980835 \t 100\t0.21422672271728516 \t 100\t\n",
      "34 0.2138037532567978 \t 100\t0.21439608931541443 \t 100\t0.21408124268054962 \t 100\t\n",
      "35 0.21376056969165802 \t 100\t0.21456997096538544 \t 100\t0.2143670916557312 \t 100\t\n",
      "36 0.2140088677406311 \t 100\t0.2139885574579239 \t 100\t0.21402956545352936 \t 100\t\n",
      "37 0.21393488347530365 \t 100\t0.21376006305217743 \t 100\t0.21411524713039398 \t 100\t\n",
      "38 0.21378003060817719 \t 100\t0.21420679986476898 \t 100\t0.21401236951351166 \t 100\t\n",
      "39 0.21415862441062927 \t 100\t0.21391835808753967 \t 100\t0.2144654542207718 \t 100\t\n",
      "40 0.2140466421842575 \t 100\t0.21397115290164948 \t 100\t0.21426300704479218 \t 100\t\n",
      "41 0.2137943059206009 \t 100\t0.2144620269536972 \t 84\t0.2143053114414215 \t 100\t\n",
      "42 0.21412666141986847 \t 100\t0.21411441266536713 \t 100\t0.2143072783946991 \t 100\t\n",
      "43 0.21394309401512146 \t 100\t0.21407000720500946 \t 100\t0.2141544669866562 \t 100\t\n",
      "44 0.2141152322292328 \t 100\t0.2136252224445343 \t 100\t0.21434976160526276 \t 100\t\n",
      "45 0.21409443020820618 \t 100\t0.21410883963108063 \t 100\t0.21436263620853424 \t 100\t\n",
      "46 0.21402513980865479 \t 100\t0.21393202245235443 \t 100\t0.21408787369728088 \t 100\t\n",
      "47 0.2139686495065689 \t 100\t0.21381334960460663 \t 100\t0.21415366232395172 \t 100\t\n",
      "48 0.21397517621517181 \t 100\t0.21416020393371582 \t 100\t0.21402311325073242 \t 100\t\n",
      "49 0.2140681892633438 \t 100\t0.2140260636806488 \t 100\t0.21421174705028534 \t 100\t\n",
      "50 0.21395203471183777 \t 100\t0.21411240100860596 \t 100\t0.21411484479904175 \t 100\t\n",
      "51 0.21383658051490784 \t 100\t0.2140156626701355 \t 100\t0.21435362100601196 \t 100\t\n",
      "52 0.21380330622196198 \t 100\t0.21381933987140656 \t 100\t0.2141721099615097 \t 100\t\n",
      "53 0.21392279863357544 \t 100\t0.21422290802001953 \t 100\t0.21411699056625366 \t 100\t\n",
      "54 0.21412301063537598 \t 100\t0.21377050876617432 \t 100\t0.2144773155450821 \t 100\t\n",
      "55 0.21384121477603912 \t 100\t0.21391883492469788 \t 100\t0.21433530747890472 \t 100\t\n",
      "56 0.21389532089233398 \t 100\t0.2141612470149994 \t 100\t0.21410861611366272 \t 100\t\n",
      "57 0.21394939720630646 \t 100\t0.21433426439762115 \t 100\t0.21391291916370392 \t 100\t\n",
      "58 0.21399399638175964 \t 100\t0.21385152637958527 \t 100\t0.21425098180770874 \t 100\t\n",
      "59 0.2141062468290329 \t 100\t0.2140694558620453 \t 100\t0.2139793038368225 \t 100\t\n",
      "60 0.21385909616947174 \t 100\t0.21402105689048767 \t 100\t0.21397419273853302 \t 100\t\n",
      "61 0.2140948474407196 \t 100\t0.2142687290906906 \t 100\t0.21408914029598236 \t 100\t\n",
      "62 0.21391940116882324 \t 98\t0.21423132717609406 \t 100\t0.21390384435653687 \t 100\t\n",
      "63 0.2139037698507309 \t 100\t0.21420833468437195 \t 100\t0.21424348652362823 \t 100\t\n",
      "64 0.21392382681369781 \t 100\t0.21414446830749512 \t 100\t0.21425388753414154 \t 100\t\n",
      "65 0.21403196454048157 \t 100\t0.2146458476781845 \t 86\t0.21433646976947784 \t 100\t\n",
      "66 0.21386836469173431 \t 100\t0.21409693360328674 \t 100\t0.2144184410572052 \t 100\t\n",
      "67 0.21398164331912994 \t 100\t0.21400290727615356 \t 100\t0.21410545706748962 \t 100\t\n",
      "68 0.21400631964206696 \t 100\t0.21408399939537048 \t 100\t0.2143155336380005 \t 100\t\n",
      "69 0.2141524851322174 \t 100\t0.21405968070030212 \t 100\t0.21411959826946259 \t 100\t\n",
      "70 0.21398644149303436 \t 100\t0.213834747672081 \t 100\t0.2142648696899414 \t 100\t\n",
      "71 0.2139638215303421 \t 100\t0.21426646411418915 \t 100\t0.21432678401470184 \t 100\t\n",
      "72 0.2139400690793991 \t 100\t0.21425668895244598 \t 100\t0.21414035558700562 \t 100\t\n",
      "73 0.2137744128704071 \t 100\t0.21446266770362854 \t 100\t0.214037224650383 \t 100\t\n",
      "74 0.2139897644519806 \t 100\t0.2139476239681244 \t 100\t0.21418802440166473 \t 100\t\n",
      "75 0.21385763585567474 \t 100\t0.214089035987854 \t 100\t0.21431484818458557 \t 100\t\n",
      "76 0.21377237141132355 \t 100\t0.21418453752994537 \t 100\t0.2143067866563797 \t 100\t\n",
      "77 0.2141823023557663 \t 100\t0.21408875286579132 \t 100\t0.2141706943511963 \t 100\t\n",
      "78 0.21382568776607513 \t 100\t0.21439237892627716 \t 100\t0.21411406993865967 \t 100\t\n",
      "79 0.2137952446937561 \t 100\t0.2139541208744049 \t 100\t0.21411040425300598 \t 100\t\n",
      "80 0.21397291123867035 \t 100\t0.21399137377738953 \t 100\t0.21414035558700562 \t 100\t\n",
      "81 0.21377046406269073 \t 100\t0.21404819190502167 \t 100\t0.21407118439674377 \t 100\t\n",
      "82 0.2140216827392578 \t 100\t0.21420861780643463 \t 100\t0.21439790725708008 \t 100\t\n",
      "83 0.2139628678560257 \t 100\t0.21408560872077942 \t 100\t0.21407414972782135 \t 100\t\n",
      "84 0.21420253813266754 \t 100\t0.21417413651943207 \t 92\t0.21404772996902466 \t 100\t\n",
      "85 0.21403060853481293 \t 100\t0.21372833847999573 \t 100\t0.2142764776945114 \t 100\t\n",
      "86 0.2138269990682602 \t 100\t0.21412751078605652 \t 100\t0.21423515677452087 \t 100\t\n",
      "87 0.21379384398460388 \t 100\t0.2140578031539917 \t 100\t0.2140313684940338 \t 100\t\n",
      "88 0.21375015377998352 \t 100\t0.21398994326591492 \t 100\t0.2141464501619339 \t 100\t\n",
      "89 0.2137051522731781 \t 100\t0.21383677423000336 \t 100\t0.21418902277946472 \t 100\t\n",
      "90 0.2137284129858017 \t 100\t0.213851198554039 \t 100\t0.2143644094467163 \t 100\t\n",
      "91 0.21385180950164795 \t 100\t0.21392019093036652 \t 100\t0.2141847461462021 \t 100\t\n",
      "92 0.21383577585220337 \t 100\t0.2139630913734436 \t 100\t0.21409329771995544 \t 100\t\n",
      "93 0.21380694210529327 \t 100\t0.21404412388801575 \t 100\t0.21408163011074066 \t 100\t\n",
      "94 0.21384887397289276 \t 100\t0.2141691893339157 \t 100\t0.2141292244195938 \t 100\t\n",
      "95 0.2139156609773636 \t 100\t0.21396911144256592 \t 100\t0.21421927213668823 \t 100\t\n",
      "96 0.2139999270439148 \t 100\t0.21389411389827728 \t 100\t0.2142171710729599 \t 100\t\n",
      "97 0.21398037672042847 \t 100\t0.21398349106311798 \t 100\t0.2142581343650818 \t 100\t\n",
      "98 0.2140512466430664 \t 100\t0.21400000154972076 \t 100\t0.21408022940158844 \t 100\t\n",
      "99 0.21379181742668152 \t 100\t0.21416664123535156 \t 100\t0.21428076922893524 \t 100\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6baaa90-4026-4358-8265-5a4e0247e9df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MLC $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6aa86d6-4738-468e-839e-634aae54d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mlc, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_mlc, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_mlc, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mlc/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'relu/'):\n",
    "    os.mkdir(filestr + 'relu/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'square/'):\n",
    "    os.mkdir(filestr + 'square/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'exponential/'):\n",
    "    os.mkdir(filestr + 'exponential/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4551597-7757-4fe3-880f-a5aa1192d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -0.13604561984539032 \t 100\t-0.11521941423416138 \t 100\t-0.20942437648773193 \t 79\t\n",
      "1 -0.14385710656642914 \t 100\t-0.10743831098079681 \t 100\tnan \t 85\t\n",
      "2 -0.16936638951301575 \t 100\t-0.14177453517913818 \t 100\t-0.19868707656860352 \t 56\t\n",
      "3 -0.11812916398048401 \t 100\t-0.10362108796834946 \t 100\tnan \t 89\t\n",
      "4 -0.105319544672966 \t 100\t-0.10645885020494461 \t 100\t-0.21466444432735443 \t 86\t\n",
      "5 -0.11482161283493042 \t 100\t-0.11460504680871964 \t 100\t-0.21253129839897156 \t 82\t\n",
      "6 -0.12384726107120514 \t 100\t-0.12887127697467804 \t 100\tnan \t 95\t\n",
      "7 -0.12204910814762115 \t 100\t-0.11877432465553284 \t 100\t-0.18805336952209473 \t 63\t\n",
      "8 -0.12582780420780182 \t 100\t-0.14920486509799957 \t 100\t-0.22527265548706055 \t 83\t\n",
      "9 -0.11761670559644699 \t 100\t-0.14108197391033173 \t 100\t-0.1843865066766739 \t 55\t\n",
      "10 -0.13326507806777954 \t 100\t-0.13218072056770325 \t 100\t-0.19289343059062958 \t 78\t\n",
      "11 -0.1209031417965889 \t 100\t-0.11254226416349411 \t 100\tnan \t 77\t\n",
      "12 -0.13885584473609924 \t 100\t-0.10793232917785645 \t 100\t-0.1959761530160904 \t 65\t\n",
      "13 -0.13042233884334564 \t 100\t-0.15111730992794037 \t 100\t-0.17877496778964996 \t 55\t\n",
      "14 -0.1328374445438385 \t 100\t-0.14082302153110504 \t 100\t-0.18953891098499298 \t 68\t\n",
      "15 -0.1173388883471489 \t 100\t-0.10884764045476913 \t 100\t-0.1675707846879959 \t 76\t\n",
      "16 -0.1123800054192543 \t 100\t-0.1587415337562561 \t 100\tnan \t 76\t\n",
      "17 -0.1262432485818863 \t 100\t-0.09158631414175034 \t 100\t-0.19515377283096313 \t 68\t\n",
      "18 -0.11597172915935516 \t 100\t-0.1022210642695427 \t 100\t-0.2152685821056366 \t 64\t\n",
      "19 -0.11834470182657242 \t 100\t-0.10538861900568008 \t 100\t-0.2051170915365219 \t 67\t\n",
      "20 -0.13739687204360962 \t 100\t-0.09173126518726349 \t 100\t-0.18825843930244446 \t 67\t\n",
      "21 -0.11082196980714798 \t 100\t0.7890433669090271 \t 28\t-0.1895805299282074 \t 82\t\n",
      "22 -0.1161326989531517 \t 100\t-0.11652272194623947 \t 100\t-0.2196420580148697 \t 78\t\n",
      "23 -0.11941229552030563 \t 100\t-0.14632518589496613 \t 100\t-0.17575493454933167 \t 69\t\n",
      "24 -0.11471490561962128 \t 100\t-0.030816534534096718 \t 72\t-0.19934993982315063 \t 60\t\n",
      "25 -0.12164819985628128 \t 100\t-0.09178321063518524 \t 100\tnan \t 91\t\n",
      "26 -0.13344480097293854 \t 100\t-0.1204492449760437 \t 100\t-0.1775038093328476 \t 51\t\n",
      "27 -0.13577967882156372 \t 100\t-0.11188697814941406 \t 100\t-0.19984768331050873 \t 82\t\n",
      "28 -0.10663554817438126 \t 100\t-0.08699378371238708 \t 100\t-0.18600481748580933 \t 74\t\n",
      "29 -0.13516762852668762 \t 100\t-0.09798367321491241 \t 100\tnan \t 79\t\n",
      "30 -0.13103485107421875 \t 100\t-0.12840938568115234 \t 100\t-0.20242543518543243 \t 89\t\n",
      "31 -0.11058057844638824 \t 100\t0.2983228862285614 \t 43\t-0.19369392096996307 \t 77\t\n",
      "32 -0.13784074783325195 \t 100\t-0.1283784955739975 \t 100\t-0.21450603008270264 \t 77\t\n",
      "33 -0.14810097217559814 \t 100\t-0.15664932131767273 \t 100\t-0.2009638100862503 \t 73\t\n",
      "34 -0.12082739174365997 \t 100\t-0.13381904363632202 \t 100\t-0.21085187792778015 \t 66\t\n",
      "35 -0.1432550847530365 \t 100\t-0.135023832321167 \t 100\t-0.17659856379032135 \t 63\t\n",
      "36 -0.1305878758430481 \t 100\t-0.12418143451213837 \t 100\tnan \t 83\t\n",
      "37 -0.11035965383052826 \t 100\t-0.11227821558713913 \t 100\t-0.2054125815629959 \t 63\t\n",
      "38 -0.12082019448280334 \t 100\t-0.15570229291915894 \t 100\tnan \t 72\t\n",
      "39 -0.15449011325836182 \t 100\t-0.16338594257831573 \t 100\tnan \t 100\t\n",
      "40 -0.12435318529605865 \t 100\t-0.13002613186836243 \t 100\t-0.20853471755981445 \t 76\t\n",
      "41 -0.12231189757585526 \t 100\t-0.13179060816764832 \t 100\t-0.19160300493240356 \t 80\t\n",
      "42 -0.1478154957294464 \t 100\t-0.129048153758049 \t 100\t-0.18737879395484924 \t 86\t\n",
      "43 -0.12023858726024628 \t 100\t-0.13071097433567047 \t 100\t-0.17518968880176544 \t 51\t\n",
      "44 -0.13279055058956146 \t 100\t-0.12163000553846359 \t 100\t-0.20881906151771545 \t 72\t\n",
      "45 -0.12125837802886963 \t 100\t0.43722862005233765 \t 29\t-0.20632638037204742 \t 81\t\n",
      "46 -0.12791775166988373 \t 100\t-0.15107214450836182 \t 100\tnan \t 85\t\n",
      "47 -0.11526235938072205 \t 100\t-0.1343182921409607 \t 100\t-0.20746970176696777 \t 62\t\n",
      "48 -0.13741528987884521 \t 100\t-0.12570804357528687 \t 100\t-0.18388240039348602 \t 97\t\n",
      "49 -0.11716768890619278 \t 100\t-0.09323444962501526 \t 100\t-0.20576415956020355 \t 62\t\n",
      "50 -0.12185865640640259 \t 100\t-0.1156587153673172 \t 100\t-0.19952306151390076 \t 62\t\n",
      "51 -0.11535010486841202 \t 100\t-0.12170469015836716 \t 100\t-0.19504481554031372 \t 88\t\n",
      "52 -0.15406014025211334 \t 100\t-0.1485002487897873 \t 100\t-0.21132603287696838 \t 65\t\n",
      "53 -0.13774509727954865 \t 100\t-0.14726483821868896 \t 100\tnan \t 81\t\n",
      "54 -0.10849283635616302 \t 100\t0.47947970032691956 \t 29\t-0.2027982920408249 \t 80\t\n",
      "55 -0.1361960768699646 \t 100\t-0.12966354191303253 \t 100\tnan \t 81\t\n",
      "56 -0.10113465040922165 \t 100\t-0.09648561477661133 \t 100\t-0.20026344060897827 \t 86\t\n",
      "57 -0.13182689249515533 \t 100\t-0.11965502798557281 \t 100\t-0.18330425024032593 \t 61\t\n",
      "58 -0.12054122239351273 \t 100\t-0.1525554358959198 \t 100\t-0.18700942397117615 \t 70\t\n",
      "59 -0.11715994030237198 \t 100\t-0.14495687186717987 \t 86\t-0.2028067409992218 \t 76\t\n",
      "60 -0.12433994561433792 \t 100\t-0.1326538473367691 \t 100\tnan \t 95\t\n",
      "61 -0.14841656386852264 \t 100\t-0.1344956010580063 \t 100\t-0.2239810675382614 \t 100\t\n",
      "62 -0.13229866325855255 \t 100\t-0.14708936214447021 \t 100\t-0.2131386548280716 \t 78\t\n",
      "63 -0.12915079295635223 \t 100\t-0.12281883507966995 \t 89\tnan \t 71\t\n",
      "64 -0.12609127163887024 \t 100\t-0.0881122499704361 \t 100\tnan \t 81\t\n",
      "65 -0.11580022424459457 \t 100\t-0.15344521403312683 \t 100\t-0.19056962430477142 \t 71\t\n",
      "66 -0.1223374679684639 \t 100\t-0.11337538808584213 \t 100\tnan \t 82\t\n",
      "67 -0.1396089494228363 \t 100\t-0.13685579597949982 \t 100\tnan \t 74\t\n",
      "68 -0.11857542395591736 \t 100\t-0.15486547350883484 \t 100\t-0.18899081647396088 \t 63\t\n",
      "69 -0.1226934865117073 \t 100\t-0.12538005411624908 \t 100\t-0.17915542423725128 \t 86\t\n",
      "70 -0.13385525345802307 \t 100\t-0.11641990393400192 \t 100\tnan \t 95\t\n",
      "71 -0.13264234364032745 \t 100\t-0.16229824721813202 \t 100\t-0.22273358702659607 \t 89\t\n",
      "72 -0.11796969175338745 \t 100\t-0.13705243170261383 \t 100\t-0.18035009503364563 \t 75\t\n",
      "73 -0.11326797306537628 \t 100\t-0.10787956416606903 \t 100\t-0.2206035554409027 \t 91\t\n",
      "74 -0.1367344707250595 \t 90\t-0.12956735491752625 \t 100\t-0.1891188770532608 \t 67\t\n",
      "75 -0.12250466644763947 \t 100\t-0.0892845094203949 \t 100\tnan \t 82\t\n",
      "76 -0.11805971711874008 \t 100\t-0.11277798563241959 \t 100\t-0.18844684958457947 \t 60\t\n",
      "77 -0.12686416506767273 \t 100\t-0.1675111949443817 \t 100\t-0.2179613709449768 \t 90\t\n",
      "78 -0.13059191405773163 \t 100\t-0.06752706319093704 \t 100\t-0.2023899406194687 \t 65\t\n",
      "79 -0.12309539318084717 \t 100\t-0.12556682527065277 \t 100\t-0.17619352042675018 \t 67\t\n",
      "80 -0.10984767228364944 \t 100\t0.49507594108581543 \t 54\t-0.1774766594171524 \t 56\t\n",
      "81 -0.1172330379486084 \t 100\t-0.14148923754692078 \t 100\tnan \t 82\t\n",
      "82 -0.1346612274646759 \t 100\t-0.16015204787254333 \t 100\tnan \t 83\t\n",
      "83 -0.1253400593996048 \t 100\t-0.12090633809566498 \t 100\t-0.1905086189508438 \t 60\t\n",
      "84 -0.12410604953765869 \t 100\t0.10611637681722641 \t 60\t-0.18636099994182587 \t 70\t\n",
      "85 -0.13013452291488647 \t 100\t0.3313104510307312 \t 66\t-0.18084117770195007 \t 60\t\n",
      "86 -0.10934340953826904 \t 100\t0.34349676966667175 \t 37\t-0.1810995489358902 \t 61\t\n",
      "87 -0.11688757687807083 \t 100\t-0.13787990808486938 \t 100\t-0.21347956359386444 \t 100\t\n",
      "88 -0.111056387424469 \t 100\t-0.13501004874706268 \t 100\t-0.21033762395381927 \t 71\t\n",
      "89 -0.1191096231341362 \t 100\t-0.14386321604251862 \t 100\t-0.18916086852550507 \t 68\t\n",
      "90 -0.12448751926422119 \t 100\t0.6006924510002136 \t 33\t-0.16482649743556976 \t 62\t\n",
      "91 -0.12691910564899445 \t 100\t-0.14186148345470428 \t 100\t-0.20597253739833832 \t 71\t\n",
      "92 -0.11787936091423035 \t 100\t-0.13268712162971497 \t 100\tnan \t 65\t\n",
      "93 -0.10838087648153305 \t 100\t-0.14721137285232544 \t 100\tnan \t 100\t\n",
      "94 -0.12833678722381592 \t 100\t-0.1148141399025917 \t 100\t-0.21160151064395905 \t 67\t\n",
      "95 -0.11555875092744827 \t 100\t-0.1183815598487854 \t 100\t-0.17124997079372406 \t 80\t\n",
      "96 -0.1257563680410385 \t 100\t-0.11775320023298264 \t 100\t-0.20812880992889404 \t 77\t\n",
      "97 -0.11144920438528061 \t 100\t-0.07833920419216156 \t 100\tnan \t 97\t\n",
      "98 -0.12406489253044128 \t 100\t-0.13461419939994812 \t 100\t-0.2024185061454773 \t 69\t\n",
      "99 -0.12032415717840195 \t 100\t-0.10280442237854004 \t 100\t-0.20556840300559998 \t 71\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbee70d-c8e0-45ba-a396-87da95618bc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# SQR $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ec3e23c-a094-4507-b97a-41de6ac2f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':sqr, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_sqr, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_sqr, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_sqr/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'relu/'):\n",
    "    os.mkdir(filestr + 'relu/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'square/'):\n",
    "    os.mkdir(filestr + 'square/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'exponential/'):\n",
    "    os.mkdir(filestr + 'exponential/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1040f958-cad5-4942-b7cc-a74d00b38a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9727969765663147 \t 100\t1.1453828811645508 \t 65\t0.9148647785186768 \t 100\t\n",
      "1 0.9785235524177551 \t 100\t1.2218544483184814 \t 100\t0.9155407547950745 \t 100\t\n",
      "2 0.9743910431861877 \t 100\t17.52957534790039 \t 18\t0.9148786664009094 \t 100\t\n",
      "3 0.9864885210990906 \t 100\t1.2884525060653687 \t 25\t0.9143615365028381 \t 100\t\n",
      "4 0.9578568339347839 \t 100\t1.4093098640441895 \t 69\t0.9139790534973145 \t 100\t\n",
      "5 0.9667890071868896 \t 100\t1.9674628973007202 \t 21\t0.9142982363700867 \t 100\t\n",
      "6 0.9521061182022095 \t 100\t0.9828982949256897 \t 100\t0.9141726493835449 \t 100\t\n",
      "7 0.9590039253234863 \t 100\t1.5066394805908203 \t 37\t0.9147028923034668 \t 100\t\n",
      "8 0.9811533689498901 \t 100\t1.256949543952942 \t 42\t0.9140576124191284 \t 100\t\n",
      "9 0.981311559677124 \t 100\t4.853180408477783 \t 34\t0.9143707752227783 \t 100\t\n",
      "10 0.9548529982566833 \t 100\t22.428926467895508 \t 12\t0.9141653776168823 \t 100\t\n",
      "11 0.9791586399078369 \t 100\t23.588804244995117 \t 14\t0.9135320782661438 \t 100\t\n",
      "12 0.9601330757141113 \t 100\t1.554908275604248 \t 29\t0.914269208908081 \t 100\t\n",
      "13 0.9804087281227112 \t 100\t43.502750396728516 \t 11\t0.9140796065330505 \t 100\t\n",
      "14 0.9684557318687439 \t 100\t1.317916989326477 \t 89\t0.9136615991592407 \t 100\t\n",
      "15 0.9832785129547119 \t 100\t1.3538655042648315 \t 41\t0.9142157435417175 \t 100\t\n",
      "16 0.9753973484039307 \t 100\t8.042738914489746 \t 25\t0.9141272902488708 \t 100\t\n",
      "17 0.9557486772537231 \t 100\t2.102324962615967 \t 20\t0.9146071672439575 \t 100\t\n",
      "18 0.9721731543540955 \t 100\t1.2574877738952637 \t 36\t0.9138513207435608 \t 100\t\n",
      "19 0.9707508683204651 \t 100\t1.0623499155044556 \t 100\t0.9141632318496704 \t 100\t\n",
      "20 0.9543580412864685 \t 100\t7.804774284362793 \t 13\t0.914134681224823 \t 100\t\n",
      "21 0.9727394580841064 \t 99\t1.2275540828704834 \t 45\t0.9142064452171326 \t 100\t\n",
      "22 0.9727351665496826 \t 100\t1.3765537738800049 \t 19\t0.9142948389053345 \t 100\t\n",
      "23 0.9497561454772949 \t 100\t0.9718044400215149 \t 100\t0.91474449634552 \t 100\t\n",
      "24 0.9584082365036011 \t 100\t1.1345446109771729 \t 71\t0.9142613410949707 \t 100\t\n",
      "25 0.965292751789093 \t 100\t7.1237101554870605 \t 17\t0.9140114784240723 \t 100\t\n",
      "26 0.9661718010902405 \t 100\t1.1031864881515503 \t 100\t0.9143771529197693 \t 100\t\n",
      "27 0.9734514951705933 \t 100\t1.2215245962142944 \t 100\t0.9145035147666931 \t 100\t\n",
      "28 0.9611148834228516 \t 80\t1.3711482286453247 \t 41\t0.9141796231269836 \t 100\t\n",
      "29 0.9718104004859924 \t 100\t1.3538756370544434 \t 100\t0.9137866497039795 \t 100\t\n",
      "30 0.9746084809303284 \t 100\t2.182914972305298 \t 33\t0.9143210053443909 \t 100\t\n",
      "31 0.9869904518127441 \t 100\t1.709647536277771 \t 31\t0.9140712022781372 \t 100\t\n",
      "32 0.9880958795547485 \t 100\t7.434568881988525 \t 22\t0.9140180349349976 \t 100\t\n",
      "33 0.9825736284255981 \t 100\t1.4456853866577148 \t 40\t0.9137349724769592 \t 100\t\n",
      "34 0.9434425234794617 \t 96\t1.315146803855896 \t 21\t0.9141473770141602 \t 100\t\n",
      "35 0.9719411134719849 \t 100\t1.2588104009628296 \t 46\t0.9142531156539917 \t 100\t\n",
      "36 0.9856656193733215 \t 100\t1.1288917064666748 \t 100\t0.9142876267433167 \t 100\t\n",
      "37 0.9911157488822937 \t 100\t8.571151733398438 \t 46\t0.9140956401824951 \t 100\t\n",
      "38 0.9593794345855713 \t 100\t9.447344779968262 \t 51\t0.9150179624557495 \t 100\t\n",
      "39 0.9670926332473755 \t 100\t0.969164252281189 \t 100\t0.9146740436553955 \t 100\t\n",
      "40 0.963250994682312 \t 100\t11.433528900146484 \t 20\t0.9143530130386353 \t 100\t\n",
      "41 0.9712016582489014 \t 100\t4.043422222137451 \t 24\t0.9141466617584229 \t 100\t\n",
      "42 0.9640135169029236 \t 100\t1.699002742767334 \t 33\t0.915023922920227 \t 100\t\n",
      "43 0.9706234931945801 \t 100\t1.0090410709381104 \t 100\t0.9147803783416748 \t 100\t\n",
      "44 0.9809890985488892 \t 100\t14.247968673706055 \t 25\t0.9143271446228027 \t 100\t\n",
      "45 0.9614573121070862 \t 100\t1.2671557664871216 \t 81\t0.914286196231842 \t 100\t\n",
      "46 0.9652956128120422 \t 100\t29.999876022338867 \t 20\t0.9147453904151917 \t 100\t\n",
      "47 0.9848251938819885 \t 100\t1.3642034530639648 \t 27\t0.9142248034477234 \t 100\t\n",
      "48 0.9834458827972412 \t 100\t1.8757685422897339 \t 23\t0.9137616157531738 \t 100\t\n",
      "49 0.9635673761367798 \t 100\t1.3182858228683472 \t 31\t0.9142047166824341 \t 100\t\n",
      "50 0.9765866994857788 \t 100\t0.9950100779533386 \t 100\t0.9143213629722595 \t 100\t\n",
      "51 0.9675902724266052 \t 100\t1.692257046699524 \t 100\t0.9139248728752136 \t 100\t\n",
      "52 0.9669206738471985 \t 100\t1.3633074760437012 \t 66\t0.9138774275779724 \t 100\t\n",
      "53 0.9799586534500122 \t 100\t1.0672962665557861 \t 100\t0.9137582778930664 \t 100\t\n",
      "54 0.9758484959602356 \t 100\t1.1848442554473877 \t 94\t0.9140514731407166 \t 100\t\n",
      "55 0.9741504788398743 \t 100\t0.9685142040252686 \t 100\t0.914782702922821 \t 100\t\n",
      "56 0.9553244709968567 \t 100\t7.264149188995361 \t 27\t0.9145277738571167 \t 100\t\n",
      "57 0.9761989712715149 \t 100\t1.5066553354263306 \t 43\t0.9139766097068787 \t 100\t\n",
      "58 0.9725354909896851 \t 100\t1.1249094009399414 \t 78\t0.9145836234092712 \t 100\t\n",
      "59 0.9831574559211731 \t 100\t1.1721447706222534 \t 100\t0.9139060378074646 \t 100\t\n",
      "60 0.96924889087677 \t 100\t1.6685476303100586 \t 39\t0.9149883985519409 \t 100\t\n",
      "61 0.9725819826126099 \t 100\t1.3659011125564575 \t 57\t0.9135533571243286 \t 100\t\n",
      "62 0.978766143321991 \t 100\t1.0109549760818481 \t 100\t0.914095401763916 \t 100\t\n",
      "63 0.967087984085083 \t 100\t1.2934527397155762 \t 41\t0.9137223362922668 \t 100\t\n",
      "64 0.9636899828910828 \t 100\t1.3864960670471191 \t 29\t0.9137126207351685 \t 100\t\n",
      "65 0.9810032248497009 \t 100\t1.1048284769058228 \t 100\t0.9147735238075256 \t 100\t\n",
      "66 0.9757547378540039 \t 100\t1.884385347366333 \t 46\t0.9140318036079407 \t 100\t\n",
      "67 0.9724498391151428 \t 100\t1.1027222871780396 \t 58\t0.9135345220565796 \t 100\t\n",
      "68 0.9521619081497192 \t 100\t1.3787970542907715 \t 52\t0.9142194986343384 \t 100\t\n",
      "69 0.9571835398674011 \t 100\t5.302264213562012 \t 27\t0.9145141839981079 \t 100\t\n",
      "70 0.9557950496673584 \t 100\t8.705978393554688 \t 33\t0.9148862361907959 \t 100\t\n",
      "71 0.9433026313781738 \t 100\t1.0677909851074219 \t 100\t0.9138587713241577 \t 100\t\n",
      "72 0.9818251132965088 \t 100\t1.157760739326477 \t 56\t0.9149790406227112 \t 100\t\n",
      "73 0.9673469662666321 \t 100\t1.4146549701690674 \t 29\t0.9148651361465454 \t 100\t\n",
      "74 0.965138852596283 \t 83\t1.3740901947021484 \t 24\t0.9150672554969788 \t 98\t\n",
      "75 0.9617869257926941 \t 100\t1.4129074811935425 \t 27\t0.9138254523277283 \t 100\t\n",
      "76 0.9682137370109558 \t 100\t19.862964630126953 \t 14\t0.9139920473098755 \t 100\t\n",
      "77 0.9633414149284363 \t 100\t1.4756392240524292 \t 20\t0.9145699739456177 \t 100\t\n",
      "78 0.9736371040344238 \t 100\t4.552643775939941 \t 28\t0.9139589667320251 \t 100\t\n",
      "79 0.9727963805198669 \t 100\t1.3951154947280884 \t 100\t0.9137770533561707 \t 100\t\n",
      "80 0.9770995378494263 \t 100\t1.6170450448989868 \t 26\t0.913773238658905 \t 100\t\n",
      "81 0.9583513736724854 \t 100\t1.569569706916809 \t 42\t0.9151662588119507 \t 100\t\n",
      "82 0.9743130803108215 \t 100\t0.9779838919639587 \t 100\t0.9151981472969055 \t 100\t\n",
      "83 0.9870971441268921 \t 100\t7.956296443939209 \t 12\t0.9144365191459656 \t 100\t\n",
      "84 0.9823748469352722 \t 100\t12.962309837341309 \t 19\t0.9141175150871277 \t 100\t\n",
      "85 0.9757634997367859 \t 100\t1.1489700078964233 \t 100\t0.9135791063308716 \t 100\t\n",
      "86 0.9604475498199463 \t 63\t1.1558438539505005 \t 36\t0.9140174984931946 \t 100\t\n",
      "87 0.9784741401672363 \t 100\t4.200854301452637 \t 18\t0.913764238357544 \t 100\t\n",
      "88 0.9601050615310669 \t 100\t1.0498695373535156 \t 100\t0.9141919016838074 \t 100\t\n",
      "89 0.9705577492713928 \t 100\t12.83491039276123 \t 11\t0.914375901222229 \t 100\t\n",
      "90 0.9854867458343506 \t 100\t1.901114583015442 \t 20\t0.9137676358222961 \t 100\t\n",
      "91 0.9763467311859131 \t 100\t1.3937275409698486 \t 85\t0.9140797257423401 \t 100\t\n",
      "92 0.9574298858642578 \t 100\t12.188070297241211 \t 19\t0.9141157269477844 \t 100\t\n",
      "93 0.9845795035362244 \t 100\t13.168795585632324 \t 32\t0.9136373996734619 \t 100\t\n",
      "94 0.9773651361465454 \t 100\t1.2780009508132935 \t 100\t0.9136853814125061 \t 100\t\n",
      "95 0.9727368950843811 \t 100\t15.347016334533691 \t 16\t0.9143010973930359 \t 100\t\n",
      "96 0.9783843755722046 \t 100\t1.0015579462051392 \t 100\t0.9144022464752197 \t 100\t\n",
      "97 0.9752626419067383 \t 100\t1.0801377296447754 \t 48\t0.9141849875450134 \t 100\t\n",
      "98 0.9598960876464844 \t 100\t1.336654782295227 \t 100\t0.9145548939704895 \t 100\t\n",
      "99 0.9750447273254395 \t 100\t3.0202276706695557 \t 16\t0.9147046208381653 \t 100\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741f85a-f192-48fb-bb2f-1c30568fa5dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6ade90b-3356-4119-bec8-b9311b75cf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4784c96680>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 4\n",
    "\n",
    "dat_target = make_target(d)\n",
    "sim_target = make_target(d)\n",
    "\n",
    "dat_ckpt = tf.train.Checkpoint(dat_target)\n",
    "sim_ckpt = tf.train.Checkpoint(sim_target)\n",
    "\n",
    "dat_ckpt.restore('flows/dat/ckpt-79')\n",
    "sim_ckpt.restore('flows/sim/ckpt-79')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb718dcf-eab9-4c9f-9e87-a2b7c1c5be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lambda x: tf.math.exp(dat_target.log_prob(x) - sim_target.log_prob(x)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4f3133c2-dac6-41df-9321-28ea76171d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 49s, sys: 1.32 s, total: 3min 51s\n",
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_mae = np.load('data/zenodo/X_tst.npy')\n",
    "lr_tst = lr(X_mae)\n",
    "np.save('data/zenodo/lr_tst.npy', lr_tst)\n",
    "\n",
    "def mae(model_lr):\n",
    "    abs_dif = abs(model_lr(X_mae) - lr_tst)\n",
    "    abs_dif = abs_dif[np.isfinite(abs_dif)]\n",
    "    return abs_dif.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33598d-74f3-4a55-8655-dbbd4c98a248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "69dbad47-eaad-4b2b-8d52-887761f082a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':bce, 'd':4}\n",
    "params_2 = {'loss':tanh_bce, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_bce, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_bce/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3ff4a908-ebbf-46aa-8080-b02e5ec37924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Calculate mean absolute errors\\nmaes_1 = [mae(lr) for lr in lrs_1]\\nmaes_2 = [mae(lr) for lr in lrs_2]\\nmaes_3 = [mae(lr) for lr in lrs_3]\\n\\navg_1 = np.mean(maes_1)\\navg_2 = np.mean(maes_2)\\navg_3 = np.mean(maes_3)\\n\\n# Save results\\nnp.save(filestr + 'avg_1.npy', avg_1)\\nnp.save(filestr + 'avg_2.npy', avg_2)\\nnp.save(filestr + 'avg_3.npy', avg_3)\\n\\nprint(avg_1, avg_2, avg_3)\\n\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = odds_lr(model_1, m, s)\n",
    "    lrs_2[i] = tanh_lr(model_2, m, s)\n",
    "    lrs_3[i] = arctan_lr(model_3, m, s)\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3)\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "print(avg_1, avg_2, avg_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6ce01e39-4c19-488d-a14f-a48b9f54076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_lr = lrs_1[0]\n",
    "abs_dif = abs(bce_lr(X_mae) - lr_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4a7456aa-3535-40b0-93d1-b3a3f1d1e2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = np.linspace(0, 20)\n",
    "plt.plot(ts, [(abs_dif < t).mean() for t in ts])\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$\\text{Pr}\\left(\\Big|\\mathcal{L}(X) - \\mathcal{L}_\\text{BCE}(X)\\Big| < t\\right)$')\n",
    "plt.title('Proportions of Likelihood Ratios Exceeding')\n",
    "\n",
    "plt.savefig('plots/threshold_plot.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "42155876-d974-4894-9611-edd97ade0a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.9978e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([4.7683716e-07, 6.7250100e+35, 1.3450020e+36, 2.0175030e+36,\n",
       "        2.6900040e+36, 3.3625050e+36, 4.0350060e+36, 4.7075070e+36,\n",
       "        5.3800080e+36, 6.0525093e+36, 6.7250100e+36], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(abs_dif[np.isfinite(abs_dif)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13e87b-0600-4481-82d7-8f0d0ea4f721",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "38aa4548-76a5-4b4c-bc18-0d850162c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mse, 'd':4}\n",
    "params_2 = {'loss':tanh_mse, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_mse, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mse/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)\n",
    "\n",
    "# True distribution information\n",
    "# from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7682203a-16c9-4790-bed1-5d2e23b0d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f46295b2020>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py\", line 616, in new_func\n",
      "    return func(*args, **kwargs)  File \"/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2548, in while_loop_v2\n",
      "    return while_loop(  File \"/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2795, in while_loop\n",
      "    loop_vars = body(*loop_vars)  File \"/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow_probability/python/math/diag_jacobian.py\", line 218, in _fn\n",
      "    return j + 1, result.write(j, res)  File \"/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [149]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     lrs_3[i] \u001b[38;5;241m=\u001b[39m arctan_lr(model_3, m, s)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate mean absolute errors\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m maes_1 \u001b[38;5;241m=\u001b[39m [mae(lr) \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m lrs_1]\n\u001b[1;32m     20\u001b[0m maes_2 \u001b[38;5;241m=\u001b[39m [mae(lr) \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m lrs_2]\n\u001b[1;32m     21\u001b[0m maes_3 \u001b[38;5;241m=\u001b[39m [mae(lr) \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m lrs_3]\n",
      "Input \u001b[0;32mIn [149]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     lrs_3[i] \u001b[38;5;241m=\u001b[39m arctan_lr(model_3, m, s)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate mean absolute errors\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m maes_1 \u001b[38;5;241m=\u001b[39m [\u001b[43mmae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m lrs_1]\n\u001b[1;32m     20\u001b[0m maes_2 \u001b[38;5;241m=\u001b[39m [mae(lr) \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m lrs_2]\n\u001b[1;32m     21\u001b[0m maes_3 \u001b[38;5;241m=\u001b[39m [mae(lr) \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m lrs_3]\n",
      "File \u001b[0;32m<timed exec>:6\u001b[0m, in \u001b[0;36mmae\u001b[0;34m(model_lr)\u001b[0m\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/reweighting-schemes/utils/training.py:167\u001b[0m, in \u001b[0;36modds_lr.<locals>.model_lr\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_lr\u001b[39m(x):\n\u001b[0;32m--> 167\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqueeze(f \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m f))\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/keras/engine/training.py:1982\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1981\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1982\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1983\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1984\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/clusterfs/ml4hep/shahzar/miniconda/envs/multifold/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = odds_lr(model_1, m, s)\n",
    "    lrs_2[i] = tanh_lr(model_2, m, s)\n",
    "    lrs_3[i] = arctan_lr(model_3, m, s)\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3)\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "print(avg_1, avg_2, avg_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadcc88-597b-4b61-a6b3-b3d1c11ea787",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e21fa2-f50c-4582-853f-1ea132efdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mlc, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_mlc, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_mlc, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mlc/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e016852-6db4-4e52-8120-a8bd6f645ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1, m, s)\n",
    "    lrs_2[i] = square_lr(model_2, m, s)\n",
    "    lrs_3[i] = exp_lr(model_3, m, s)\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3)\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "avg_1, avg_2, avg_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3916ccb-334b-4f01-974e-0a98c41f9f1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325de8ea-3b28-4caf-ba25-4418e633199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':sqr, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_sqr, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_sqr, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_sqr/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b8688-4aee-4b2a-a250-f1ba47aa005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1, m, s)\n",
    "    lrs_2[i] = square_lr(model_2, m, s)\n",
    "    lrs_3[i] = exp_lr(model_3, m, s)\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3)\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "avg_1, avg_2, avg_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513c98b-f6d8-4634-95b5-2cf5858e14e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AB MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db897521-4fe9-466f-aaf4-d2ad57dfb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 20\n",
    "\n",
    "# File parameters\n",
    "filestr = 'models/flows/ab_mse/set_{}/'.format(num)\n",
    "mse_filestr = filestr + 'model_{}_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)\n",
    "\n",
    "ps = np.round(np.linspace(-2, 2, 101), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70170ff3-8086-4ecc-8280-f736213f1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "avgs = []\n",
    "for p in ps:\n",
    "    print(p, end = '\\t')\n",
    "    lrs = [None] * reps\n",
    "    params = {'loss':get_mse(p), 'd': 4}\n",
    "    for i in range(reps):\n",
    "        model = create_model(**params)\n",
    "        model.load_weights(mse_filestr.format(p, i))\n",
    "        lrs[i] = pow_odds_lr(model, p, m, s)\n",
    "    \n",
    "    maes = [mae(lr) for lr in lrs]\n",
    "    avgs += [np.mean(maes)]\n",
    "\n",
    "avgs = np.array(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f842f-af6c-47b8-b91f-e9d31057046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "np.save(filestr + 'avgs', avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c60f67-b39d-4f2e-9562-8e52aef9aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 3.5\n",
    "h = 3.25              # Plots have dimension (w,h)\n",
    "\n",
    "plt.figure(figsize = (w, h))\n",
    "\n",
    "plt.plot(ps, avgs, c='blue', lw = 0.75)\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(which = 'minor', length = 3)\n",
    "plt.tick_params(which = 'major', length = 5)\n",
    "plt.tick_params(which = 'both', direction='in')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$p$')\n",
    "#plt.ylim(0, 0.16)\n",
    "\n",
    "plt.title(r\"\\it $A/B$ Parametrization\",loc=\"right\");\n",
    "plt.savefig('plots/paper/ab_mse_zenodo.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c8a66-8e9b-4002-96ec-eedd2b1a4f93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AB SQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd334724-1f8b-436b-9e49-4503f5ceb345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 20\n",
    "\n",
    "# File parameters\n",
    "filestr = 'models/flows/ab_sqr/set_{}/'.format(num)\n",
    "lin_filestr = filestr + 'relu/model_{}_{}.h5'\n",
    "exp_filestr = filestr + 'exponential/model_{}_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)\n",
    "\n",
    "rs = np.sort(np.append(np.round(np.linspace(-2, 2, 81), 2),\n",
    "                       np.round(np.linspace(-0.05, 0.05, 26), 3)[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb33fad-86c8-4532-b713-ddbbe3597496",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_avgs = []\n",
    "exp_avgs = []\n",
    "\n",
    "for r in rs:\n",
    "    print(r, end = '\\t')\n",
    "    lin_lrs = [None] * reps\n",
    "    exp_lrs = [None] * reps\n",
    "    lin_params = {'loss': get_sqr(r), 'd': 4, 'output':'relu'}\n",
    "    exp_params = {'loss': get_exp_sqr(r), 'd': 4, 'output':'linear'}\n",
    "    \n",
    "    for i in range(reps):\n",
    "        lin_model = create_model(**lin_params)\n",
    "        exp_model = create_model(**exp_params)\n",
    "        \n",
    "        lin_model.load_weights(lin_filestr.format(r, i))\n",
    "        exp_model.load_weights(exp_filestr.format(r, i))\n",
    "        \n",
    "        lin_lrs[i] = pow_lr(lin_model, r, m, s)\n",
    "        exp_lrs[i] = pow_exp_lr(exp_model, r, m, s)\n",
    "    \n",
    "    lin_maes = [mae(lr) for lr in lin_lrs]\n",
    "    exp_maes = [mae(lr) for lr in exp_lrs]\n",
    "    \n",
    "    lin_avgs += [np.mean(lin_maes)]\n",
    "    exp_avgs += [np.mean(exp_maes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0b698-a0b7-4a15-a413-d4d10cea1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "lin_avgs = np.array(lin_avgs)\n",
    "exp_avgs = np.array(exp_avgs)\n",
    "\n",
    "np.save(filestr + 'lin_avgs', lin_avgs)\n",
    "np.save(filestr + 'exp_avgs', exp_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569dab1-2a10-459c-a45b-9e678dd05123",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_avgs = np.load(filestr + 'lin_avgs.npy')\n",
    "exp_avgs = np.load(filestr + 'exp_avgs.npy')\n",
    "\n",
    "rs[lin_avgs == min(lin_avgs)], rs[exp_avgs == min(exp_avgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c9481-f9c4-4f30-8fc3-ee9bed466109",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (w, h))\n",
    "\n",
    "plt.plot(rs, lin_avgs, label=r'$\\text{ReLU}(z)$', c='blue', lw = 0.75)\n",
    "plt.plot(rs, exp_avgs, label=r'$\\exp{z}$', c='red', lw = 0.75)\n",
    "plt.legend()\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(which = 'minor', length = 3)\n",
    "plt.tick_params(which = 'major', length = 5)\n",
    "plt.tick_params(which = 'both', direction='in')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$r$')\n",
    "#plt.ylim(0, 0.16)\n",
    "\n",
    "plt.title(r\"\\it $A/B$ Parametrization\",loc=\"right\");\n",
    "plt.savefig('plots/paper/ab_sqr_zenodo.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multifold",
   "language": "python",
   "name": "multifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
