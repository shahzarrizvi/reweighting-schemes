{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c913b40d-0cab-4126-a697-7f9dcb77da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e4adb9-f5a3-47a7-b013-6da24e29d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "\n",
    "# Utility imports\n",
    "from utils.losses import *\n",
    "from utils.plotting import *\n",
    "from utils.training import *\n",
    "\n",
    "from flows.flows import *\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8816cc5e-528f-416d-adf1-8e98f8c0dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836abb92-a317-4520-9b36-d60c8588a715",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306c891-2979-4d9b-ac19-20ad3a6d36be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BCE $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf47a8f-61ec-4c44-a96d-41cda631935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':bce, 'd':4}\n",
    "params_2 = {'loss':tanh_bce, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_bce, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_bce/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'sigmoid/'):\n",
    "    os.mkdir(filestr + 'sigmoid/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'tanh/'):\n",
    "    os.mkdir(filestr + 'tanh/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'arctan/'):\n",
    "    os.mkdir(filestr + 'arctan/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd23de1-cfa5-4896-b9d5-47073ec28015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9638f4ac-8128-458b-a8b5-bdaf2b0ab509",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MSE $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2afea-448e-4859-9769-d45efeb72fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mse, 'd':4}\n",
    "params_2 = {'loss':tanh_mse, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_mse, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mse/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'sigmoid/'):\n",
    "    os.mkdir(filestr + 'sigmoid/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'tanh/'):\n",
    "    os.mkdir(filestr + 'tanh/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'arctan/'):\n",
    "    os.mkdir(filestr + 'arctan/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ce72c-c192-46a2-bf81-fe9387d4c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6baaa90-4026-4358-8265-5a4e0247e9df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLC $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa86d6-4738-468e-839e-634aae54d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mlc, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_mlc, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_mlc, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mlc/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'relu/'):\n",
    "    os.mkdir(filestr + 'relu/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'square/'):\n",
    "    os.mkdir(filestr + 'square/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'exponential/'):\n",
    "    os.mkdir(filestr + 'exponential/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4551597-7757-4fe3-880f-a5aa1192d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbee70d-c8e0-45ba-a396-87da95618bc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SQR $C$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3e23c-a094-4507-b97a-41de6ac2f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':sqr, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_sqr, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_sqr, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_sqr/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'relu/'):\n",
    "    os.mkdir(filestr + 'relu/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'square/'):\n",
    "    os.mkdir(filestr + 'square/')\n",
    "\n",
    "if not os.path.isdir(filestr + 'exponential/'):\n",
    "    os.mkdir(filestr + 'exponential/')\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040f958-cad5-4942-b7cc-a74d00b38a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1, trace = train(data, **params_1)\n",
    "    model_2, trace = train(data, **params_2)\n",
    "    model_3, trace = train(data, **params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741f85a-f192-48fb-bb2f-1c30568fa5dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ade90b-3356-4119-bec8-b9311b75cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = 4\n",
    "#\n",
    "#dat_target = make_target(d)\n",
    "#sim_target = make_target(d)\n",
    "#\n",
    "#dat_ckpt = tf.train.Checkpoint(dat_target)\n",
    "#sim_ckpt = tf.train.Checkpoint(sim_target)\n",
    "#\n",
    "#dat_ckpt.restore('flows/dat/ckpt-79')\n",
    "#sim_ckpt.restore('flows/sim/ckpt-79')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb718dcf-eab9-4c9f-9e87-a2b7c1c5be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lambda x: tf.math.exp(dat_target.log_prob(x) - sim_target.log_prob(x)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3133c2-dac6-41df-9321-28ea76171d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#X_mae = np.load('data/zenodo/X_tst.npy')\n",
    "#lr_tst = lr(X_mae)\n",
    "#np.save('data/zenodo/lr_tst.npy', lr_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397b9acd-70f9-4bb8-8ec2-f34c6a9fdad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mae = np.load('data/zenodo/X_tst.npy')\n",
    "lr_tst = np.load('data/zenodo/lr_tst.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10649c6a-b2ec-454b-855f-9e8ffa212871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(model_lr):\n",
    "    abs_dif = abs(model_lr(X_mae) - lr_tst)\n",
    "    return abs_dif[abs_dif < 100].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33598d-74f3-4a55-8655-dbbd4c98a248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69dbad47-eaad-4b2b-8d52-887761f082a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':bce, 'd':4}\n",
    "params_2 = {'loss':tanh_bce, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_bce, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_bce/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4a908-ebbf-46aa-8080-b02e5ec37924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22851/952197064.py:2: RuntimeWarning: invalid value encountered in subtract\n",
      "  abs_dif = abs(model_lr(X_mae) - lr_tst)\n"
     ]
    }
   ],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = odds_lr(model_1, m, s)\n",
    "    lrs_2[i] = tanh_lr(model_2, m, s)\n",
    "    lrs_3[i] = arctan_lr(model_3, m, s)\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "    \n",
    "print('Absolute Differences')\n",
    "abs_dif_1 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_1])\n",
    "abs_dif_2 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_2])\n",
    "abs_dif_3 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_3])\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3, where = ~np.isnan(maes_3))\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "np.save(filestr + 'abs_dif_1.npy', avg_1)\n",
    "np.save(filestr + 'abs_dif_2.npy', avg_2)\n",
    "np.save(filestr + 'abs_dif_3.npy', avg_3)\n",
    "\n",
    "avg_1, avg_2, avg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7456aa-3535-40b0-93d1-b3a3f1d1e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = abs_dif_1.flatten()\n",
    "bb = abs_dif_2.flatten()\n",
    "cc = abs_dif_3.flatten()\n",
    "\n",
    "ts = np.linspace(0, 20)\n",
    "plt.plot(ts, [(aa < t).mean() for t in ts], label = r'$\\sigma(z)$')\n",
    "plt.plot(ts, [(bb < t).mean() for t in ts], label = r'$\\frac{1}{2}\\left(\\tanh{z} + 1\\right)$')\n",
    "plt.plot(ts, [(cc < t).mean() for t in ts], label = r'$\\frac{1}{\\pi}\\left(\\arctan{z} + \\frac{\\pi}{2}\\right)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$\\text{Pr}\\left(\\Big|\\mathcal{L}(X) - \\mathcal{L}_\\text{BCE}(X)\\Big| < t\\right)$')\n",
    "plt.title(r'BCE Likelihood Ratios Absolute Differences')\n",
    "\n",
    "plt.savefig('plots/bce_threshold_plot.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13e87b-0600-4481-82d7-8f0d0ea4f721",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa4548-76a5-4b4c-bc18-0d850162c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mse, 'd':4}\n",
    "params_2 = {'loss':tanh_mse, 'd':4, 'output': 'linear'}\n",
    "params_3 = {'loss':arctan_mse, 'd':4,  'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mse/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'sigmoid/model_{}.h5'\n",
    "filestr_2 = filestr + 'tanh/model_{}.h5'\n",
    "filestr_3 = filestr + 'arctan/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682203a-16c9-4790-bed1-5d2e23b0d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = odds_lr(model_1, m, s)\n",
    "    lrs_2[i] = tanh_lr(model_2, m, s)\n",
    "    lrs_3[i] = arctan_lr(model_3, m, s)\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "\n",
    "print('Absolute Differences')\n",
    "abs_dif_1 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_1])\n",
    "abs_dif_2 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_2])\n",
    "abs_dif_3 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_3])\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3, where = ~np.isnan(maes_3))\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "np.save(filestr + 'abs_dif_1.npy', avg_1)\n",
    "np.save(filestr + 'abs_dif_2.npy', avg_2)\n",
    "np.save(filestr + 'abs_dif_3.npy', avg_3)\n",
    "\n",
    "avg_1, avg_2, avg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf098b1-7914-499a-aad5-f9d3b6181995",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = abs_dif_1.flatten()\n",
    "bb = abs_dif_2.flatten()\n",
    "cc = abs_dif_3.flatten()\n",
    "\n",
    "ts = np.linspace(0, 20)\n",
    "plt.plot(ts, [(aa < t).mean() for t in ts], label = r'$\\sigma(z)$')\n",
    "plt.plot(ts, [(bb < t).mean() for t in ts], label = r'$\\frac{1}{2}\\left(\\tanh{z} + 1\\right)$')\n",
    "plt.plot(ts, [(cc < t).mean() for t in ts], label = r'$\\frac{1}{\\pi}\\left(\\arctan{z} + \\frac{\\pi}{2}\\right)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$\\text{Pr}\\left(\\Big|\\mathcal{L}(X) - \\mathcal{L}_\\text{MSE}(X)\\Big| < t\\right)$')\n",
    "plt.title(r'MSE Likelihood Ratios Absolute Differences')\n",
    "\n",
    "plt.savefig('plots/mse_threshold_plot.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadcc88-597b-4b61-a6b3-b3d1c11ea787",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e21fa2-f50c-4582-853f-1ea132efdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mlc, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_mlc, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_mlc, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_mlc/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e016852-6db4-4e52-8120-a8bd6f645ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1, m, s)\n",
    "    lrs_2[i] = square_lr(model_2, m, s)\n",
    "    lrs_3[i] = exp_lr(model_3, m, s)\n",
    "print()\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "print('MAEs')\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "\n",
    "print('Absolute Differences')\n",
    "abs_dif_1 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_1])\n",
    "abs_dif_2 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_2])\n",
    "abs_dif_3 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_3])\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3, where = ~np.isnan(maes_3))\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "np.save(filestr + 'abs_dif_1.npy', avg_1)\n",
    "np.save(filestr + 'abs_dif_2.npy', avg_2)\n",
    "np.save(filestr + 'abs_dif_3.npy', avg_3)\n",
    "\n",
    "avg_1, avg_2, avg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2dff01-f636-4b8e-9728-f9920be63be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = abs_dif_1.flatten()\n",
    "bb = abs_dif_2.flatten()\n",
    "cc = abs_dif_3.flatten()\n",
    "\n",
    "ts = np.linspace(0, 20)\n",
    "plt.plot(ts, [(aa < t).mean() for t in ts], label = r'${\\rm ReLU}(z)$')\n",
    "plt.plot(ts, [(bb < t).mean() for t in ts], label = r'$z^2$')\n",
    "plt.plot(ts, [(cc < t).mean() for t in ts], label = r'$\\exp(z)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$\\text{Pr}\\left(\\Big|\\mathcal{L}(X) - \\mathcal{L}_\\text{MLC}(X)\\Big| < t\\right)$')\n",
    "plt.title(r'MLC Likelihood Ratios Absolute Differences')\n",
    "\n",
    "plt.savefig('plots/mlc_threshold_plot.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3916ccb-334b-4f01-974e-0a98c41f9f1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325de8ea-3b28-4caf-ba25-4418e633199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':sqr, 'd': 4, 'output': 'relu'}\n",
    "params_2 = {'loss':square_sqr, 'd': 4, 'output': 'linear'}\n",
    "params_3 = {'loss':exp_sqr, 'd': 4, 'output': 'linear'}\n",
    "\n",
    "filestr = 'models/flows/c_sqr/set_{}/'.format(num)\n",
    "filestr_1 = filestr + 'relu/model_{}.h5'\n",
    "filestr_2 = filestr + 'square/model_{}.h5'\n",
    "filestr_3 = filestr + 'exponential/model_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b8688-4aee-4b2a-a250-f1ba47aa005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    \n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1, m, s)\n",
    "    lrs_2[i] = square_lr(model_2, m, s)\n",
    "    lrs_3[i] = exp_lr(model_3, m, s)\n",
    "\n",
    "# Calculate mean absolute errors\n",
    "maes_1 = [mae(lr) for lr in lrs_1]\n",
    "maes_2 = [mae(lr) for lr in lrs_2]\n",
    "maes_3 = [mae(lr) for lr in lrs_3]\n",
    "\n",
    "print('Absolute Differences')\n",
    "abs_dif_1 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_1])\n",
    "abs_dif_2 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_2])\n",
    "abs_dif_3 = np.array([abs(lr(X_mae) - lr_tst) for lr in lrs_3])\n",
    "\n",
    "avg_1 = np.mean(maes_1)\n",
    "avg_2 = np.mean(maes_2)\n",
    "avg_3 = np.mean(maes_3, where = ~np.isnan(maes_3))\n",
    "\n",
    "# Save results\n",
    "np.save(filestr + 'avg_1.npy', avg_1)\n",
    "np.save(filestr + 'avg_2.npy', avg_2)\n",
    "np.save(filestr + 'avg_3.npy', avg_3)\n",
    "\n",
    "np.save(filestr + 'abs_dif_1.npy', avg_1)\n",
    "np.save(filestr + 'abs_dif_2.npy', avg_2)\n",
    "np.save(filestr + 'abs_dif_3.npy', avg_3)\n",
    "\n",
    "avg_1, avg_2, avg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df040e3-10c3-4c7c-b5d6-1aecb060e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = abs_dif_1.flatten()\n",
    "bb = abs_dif_2.flatten()\n",
    "cc = abs_dif_3.flatten()\n",
    "\n",
    "ts = np.linspace(0, 20)\n",
    "plt.plot(ts, [(aa < t).mean() for t in ts], label = r'${\\rm ReLU}(z)$')\n",
    "plt.plot(ts, [(bb < t).mean() for t in ts], label = r'$z^2$')\n",
    "plt.plot(ts, [(cc < t).mean() for t in ts], label = r'$\\exp(z)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(r'$t$')\n",
    "plt.ylabel(r'$\\text{Pr}\\left(\\Big|\\mathcal{L}(X) - \\mathcal{L}_\\text{SQR}(X)\\Big| < t\\right)$')\n",
    "plt.title(r'SQR Likelihood Ratios Absolute Differences')\n",
    "\n",
    "plt.savefig('plots/sqr_threshold_plot.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513c98b-f6d8-4634-95b5-2cf5858e14e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AB MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db897521-4fe9-466f-aaf4-d2ad57dfb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 20\n",
    "\n",
    "# File parameters\n",
    "filestr = 'models/flows/ab_mse/set_{}/'.format(num)\n",
    "mse_filestr = filestr + 'model_{}_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)\n",
    "\n",
    "ps = np.round(np.linspace(-2, 2, 101), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70170ff3-8086-4ecc-8280-f736213f1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "avgs = []\n",
    "for p in ps:\n",
    "    print(p, end = '\\t')\n",
    "    lrs = [None] * reps\n",
    "    params = {'loss':get_mse(p), 'd': 4}\n",
    "    for i in range(reps):\n",
    "        model = create_model(**params)\n",
    "        model.load_weights(mse_filestr.format(p, i))\n",
    "        lrs[i] = pow_odds_lr(model, p, m, s)\n",
    "    \n",
    "    maes = [mae(lr) for lr in lrs]\n",
    "    avgs += [np.mean(maes)]\n",
    "\n",
    "avgs = np.array(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f842f-af6c-47b8-b91f-e9d31057046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "np.save(filestr + 'avgs', avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06e29c-6b53-4824-99f6-58efc248e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = np.load(filestr + 'avgs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c60f67-b39d-4f2e-9562-8e52aef9aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 3.5\n",
    "h = 3.25              # Plots have dimension (w,h)\n",
    "\n",
    "plt.figure(figsize = (w, h))\n",
    "\n",
    "plt.plot(ps, avgs, c='blue', lw = 0.75)\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(which = 'minor', length = 3)\n",
    "plt.tick_params(which = 'major', length = 5)\n",
    "plt.tick_params(which = 'both', direction='in')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$p$')\n",
    "plt.ylim(0, 1.25)\n",
    "\n",
    "plt.title(r\"\\it $A/B$ Parametrization\",loc=\"right\");\n",
    "plt.savefig('plots/paper/ab_mse_zenodo.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c8a66-8e9b-4002-96ec-eedd2b1a4f93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AB SQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd334724-1f8b-436b-9e49-4503f5ceb345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 20\n",
    "\n",
    "# File parameters\n",
    "filestr = 'models/flows/ab_sqr/set_{}/'.format(num)\n",
    "lin_filestr = filestr + 'relu/model_{}_{}.h5'\n",
    "exp_filestr = filestr + 'exponential/model_{}_{}.h5'\n",
    "\n",
    "# Data parameters\n",
    "N = 10**6\n",
    "X = np.load('data/zenodo/X_trn.npy')[:N]\n",
    "y = np.load('data/zenodo/y_trn.npy')[:N].astype('float32')\n",
    "data, m, s = split_data(X, y)\n",
    "\n",
    "rs = np.sort(np.append(np.round(np.linspace(-2, 2, 81), 2),\n",
    "                       np.round(np.linspace(-0.05, 0.05, 26), 3)[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb33fad-86c8-4532-b713-ddbbe3597496",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_avgs = []\n",
    "exp_avgs = []\n",
    "\n",
    "for r in rs:\n",
    "    print(r, end = '\\t')\n",
    "    lin_lrs = [None] * reps\n",
    "    exp_lrs = [None] * reps\n",
    "    lin_params = {'loss': get_sqr(r), 'd': 4, 'output':'relu'}\n",
    "    exp_params = {'loss': get_exp_sqr(r), 'd': 4, 'output':'linear'}\n",
    "    \n",
    "    for i in range(reps):\n",
    "        lin_model = create_model(**lin_params)\n",
    "        exp_model = create_model(**exp_params)\n",
    "        \n",
    "        lin_model.load_weights(lin_filestr.format(r, i))\n",
    "        exp_model.load_weights(exp_filestr.format(r, i))\n",
    "        \n",
    "        lin_lrs[i] = pow_lr(lin_model, r, m, s)\n",
    "        exp_lrs[i] = pow_exp_lr(exp_model, r, m, s)\n",
    "    \n",
    "    lin_maes = [mae(lr) for lr in lin_lrs]\n",
    "    exp_maes = [mae(lr) for lr in exp_lrs]\n",
    "    \n",
    "    lin_avgs += [np.mean(lin_maes)]\n",
    "    exp_avgs += [np.mean(exp_maes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0b698-a0b7-4a15-a413-d4d10cea1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "lin_avgs = np.array(lin_avgs)\n",
    "exp_avgs = np.array(exp_avgs)\n",
    "\n",
    "np.save(filestr + 'lin_avgs', lin_avgs)\n",
    "np.save(filestr + 'exp_avgs', exp_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569dab1-2a10-459c-a45b-9e678dd05123",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_avgs = np.load(filestr + 'lin_avgs.npy')\n",
    "exp_avgs = np.load(filestr + 'exp_avgs.npy')\n",
    "\n",
    "rs[lin_avgs == min(lin_avgs)], rs[exp_avgs == min(exp_avgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c9481-f9c4-4f30-8fc3-ee9bed466109",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (w, h))\n",
    "\n",
    "plt.plot(rs, lin_avgs, label=r'$\\text{ReLU}(z)$', c='blue', lw = 0.75)\n",
    "plt.plot(rs, exp_avgs, label=r'$\\exp{z}$', c='red', lw = 0.75)\n",
    "plt.legend()\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(which = 'minor', length = 3)\n",
    "plt.tick_params(which = 'major', length = 5)\n",
    "plt.tick_params(which = 'both', direction='in')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$r$')\n",
    "#plt.ylim(0, 0.16)\n",
    "\n",
    "plt.title(r\"\\it $A/B$ Parametrization\",loc=\"right\");\n",
    "plt.savefig('plots/paper/ab_sqr_zenodo.png', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multifold",
   "language": "python",
   "name": "multifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
