{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager\n",
    "rc('font', family='serif')\n",
    "rc('text', usetex=True)\n",
    "rc('font', size=22)\n",
    "rc('xtick', labelsize=15)\n",
    "rc('ytick', labelsize=15)\n",
    "rc('legend', fontsize=15)\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the data.\n",
    "N = 10**6\n",
    "r = 5\n",
    "sigma = 1\n",
    "\n",
    "# Background is Gamma(r, √(σ/r)). Signal is Gamma(r + 1, √(σ/(r + 1))))\n",
    "bkgd = np.random.gamma(r, (sigma / r)**0.5, N)\n",
    "sgnl = np.random.gamma(r + 1, (sigma / (r + 1))**0.5, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "N = 10**6\n",
    "mu = 0.1\n",
    "sigma = 1\n",
    "\n",
    "# Background is Normal(-μ, σ). Signal is Normal(μ, σ))\n",
    "bkgd = np.random.normal(-mu, sigma, N)\n",
    "sgnl = np.random.normal(mu, sigma, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "def bce(y_true, y_pred):\n",
    "    # Clipping to (ɛ, 1 - ɛ) is fine since the final activation is sigmoid.\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    \n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + \n",
    "             (1. - y_true) * K.log(1. - y_pred))\n",
    "\n",
    "def square_bce(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred**2) + \n",
    "             (1. - y_true) * K.log(1. - y_pred**2))\n",
    "\n",
    "def exp_bce(y_true, y_pred):\n",
    "    return -((y_true) * (y_pred) + \n",
    "             (1. - y_true) * (1. - y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    # Clipping to (ɛ, 1 - ɛ) is fine since the final activation is sigmoid.\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    \n",
    "    return -((y_true) * -K.square(1. - y_pred) + \n",
    "             (1. - y_true) * -K.square(y_pred))\n",
    "\n",
    "def square_mse(y_true, y_pred):\n",
    "    return -((y_true) * -K.square(1. - y_pred) \n",
    "             + (1. - y_true) * -K.square(y_pred + K.epsilon()))\n",
    "\n",
    "def exp_mse(y_true, y_pred):\n",
    "    return -((y_true) * -K.square(1. - K.exp(y_pred)) + \n",
    "             (1. - y_true) * -K.square(K.exp(y_pred))) \n",
    "\n",
    "def get_mse(p):\n",
    "    def mse_p(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    \n",
    "        return -((y_true) * -K.pow(1. - y_pred, p) + \n",
    "                 (1. - y_true) * -K.pow(y_pred, p))\n",
    "    return mse_p\n",
    "             \n",
    "def mlc(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + \n",
    "             (1. - y_true) * (1. - y_pred))\n",
    "\n",
    "def square_mlc(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred**2 + K.epsilon()) + \n",
    "             (1. - y_true) * (1. - y_pred**2))\n",
    "\n",
    "def exp_mlc(y_true, y_pred):\n",
    "    return -((y_true) * (y_pred) + \n",
    "             (1. - y_true) * (1. - K.exp(y_pred)))\n",
    "\n",
    "def sqr(y_true, y_pred):\n",
    "    return -((y_true) * -1. / K.sqrt(y_pred + K.epsilon()) + \n",
    "             (1. - y_true) * -K.sqrt(y_pred + K.epsilon()))\n",
    "\n",
    "def square_sqr(y_true, y_pred):\n",
    "    return -((y_true) * -1. / K.sqrt(K.square(y_pred)) + \n",
    "             (1. - y_true) * -K.sqrt(K.square(y_pred)))\n",
    "\n",
    "def exp_sqr(y_true, y_pred):\n",
    "    return -((y_true) * -1. / K.sqrt(K.exp(y_pred)) + \n",
    "             (1. - y_true) * -K.sqrt(K.exp(y_pred)))\n",
    "\n",
    "def get_sqr(p):\n",
    "    def sqr_p(y_true, y_pred):\n",
    "        return -((y_true) * -K.pow(y_pred + K.epsilon(), -p/2) + \n",
    "                 (1. - y_true) * -K.pow(y_pred + K.epsilon(), p/2))\n",
    "    return sqr_p\n",
    "\n",
    "def get_exp_sqr(p):\n",
    "    def exp_sqr_p(y_true, y_pred):\n",
    "        return -((y_true) * -K.pow(K.exp(y_pred), -p/2) + \n",
    "                 (1. - y_true) * -K.pow(K.exp(y_pred), p/2))\n",
    "    return exp_sqr_p\n",
    "        \n",
    "# Likelihood ratios\n",
    "def lr(x):\n",
    "    #return np.exp(-10 + 11) * (10/11)**x\n",
    "    return np.exp(-(1/(2 * sigma**2)) * ( (x - mu)**2 - (x + mu)**2))\n",
    "    r_1 = r\n",
    "    r_2 = r + 1\n",
    "    v_1 = (r_1 / sigma)**0.5\n",
    "    v_2 = (r_2 / sigma)**0.5\n",
    "    return v_2**r_2 * np.math.factorial(r_1 - 1) * x**(r_2 - r_1) * \\\n",
    "           np.exp(-(v_2 - v_1)*x) / (v_1**r_1 * np.math.factorial(r_2 - 1))\n",
    "\n",
    "def odds_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f / (1. - f))\n",
    "    return model_lr\n",
    "\n",
    "def square_odds_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f**2 / (1. - f**2))\n",
    "    return model_lr\n",
    "\n",
    "def exp_odds_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(np.exp(f) / (1. - np.exp(f)))\n",
    "    return model_lr\n",
    "\n",
    "def pure_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f)\n",
    "    return model_lr\n",
    "\n",
    "def square_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f**2)\n",
    "    return model_lr\n",
    "\n",
    "def exp_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(np.exp(f))\n",
    "    return model_lr\n",
    "\n",
    "def pow_lr(model, p):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f**p)\n",
    "    return model_lr\n",
    "\n",
    "def exp_pow_lr(model, p):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(np.exp(f)**p)\n",
    "    return model_lr\n",
    "\n",
    "def pow_odds_lr(model, p):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze( (f / (1. - f))**(p - 1))\n",
    "    return model_lr\n",
    "\n",
    "def make_mae(mu_mae, sigma_mae, N_mae=10**4):\n",
    "    bkgd_mae = np.random.normal(-mu_mae, sigma_mae, N_mae)\n",
    "    sgnl_mae = np.random.normal(mu_mae, sigma_mae, N_mae)\n",
    "    X_mae = np.concatenate([bkgd_mae, sgnl_mae])\n",
    "    \n",
    "    def mae(model_lr):\n",
    "        nonlocal X_mae\n",
    "        return np.abs(model_lr(X_mae) - lr(X_mae)).mean()\n",
    "    return mae\n",
    "\n",
    "def make_mae(r_mae, sigma_mae, N_mae=10**4):\n",
    "    bkgd_mae = np.random.gamma(r_mae, (sigma_mae / r_mae)**0.5, N_mae)\n",
    "    sgnl_mae = np.random.gamma(r_mae + 1, (sigma_mae / (r_mae + 1))**0.5, N_mae)\n",
    "    X_mae = np.concatenate([bkgd_mae, sgnl_mae])\n",
    "    \n",
    "    def mae(model_lr):\n",
    "        nonlocal X_mae\n",
    "        return np.abs(model_lr(X_mae) - lr(X_mae)).mean()\n",
    "    return mae\n",
    "\n",
    "def make_mpe(mu_mpe, sigma_mpe, N_mpe=10**4):\n",
    "    bkgd_mpe = np.random.normal(-mu_mpe, sigma_mpe, N_mpe)\n",
    "    sgnl_mpe = np.random.normal(mu_mpe, sigma_mpe, N_mpe)\n",
    "    X_mpe = np.concatenate([bkgd_mpe, sgnl_mpe])\n",
    "    \n",
    "    def mpe(model_lr):\n",
    "        nonlocal X_mpe\n",
    "        return np.abs((model_lr(X_mpe) - lr(X_mpe)) / lr(X_mpe)).mean() * 100\n",
    "    return mpe\n",
    "    \n",
    "mae = make_mae(r, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(patience=10,\n",
    "                              verbose=0,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "def create_model(loss,\n",
    "                 hidden='relu', \n",
    "                 output='sigmoid', \n",
    "                 dropout=True, \n",
    "                 optimizer='adam', \n",
    "                 metrics=['accuracy'], \n",
    "                 verbose=0):\n",
    "    model = Sequential()\n",
    "    if dropout:\n",
    "        model.add(Dense(64, activation=hidden, input_shape=(1, )))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(128, activation=hidden))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(64, activation=hidden))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(1, activation=output))\n",
    "    else: \n",
    "        model.add(Dense(64, activation=hidden, input_shape=(1, )))\n",
    "        model.add(Dense(128, activation=hidden))\n",
    "        model.add(Dense(64, activation=hidden))\n",
    "        model.add(Dense(1, activation=output))        \n",
    "    \n",
    "    return model\n",
    "\n",
    "def train(loss,\n",
    "          hidden='relu', \n",
    "          output='sigmoid', \n",
    "          dropout=True, \n",
    "          optimizer='adam', \n",
    "          metrics=['accuracy'], \n",
    "          verbose=0):\n",
    "    model = create_model(loss, hidden, output, dropout, optimizer, metrics, verbose)      \n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    trace = model.fit(X_train, \n",
    "                      y_train,\n",
    "                      epochs = 100, \n",
    "                      batch_size=int(0.1*N), \n",
    "                      validation_data=(X_test, y_test),\n",
    "                      callbacks=[earlystopping], \n",
    "                      verbose=verbose)\n",
    "    print(trace.history['val_loss'][-1], end = ' ')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def get_preds(model_lrs, xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in model_lrs, a list of model likelihood ratios and xs, a list of \n",
    "    # values on which to compute the likelihood ratios. Returns a 2D array. The \n",
    "    # nth row is the likelihood ratio predictions from the nth model in \n",
    "    # model_lrs.\n",
    "    return np.array([model_lr(xs) for model_lr in model_lrs])\n",
    "    \n",
    "def avg_lr(preds):\n",
    "    # Takes in a 2D array of multiple models' likelihood ratio predictions. \n",
    "    # Returns the average likelihood ratio prediction and its error.\n",
    "    return preds.mean(axis=0), preds.std(axis=0)\n",
    "\n",
    "def avg_lrr(preds, xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a 2D array of multiple models' likelihood ratio predictions. \n",
    "    # Returns the average ratio of predicted likelihood to true likelihood and \n",
    "    # its error.\n",
    "    lrr_preds = preds / lr(xs)\n",
    "    return lrr_preds.mean(axis=0), lrr_preds.std(axis=0)\n",
    "    \n",
    "def lr_plot(ensembles,\n",
    "            title=None,\n",
    "            filename=None,\n",
    "            cs = ['brown', 'green', 'red', 'blue'],\n",
    "            lss = ['-', '--', '-.', ':'],\n",
    "            xs=np.linspace(4, 16, 1000)):\n",
    "            #xs=np.linspace(0, 20, 1000)):\n",
    "            #xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a list of pairs (lr_avg, lr_err). Plots them against the true \n",
    "    # likelihood.\n",
    "    fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "    \n",
    "    # Plot true likelihood\n",
    "    plt.plot(xs, lr(xs), label = 'Exact', c='k', ls='-')\n",
    "    \n",
    "    # Plot model likelihoods\n",
    "    for i in range(len(ensembles)):\n",
    "        avg, err, lbl = ensembles[i]\n",
    "        plt.plot(xs, avg, label=lbl, c=cs[i], ls=lss[i])\n",
    "        #plt.fill_between(xs, avg - err, avg + err, color=cs[i], alpha=0.1)\n",
    "    plt.legend()\n",
    "    ax_1.minorticks_on()\n",
    "    ax_1.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Likelihood Ratio')\n",
    "\n",
    "    # Plot background and signal\n",
    "    ax_2 = ax_1.twinx()\n",
    "    bins = np.linspace(4, 16, 100)\n",
    "    #bins = np.linspace(0, 20, 100)\n",
    "    #bins = np.linspace(-6, 6, 100)\n",
    "    plt.hist(sgnl, alpha=0.1, bins=bins)\n",
    "    plt.hist(bkgd, alpha=0.1, bins=bins)\n",
    "    ax_2.minorticks_on()\n",
    "    ax_2.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.xlim(xs[0], xs[-1])\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(10.1)+r\", \\mu_{\\rm{bkgd}}=\"+str(9.9)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    #plt.title(r\"$r_{\\rm{sgnl}}=\"+str(r)+r\", r_{\\rm{bkgd}}=\"+str(r+1)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    #plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    if title != None:\n",
    "        plt.title(title, loc=\"left\", fontsize=20)\n",
    "    if filename != None:\n",
    "        plt.savefig(filename, dpi=1200, bbox_inches='tight')\n",
    "\n",
    "def lrr_plot(ensembles,\n",
    "             title=None,\n",
    "             filename=None,\n",
    "             cs = ['brown', 'green', 'red', 'blue'],\n",
    "             lss = [':', '--', '-.', ':'],\n",
    "             xs=np.linspace(4, 16, 1000)):\n",
    "             #xs=np.linspace(0, 20, 1000)):\n",
    "             #xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a list of pairs (lrr_avg, lrr_err). Plots them.\n",
    "    fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "    \n",
    "    # Plot ratios of likelihood ratios\n",
    "    for i in range(len(ensembles)):\n",
    "        avg, err, lbl = ensembles[i]\n",
    "        plt.plot(xs, avg, label=lbl, c=cs[i], ls=lss[i])\n",
    "        #plt.fill_between(xs, avg - err, avg + err, color=cs[i], alpha=0.1)\n",
    "    plt.axhline(1,ls=\":\",color=\"grey\", lw=0.5)\n",
    "    plt.axvline(0,ls=\":\",color=\"grey\", lw=0.5)\n",
    "    plt.legend()\n",
    "    ax_1.minorticks_on()\n",
    "    ax_1.tick_params(direction='in', which='both',length=5)\n",
    "    #plt.ylim(0.94, 1.06)\n",
    "    plt.ylabel('Ratio')\n",
    "\n",
    "    # Plot background and signal\n",
    "    ax_2 = ax_1.twinx()\n",
    "    bins = np.linspace(4, 16, 100)\n",
    "    #bins = np.linspace(0, 20, 100)\n",
    "    #bins = np.linspace(-6, 6, 100)\n",
    "    plt.hist(sgnl, alpha=0.1, bins=bins)\n",
    "    plt.hist(bkgd, alpha=0.1, bins=bins)\n",
    "    ax_2.minorticks_on()\n",
    "    ax_2.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.xlim(xs[0], xs[-1])\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(10.1)+r\", \\mu_{\\rm{bkgd}}=\"+str(9.9)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    #plt.title(r\"$r_{\\rm{sgnl}}=\"+str(r)+r\", r_{\\rm{bkgd}}=\"+str(r+1)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    #plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    if title != None:\n",
    "        plt.title(title, loc=\"left\", fontsize=20)\n",
    "    if filename != None:\n",
    "        plt.savefig(filename, dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# BCE $C$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "reps = 10\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':bce}\n",
    "params_2 = {'loss':square_bce, 'output':'linear'}\n",
    "params_3 = {'loss':exp_bce, 'output':'linear'}\n",
    "\n",
    "filestr_1 = 'models/bce_c_param/set_' + str(num) + '/linear/model_{}.h5'\n",
    "filestr_2 = 'models/bce_c_param/set_' + str(num) + '/square/model_{}.h5'\n",
    "filestr_3 = 'models/bce_c_param/set_' + str(num) + '/exp/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and save models\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1 = train(**params_1)\n",
    "    model_2 = train(**params_2)\n",
    "    model_3 = train(**params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = odds_lr(model_1)\n",
    "    lrs_2[i] = square_odds_lr(model_2)\n",
    "    lrs_3[i] = exp_odds_lr(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels for plotting.\n",
    "lr_1 = avg_lr(get_preds(lrs_1)) + ('BCE (linear)',)\n",
    "lr_2 = avg_lr(get_preds(lrs_2)) + ('BCE (square)',)\n",
    "lr_3 = avg_lr(get_preds(lrs_3)) + ('BCE (exponential)',)\n",
    "\n",
    "lrr_1 = avg_lrr(get_preds(lrs_1)) + ('BCE (linear)',)\n",
    "lrr_2 = avg_lrr(get_preds(lrs_2)) + ('BCE (square)',)\n",
    "lrr_3 = avg_lrr(get_preds(lrs_3)) + ('BCE (exponential)',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([lr_1, lr_2, lr_3], \n",
    "        r'BCE $C$ Parametrizations',\n",
    "        filename='plots/bce_c_param/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([lrr_1, lrr_2, lrr_3], \n",
    "         r'BCE $C$ Parametrizations',\n",
    "         filename='plots/bce_c_param/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MSE $C$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "reps = 10\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mse}\n",
    "params_2 = {'loss':square_mse, 'output':'linear'}\n",
    "params_3 = {'loss':exp_mse, 'output':'linear'}\n",
    "\n",
    "filestr_1 = 'models/mse_c_param/set_' + str(num) + '/linear/model_{}.h5'\n",
    "filestr_2 = 'models/mse_c_param/set_' + str(num) + '/square/model_{}.h5'\n",
    "filestr_3 = 'models/mse_c_param/set_' + str(num) + '/exp/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and save models\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1 = train(**params_1)\n",
    "    model_2 = train(**params_2)\n",
    "    model_3 = train(**params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = odds_lr(model_1)\n",
    "    lrs_2[i] = square_odds_lr(model_2)\n",
    "    lrs_3[i] = exp_odds_lr(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels for plotting.\n",
    "lr_1 = avg_lr(get_preds(lrs_1)) + ('MSE (linear)',)\n",
    "lr_2 = avg_lr(get_preds(lrs_2)) + ('MSE (square)',)\n",
    "lr_3 = avg_lr(get_preds(lrs_3)) + ('MSE (exponential)',)\n",
    "\n",
    "lrr_1 = avg_lrr(get_preds(lrs_1)) + ('MSE (linear)',)\n",
    "lrr_2 = avg_lrr(get_preds(lrs_2)) + ('MSE (square)',)\n",
    "lrr_3 = avg_lrr(get_preds(lrs_3)) + ('MSE (exponential)',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([lr_1, lr_2, lr_3], \n",
    "        r'MSE $C$ Parametrizations',\n",
    "        filename='plots/mse_c_param/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([lrr_1, lrr_2, lrr_3], \n",
    "         r'MSE $C$ Parametrizations',\n",
    "         filename='plots/mse_c_param/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MSE $A/B$ Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "reps = 20\n",
    "\n",
    "ps = np.round(np.linspace(-4, 4, 161), 2)\n",
    "filestr = 'models/mse_ab_param/set_' + str(num) + '/model_{}_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "for p in ps:\n",
    "    print('===================================================\\n{}'.format(p))\n",
    "    params = {'loss': get_mse(p)}\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        model = train(**params)\n",
    "        print()\n",
    "        model.save_weights(filestr.format(p, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-3.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-2.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-1.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "-0.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "0.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "1.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "2.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.05\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.1\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.15\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.2\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.25\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.3\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.35\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.4\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.45\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.5\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.55\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.6\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.65\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.7\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.75\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.8\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.85\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.9\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "3.95\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "4.0\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n"
     ]
    }
   ],
   "source": [
    "# Get model likelihood ratios.\n",
    "lrs = {}\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    lrs[p] = [None] * reps\n",
    "    params = {'loss': get_mse(p)}\n",
    "    for i in range(reps):\n",
    "        model = create_model(**params)\n",
    "        model.load_weights(filestr.format(p, i))\n",
    "        lrs[p][i] = pow_odds_lr(model, p) #### FIX THIS\n",
    "        print(i, end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.0 \t 0.06906919574512903\n",
      "-3.95 \t 0.05257000576769535\n",
      "-3.9 \t 0.06687772358732641\n",
      "-3.85 \t 0.05113345555262808\n",
      "-3.8 \t 0.056420037026493716\n",
      "-3.75 \t 0.05664230561087713\n",
      "-3.7 \t 0.059692975877954746\n",
      "-3.65 \t 0.06931089947487572\n",
      "-3.6 \t 0.06383319399423044\n",
      "-3.55 \t 0.06273278037863286\n",
      "-3.5 \t 0.06899615197854797\n",
      "-3.45 \t 0.04480291670620499\n",
      "-3.4 \t 0.05193485414669291\n",
      "-3.35 \t 0.0751082117963082\n",
      "-3.3 \t 0.05549052256557888\n",
      "-3.25 \t 0.03840253180980065\n",
      "-3.2 \t 0.06718263252543072\n",
      "-3.15 \t 0.04696627029687728\n",
      "-3.1 \t 0.0500906145874919\n",
      "-3.05 \t 0.05535536092380663\n",
      "-3.0 \t 0.045370710509028286\n",
      "-2.95 \t 0.06565896803083944\n",
      "-2.9 \t 0.06454801419660774\n",
      "-2.85 \t 0.062045507838054695\n",
      "-2.8 \t 0.054605905534392506\n",
      "-2.75 \t 0.04324223573028086\n",
      "-2.7 \t 0.04600806262327982\n",
      "-2.65 \t 0.05479644683331788\n",
      "-2.6 \t 0.04466270530519327\n",
      "-2.55 \t 0.05576491211450366\n",
      "-2.5 \t 0.05256785222813395\n",
      "-2.45 \t 0.06155693311860148\n",
      "-2.4 \t 0.05327625966192483\n",
      "-2.35 \t 0.05526793354854072\n",
      "-2.3 \t 0.044112106996447006\n",
      "-2.25 \t 0.06800314365209703\n",
      "-2.2 \t 0.04852584985038422\n",
      "-2.15 \t 0.059272894755196516\n",
      "-2.1 \t 0.047900634759022294\n",
      "-2.05 \t 0.04547401548919079\n",
      "-2.0 \t 0.04448705504078578\n",
      "-1.95 \t 0.058782747794329474\n",
      "-1.9 \t 0.04667320459616708\n",
      "-1.85 \t 0.04518511200664123\n",
      "-1.8 \t 0.05257184481815628\n",
      "-1.75 \t 0.04812471917925637\n",
      "-1.7 \t 0.06007728120758562\n",
      "-1.65 \t 0.052904589937591416\n",
      "-1.6 \t 0.04838205042575442\n",
      "-1.55 \t 0.05276016922133564\n",
      "-1.5 \t 0.0420711488799429\n",
      "-1.45 \t 0.04305687532095364\n",
      "-1.4 \t 0.0469569653859536\n",
      "-1.35 \t 0.039452996042455835\n",
      "-1.3 \t 0.04599997330353741\n",
      "-1.25 \t 0.041860335432972816\n",
      "-1.2 \t 0.04420240355029896\n",
      "-1.15 \t 0.05417538675436808\n",
      "-1.1 \t 0.044419327641710846\n",
      "-1.05 \t 0.04126715855761438\n",
      "-1.0 \t 0.04250983556461069\n",
      "-0.95 \t 0.04478011190690772\n",
      "-0.9 \t 0.03587664103843647\n",
      "-0.85 \t 0.03924484998457149\n",
      "-0.8 \t 0.048685518582090484\n",
      "-0.75 \t 0.044288155728096926\n",
      "-0.7 \t 0.03844082821423679\n",
      "-0.65 \t 0.03887094256347465\n",
      "-0.6 \t 0.031732003303025016\n",
      "-0.55 \t 0.029580728166834453\n",
      "-0.5 \t 0.03485933713031121\n",
      "-0.45 \t 0.02509859398859704\n",
      "-0.4 \t 0.030070043992827655\n",
      "-0.35 \t 0.0374938748697548\n",
      "-0.3 \t 0.028533455436929023\n",
      "-0.25 \t 0.030065139991763034\n",
      "-0.2 \t 0.034189917012510354\n",
      "-0.15 \t 0.03228685793375808\n",
      "-0.1 \t 0.01907655372700816\n",
      "-0.05 \t 0.017861236351795616\n",
      "0.0 \t 0.6666326135584557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4238/2724782075.py:138: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.squeeze( (f / (1. - f))**(p - 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 \t 1.6349590501313505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4238/2724782075.py:138: RuntimeWarning: divide by zero encountered in power\n",
      "  return np.squeeze( (f / (1. - f))**(p - 1))\n",
      "/global/home/users/shahzar/anaconda3/envs/omnifold/lib/python3.8/site-packages/numpy/core/_methods.py:229: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 \t inf\n",
      "0.15 \t inf\n",
      "0.2 \t 1.6349590501313505\n",
      "0.25 \t inf\n",
      "0.3 \t 1.6349590501313505\n",
      "0.35 \t 1.6349590501313505\n",
      "0.4 \t 1.6349590501313505\n",
      "0.45 \t 1.6349590501313505\n",
      "0.5 \t 1.6349590501313505\n",
      "0.55 \t 1.6349590501313505\n",
      "0.6 \t 1.6349590501313505\n",
      "0.65 \t 1.6349590501313505\n",
      "0.7 \t 1.6349590501313505\n",
      "0.75 \t 1.634958942541823\n",
      "0.8 \t 1.6349588938813315\n",
      "0.85 \t 1.6349590501313505\n",
      "0.9 \t 1.6349509152220782\n",
      "0.95 \t 1.6348826772100324\n",
      "1.0 \t 0.6349590501313501\n",
      "1.05 \t inf\n",
      "1.1 \t inf\n",
      "1.15 \t 0.018438101142297388\n",
      "1.2 \t 0.014073920868217571\n",
      "1.25 \t 0.01039561313961674\n",
      "1.3 \t 0.01116933037834748\n",
      "1.35 \t 0.011651194162224633\n",
      "1.4 \t 0.01187268541306603\n",
      "1.45 \t 0.013412783606304619\n",
      "1.5 \t 0.016729164636136152\n",
      "1.55 \t 0.012159104284452786\n",
      "1.6 \t 0.01597480781740581\n",
      "1.65 \t 0.017683456650582966\n",
      "1.7 \t 0.016394661853159957\n",
      "1.75 \t 0.012651364559162662\n",
      "1.8 \t 0.018016711608694204\n",
      "1.85 \t 0.01900655175279651\n",
      "1.9 \t 0.021996275080034718\n",
      "1.95 \t 0.02235744309351705\n",
      "2.0 \t 0.01589668912971206\n",
      "2.05 \t 0.03018043063963404\n",
      "2.1 \t 0.01837805929149052\n",
      "2.15 \t 0.0345113847842831\n",
      "2.2 \t 0.026252357295539725\n",
      "2.25 \t 0.041111062293477954\n",
      "2.3 \t 0.03677255431807252\n",
      "2.35 \t 0.025230227725572513\n",
      "2.4 \t 0.031120792210967568\n",
      "2.45 \t 0.037418570625497256\n",
      "2.5 \t 0.037324675424559084\n",
      "2.55 \t 0.03674313474659387\n",
      "2.6 \t 0.03951248522775149\n",
      "2.65 \t 0.03125141125736255\n",
      "2.7 \t 0.0395857375070813\n",
      "2.75 \t 0.049860288235104674\n",
      "2.8 \t 0.03751315566772319\n",
      "2.85 \t 0.037321651354600645\n",
      "2.9 \t 0.03978748016869016\n",
      "2.95 \t 0.0384178838266523\n",
      "3.0 \t 0.03477905870687997\n",
      "3.05 \t 0.03185488281014283\n",
      "3.1 \t 0.04584572130169724\n",
      "3.15 \t 0.04714014610684812\n",
      "3.2 \t 0.046294601916330336\n",
      "3.25 \t 0.040576251039289774\n",
      "3.3 \t 0.04753680897422813\n",
      "3.35 \t 0.039397267335844144\n",
      "3.4 \t 0.053953676246679\n",
      "3.45 \t 0.04031771447171156\n",
      "3.5 \t 0.03199452572434407\n",
      "3.55 \t 0.050085777678416696\n",
      "3.6 \t 0.05794043123245879\n",
      "3.65 \t 0.05626700037561624\n",
      "3.7 \t 0.04300583878614016\n",
      "3.75 \t 0.04091440581546128\n",
      "3.8 \t 0.04608146983862667\n",
      "3.85 \t 0.04477318462009234\n",
      "3.9 \t 0.051773022033460445\n",
      "3.95 \t 0.04829926422761183\n",
      "4.0 \t 0.04879267752166595\n"
     ]
    }
   ],
   "source": [
    "mae_avg = []\n",
    "mae_err = []\n",
    "\n",
    "for p in ps:\n",
    "    maes = [mae(lr) for lr in lrs[p]]\n",
    "    mae_avg += [np.mean(maes)]\n",
    "    mae_err += [np.std(maes)]\n",
    "    print(p, '\\t', mae_avg[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_avg = np.array(mae_avg)\n",
    "mae_err = np.array(mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(ps, mae_avg, c='blue')\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$p$')\n",
    "\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",\n",
    "          loc=\"right\",\n",
    "          fontsize=20);\n",
    "plt.title(r\"MSE $A/B$ Parametrization\",loc=\"left\",fontsize=20);\n",
    "plt.savefig('plots/mse_ab_param/set_{}/maes.png'.format(num), \n",
    "            dpi=1200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MLC $C$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mlc, 'output':'relu'}\n",
    "params_2 = {'loss':square_mlc, 'output':'linear'}\n",
    "params_3 = {'loss':exp_mlc, 'output':'linear'}\n",
    "\n",
    "filestr_1 = 'models/mlc_c_param/set_' + str(num) + '/linear/model_{}.h5'\n",
    "filestr_2 = 'models/mlc_c_param/set_' + str(num) + '/square/model_{}.h5'\n",
    "filestr_3 = 'models/mlc_c_param/set_' + str(num) + '/exp/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and save models\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1 = train(**params_1)\n",
    "    model_2 = train(**params_2)\n",
    "    model_3 = train(**params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1)\n",
    "    lrs_2[i] = square_lr(model_2)\n",
    "    lrs_3[i] = exp_lr(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels for plotting.\n",
    "lr_1 = avg_lr(get_preds(lrs_1)) + ('MLC (linear)',)\n",
    "lr_2 = avg_lr(get_preds(lrs_2)) + ('MLC (square)',)\n",
    "lr_3 = avg_lr(get_preds(lrs_3)) + ('MLC (exponential)',)\n",
    "\n",
    "lrr_1 = avg_lrr(get_preds(lrs_1)) + ('MLC (linear)',)\n",
    "lrr_2 = avg_lrr(get_preds(lrs_2)) + ('MLC (square)',)\n",
    "lrr_3 = avg_lrr(get_preds(lrs_3)) + ('MLC (exponential)',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_plot([lr_1, lr_2, lr_3], \n",
    "        r'MLC $C$ Parametrizations',\n",
    "        filename='plots/mlc_c_param/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([lrr_1, lrr_2, lrr_3], \n",
    "         r'MLC $C$ Parametrizations',\n",
    "         filename='plots/mlc_c_param/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# SQR $C$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':sqr, 'output':'relu'}\n",
    "params_2 = {'loss':square_sqr, 'output':'linear'}\n",
    "params_3 = {'loss':exp_sqr, 'output':'linear'}\n",
    "\n",
    "filestr_1 = 'models/sqr_c_param/set_' + str(num) + '/linear/model_{}.h5'\n",
    "filestr_2 = 'models/sqr_c_param/set_' + str(num) + '/square/model_{}.h5'\n",
    "filestr_3 = 'models/sqr_c_param/set_' + str(num) + '/exp/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and save models\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1 = train(**params_1)\n",
    "    model_2 = train(**params_2)\n",
    "    model_3 = train(**params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1)\n",
    "    lrs_2[i] = square_lr(model_2)\n",
    "    lrs_3[i] = exp_lr(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels to \n",
    "# make plotting easier.\n",
    "lr_1 = avg_lr(get_preds(lrs_1)) + ('SQR (linear)',)\n",
    "lr_2 = avg_lr(get_preds(lrs_2)) + ('SQR (square)',)\n",
    "lr_3 = avg_lr(get_preds(lrs_3)) + ('SQR (exp)',)\n",
    "\n",
    "lrr_1 = avg_lrr(get_preds(lrs_1)) + ('SQR (linear)',)\n",
    "lrr_2 = avg_lrr(get_preds(lrs_2)) + ('SQR (square)',)\n",
    "lrr_3 = avg_lrr(get_preds(lrs_3)) + ('SQR (exponential)',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([lr_1, lr_2, lr_3], \n",
    "        title=r'SQR $C$ Parametrizations',\n",
    "        filename='plots/sqr_c_param/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrr_plot([lrr_1, lrr_2, lrr_3], \n",
    "         title=r'SQR $C$ Parametrizations',\n",
    "         filename='plots/sqr_c_param/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# SQR $A$/$B$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "reps = 20\n",
    "\n",
    "ps = np.round(np.linspace(-2, 2, 81), 2)\n",
    "sqr_filestr = 'models/sqr_ab_param/set_' + str(num) + '/linear/model_{}_{}.h5'\n",
    "exp_filestr = 'models/sqr_ab_param/set_' + str(num) + '/exp/model_{}_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "for p in ps:\n",
    "    print('===================================================\\n{}'.format(p))\n",
    "    sqr_params = {'loss': get_sqr(p), 'output':'relu'}\n",
    "    exp_params = {'loss': get_exp_sqr(p), 'output':'linear'}\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        sqr_model = train(**sqr_params)\n",
    "        exp_model = train(**exp_params)\n",
    "        print()\n",
    "        sqr_model.save_weights(sqr_filestr.format(p, i))\n",
    "        exp_model.save_weights(exp_filestr.format(p, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "sqr_lrs = {}\n",
    "exp_lrs = {}\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    sqr_lrs[p] = [None] * reps\n",
    "    exp_lrs[p] = [None] * reps\n",
    "    sqr_params = {'loss': get_sqr(p), 'output':'relu'}\n",
    "    exp_params = {'loss': get_exp_sqr(p), 'output':'linear'}\n",
    "    for i in range(reps):\n",
    "        sqr_model = create_model(**sqr_params)\n",
    "        exp_model = create_model(**exp_params)\n",
    "        sqr_model.load_weights(sqr_filestr.format(p, i))\n",
    "        exp_model.load_weights(exp_filestr.format(p, i))\n",
    "        sqr_lrs[p][i] = pow_lr(sqr_model, p)\n",
    "        exp_lrs[p][i] = exp_pow_lr(exp_model, p)\n",
    "        print(i, end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sqr_mae_avg = []\n",
    "sqr_mae_err = []\n",
    "exp_mae_avg = []\n",
    "exp_mae_err = []\n",
    "\n",
    "for p in ps:\n",
    "    sqr_maes = [mae(lr) for lr in sqr_lrs[p]]\n",
    "    exp_maes = [mae(lr) for lr in exp_lrs[p]]\n",
    "    sqr_mae_avg += [np.mean(sqr_maes)]\n",
    "    sqr_mae_err += [np.std(sqr_maes)]\n",
    "    exp_mae_avg += [np.mean(exp_maes)]\n",
    "    exp_mae_err += [np.std(exp_maes)]\n",
    "    print(p, '\\t', sqr_mae_avg[-1], '\\t', exp_mae_avg[-1])\n",
    "    print(p, '\\t', sqr_mae_avg[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqr_mae_avg = np.array(sqr_mae_avg)\n",
    "sqr_mae_err = np.array(sqr_mae_err)\n",
    "exp_mae_avg = np.array(exp_mae_avg)\n",
    "exp_mae_err = np.array(exp_mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(ps, sqr_mae_avg, c='blue', label='linear')\n",
    "plt.plot(ps, exp_mae_avg, c='red', label='exponential')\n",
    "plt.legend()\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$p$')\n",
    "\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",\n",
    "          loc=\"right\",\n",
    "          fontsize=20);\n",
    "plt.title(r\"SQR $A/B$ Parametrization\",loc=\"left\",fontsize=20);\n",
    "plt.savefig('plots/sqr_ab_param/set_{}/maes.png'.format(num), \n",
    "            dpi=1200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "reps = 100\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce}\n",
    "mse_params = {'loss':mse}\n",
    "mlc_params = {'loss':exp_mlc, 'output':'linear'}\n",
    "sqr_params = {'loss':exp_sqr, 'output':'linear'}\n",
    "\n",
    "bce_filestr = 'models/loss_comp/set_' + str(num) + '/bce/model_{}_{}.h5'\n",
    "mse_filestr = 'models/loss_comp/set_' + str(num) + '/mse/model_{}_{}.h5'\n",
    "mlc_filestr = 'models/loss_comp/set_' + str(num) + '/mlc/model_{}_{}.h5'\n",
    "sqr_filestr = 'models/loss_comp/set_' + str(num) + '/sqr/model_{}_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "%%time\n",
    "\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Generate data\n",
    "    bkgd = np.random.normal(-mu, sigma, N)\n",
    "    sgnl = np.random.normal(mu, sigma, N)\n",
    "    X = np.concatenate([bkgd, sgnl])\n",
    "    y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        bce_model = train(**bce_params)\n",
    "        mse_model = train(**mse_params)\n",
    "        mlc_model = train(**mlc_params)\n",
    "        sqr_model = train(**sqr_params)\n",
    "        print()\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        mse_model.save_weights(mse_filestr.format(N, i))\n",
    "        mlc_model.save_weights(mlc_filestr.format(N, i))\n",
    "        sqr_model.save_weights(sqr_filestr.format(N, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute errors\n",
    "bce_mae_avg = []\n",
    "mse_mae_avg = []\n",
    "mlc_mae_avg = []\n",
    "sqr_mae_avg = []\n",
    "\n",
    "bce_mae_err = []\n",
    "mse_mae_err = []\n",
    "mlc_mae_err = []\n",
    "sqr_mae_err = []\n",
    "\n",
    "for N in Ns:\n",
    "    print(N)\n",
    "    bce_lrs = [None] * reps\n",
    "    mse_lrs = [None] * reps\n",
    "    mlc_lrs = [None] * reps\n",
    "    sqr_lrs = [None] * reps\n",
    "    for i in range(reps):\n",
    "        bce_model = create_model(**bce_params)\n",
    "        bce_model.load_weights(bce_filestr.format(N, i))\n",
    "        bce_lrs[i] = odds_lr(bce_model)\n",
    "\n",
    "        mse_model = create_model(**mse_params)\n",
    "        mse_model.load_weights(mse_filestr.format(N, i))\n",
    "        mse_lrs[i] = odds_lr(mse_model)\n",
    "\n",
    "        mlc_model = create_model(**mlc_params)\n",
    "        mlc_model.load_weights(mlc_filestr.format(N, i))\n",
    "        mlc_lrs[i] = exp_lr(mlc_model)\n",
    "\n",
    "        sqr_model = create_model(**sqr_params)\n",
    "        sqr_model.load_weights(sqr_filestr.format(N, i))\n",
    "        sqr_lrs[i] = exp_lr(sqr_model)\n",
    "    \n",
    "    bce_maes = [mae(lr) for lr in bce_lrs]\n",
    "    mse_maes = [mae(lr) for lr in mse_lrs]\n",
    "    mlc_maes = [mae(lr) for lr in mlc_lrs]\n",
    "    sqr_maes = [mae(lr) for lr in sqr_lrs]\n",
    "    \n",
    "    bce_mae_avg += [np.mean(bce_maes)]\n",
    "    bce_mae_err += [np.std(bce_maes)]\n",
    "    \n",
    "    mse_mae_avg += [np.mean(mse_maes)]\n",
    "    mse_mae_err += [np.std(mse_maes)]\n",
    "    \n",
    "    mlc_mae_avg += [np.mean(mlc_maes)]\n",
    "    mlc_mae_err += [np.std(mlc_maes)]\n",
    "    \n",
    "    sqr_mae_avg += [np.mean(sqr_maes)]\n",
    "    sqr_mae_err += [np.std(sqr_maes)]\n",
    "\n",
    "bce_mae_avg = np.array(bce_mae_avg)\n",
    "mse_mae_avg = np.array(mse_mae_avg)\n",
    "mlc_mae_avg = np.array(mlc_mae_avg)\n",
    "sqr_mae_avg = np.array(sqr_mae_avg)\n",
    "\n",
    "bce_mae_err = np.array(bce_mae_err)\n",
    "mse_mae_err = np.array(mse_mae_err)\n",
    "mlc_mae_err = np.array(mlc_mae_err)\n",
    "sqr_mae_err = np.array(sqr_mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(Ns, bce_mae_avg, c='brown', ls=':', label='BCE')\n",
    "plt.plot(Ns, mse_mae_avg, c='green', ls='--', label='MSE')\n",
    "plt.plot(Ns, mlc_mae_avg, c='red', ls='--', label='MLC')\n",
    "plt.plot(Ns, sqr_mae_avg, c='blue', ls='-.', label='SQR')\n",
    "#plt.fill_between(Ns, bce_mae_avg - bce_mae_err, bce_mae_avg + bce_mae_err, color='brown', alpha=0.1)\n",
    "#plt.fill_between(Ns, mse_mae_avg - mse_mae_err, mse_mae_avg + mse_mae_err, color='green', alpha=0.1)\n",
    "#plt.fill_between(Ns, mlc_mae_avg - mlc_mae_err, mlc_mae_avg + mlc_mae_err, color='red', alpha=0.1)\n",
    "#plt.fill_between(Ns, sqr_mae_avg - sqr_mae_err, sqr_mae_avg + sqr_mae_err, color='blue', alpha=0.1)\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\", base=10)\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$N$')\n",
    "\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",\n",
    "          loc=\"right\",\n",
    "          fontsize=20);\n",
    "plt.savefig('plots/loss_comp/set_{}/maes.png'.format(num),\n",
    "            dpi=1200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Likelihood Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10**6\n",
    "reps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in models.\n",
    "bce_lrs = [None] * reps\n",
    "mse_lrs = [None] * reps\n",
    "mlc_lrs = [None] * reps\n",
    "sqr_lrs = [None] * reps\n",
    "for i in range(reps):\n",
    "    bce_model = create_model(**bce_params)\n",
    "    bce_model.load_weights(bce_filestr.format(N, i))\n",
    "    bce_lrs[i] = odds_lr(bce_model)\n",
    "    \n",
    "    mse_model = create_model(**mse_params)\n",
    "    mse_model.load_weights(mse_filestr.format(N, i))\n",
    "    mse_lrs[i] = odds_lr(mse_model)\n",
    "    \n",
    "    mlc_model = create_model(**mlc_params)\n",
    "    mlc_model.load_weights(mlc_filestr.format(N, i))\n",
    "    mlc_lrs[i] = exp_lr(mlc_model)\n",
    "    \n",
    "    sqr_model = create_model(**sqr_params)\n",
    "    sqr_model.load_weights(sqr_filestr.format(N, i))\n",
    "    sqr_lrs[i] = exp_lr(sqr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_lr = avg_lr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lr = avg_lr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lr = avg_lr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lr = avg_lr(get_preds(sqr_lrs)) + ('SQR',)\n",
    "\n",
    "bce_lrr = avg_lrr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lrr = avg_lrr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lrr = avg_lrr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lrr = avg_lrr(get_preds(sqr_lrs)) + ('SQR',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([bce_lr, mse_lr, mlc_lr, sqr_lr], \n",
    "        filename='plots/loss_comp/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrr_plot([bce_lrr, mse_lrr, mlc_lrr, sqr_lrr], \n",
    "         filename='plots/loss_comp/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_mae = np.mean([mae(lr) for lr in bce_lrs])\n",
    "mse_mae = np.mean([mae(lr) for lr in mse_lrs])\n",
    "mlc_mae = np.mean([mae(lr) for lr in mlc_lrs])\n",
    "sqr_mae = np.mean([mae(lr) for lr in sqr_lrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bce_mae, mse_mae, mlc_mae, sqr_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Interpolation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5\n",
    "N = 10**6\n",
    "mus = np.round(np.linspace(0.1, 1.5, 15), 2)\n",
    "sigma = 1\n",
    "\n",
    "reps = 50\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'verbose':0}\n",
    "mse_params = {'loss':mse, 'verbose':0}\n",
    "mlc_params = {'loss':exp_mlc, 'output':'linear', 'verbose':0}\n",
    "sqr_params = {'loss':exp_sqr, 'output':'linear', 'verbose':0}\n",
    "\n",
    "bce_filestr = 'models/interp/set_' + str(num) + '/bce/model_{}_{}.h5'\n",
    "mse_filestr = 'models/interp/set_' + str(num) + '/mse/model_{}_{}.h5'\n",
    "mlc_filestr = 'models/interp/set_' + str(num) + '/mlc/model_{}_{}.h5'\n",
    "sqr_filestr = 'models/interp/set_' + str(num) + '/sqr/model_{}_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for mu in mus:\n",
    "    print('===================================================\\n{}'.format(mu))\n",
    "    # Generate data\n",
    "    bkgd = np.random.normal(-mu, sigma, N)\n",
    "    sgnl = np.random.normal(mu, sigma, N)\n",
    "    X = np.concatenate([bkgd, sgnl])\n",
    "    y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        bce_model = train(**bce_params)\n",
    "        mse_model = train(**mse_params)\n",
    "        mlc_model = train(**mlc_params)\n",
    "        sqr_model = train(**sqr_params)\n",
    "        print()\n",
    "        bce_model.save_weights(bce_filestr.format(mu, i))\n",
    "        mse_model.save_weights(mse_filestr.format(mu, i))\n",
    "        mlc_model.save_weights(mlc_filestr.format(mu, i))\n",
    "        sqr_model.save_weights(sqr_filestr.format(mu, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Expected Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute errors\n",
    "bce_mae_avg = []\n",
    "mse_mae_avg = []\n",
    "mlc_mae_avg = []\n",
    "sqr_mae_avg = []\n",
    "\n",
    "bce_mae_err = []\n",
    "mse_mae_err = []\n",
    "mlc_mae_err = []\n",
    "sqr_mae_err = []\n",
    "\n",
    "bce_mpe_avg = []\n",
    "mse_mpe_avg = []\n",
    "mlc_mpe_avg = []\n",
    "sqr_mpe_avg = []\n",
    "\n",
    "bce_mpe_err = []\n",
    "mse_mpe_err = []\n",
    "mlc_mpe_err = []\n",
    "sqr_mpe_err = []\n",
    "\n",
    "for mu in mus:\n",
    "    print(mu)\n",
    "    bce_lrs = [None] * reps\n",
    "    mse_lrs = [None] * reps\n",
    "    mlc_lrs = [None] * reps\n",
    "    sqr_lrs = [None] * reps\n",
    "    for i in range(reps):\n",
    "        bce_model = create_model(**bce_params)\n",
    "        bce_model.load_weights(bce_filestr.format(mu, i))\n",
    "        bce_lrs[i] = odds_lr(bce_model)\n",
    "\n",
    "        mse_model = create_model(**mse_params)\n",
    "        mse_model.load_weights(mse_filestr.format(mu, i))\n",
    "        mse_lrs[i] = odds_lr(mse_model)\n",
    "\n",
    "        mlc_model = create_model(**mlc_params)\n",
    "        mlc_model.load_weights(mlc_filestr.format(mu, i))\n",
    "        mlc_lrs[i] = exp_lr(mlc_model)\n",
    "\n",
    "        sqr_model = create_model(**sqr_params)\n",
    "        sqr_model.load_weights(sqr_filestr.format(mu, i))\n",
    "        sqr_lrs[i] = exp_lr(sqr_model)\n",
    "    \n",
    "    mae = make_mae(mu, sigma)\n",
    "    bce_maes = [mae(lr) for lr in bce_lrs]\n",
    "    mse_maes = [mae(lr) for lr in mse_lrs]\n",
    "    mlc_maes = [mae(lr) for lr in mlc_lrs]\n",
    "    sqr_maes = [mae(lr) for lr in sqr_lrs]\n",
    "    \n",
    "    bce_mae_avg += [np.mean(bce_maes)]\n",
    "    bce_mae_err += [np.std(bce_maes)]\n",
    "    \n",
    "    mse_mae_avg += [np.mean(mse_maes)]\n",
    "    mse_mae_err += [np.std(mse_maes)]\n",
    "    \n",
    "    mlc_mae_avg += [np.mean(mlc_maes)]\n",
    "    mlc_mae_err += [np.std(mlc_maes)]\n",
    "    \n",
    "    sqr_mae_avg += [np.mean(sqr_maes)]\n",
    "    sqr_mae_err += [np.std(sqr_maes)]\n",
    "    \n",
    "    print(bce_mae_avg[-1], mse_mae_avg[-1], mlc_mae_avg[-1], sqr_mae_avg[-1])\n",
    "    \n",
    "    mpe = make_mpe(mu, sigma)\n",
    "    bce_mpes = [mpe(lr) for lr in bce_lrs]\n",
    "    mse_mpes = [mpe(lr) for lr in mse_lrs]\n",
    "    mlc_mpes = [mpe(lr) for lr in mlc_lrs]\n",
    "    sqr_mpes = [mpe(lr) for lr in sqr_lrs]\n",
    "    \n",
    "    bce_mpe_avg += [np.mean(bce_mpes)]\n",
    "    bce_mpe_err += [np.std(bce_mpes)]\n",
    "    \n",
    "    mse_mpe_avg += [np.mean(mse_mpes)]\n",
    "    mse_mpe_err += [np.std(mse_mpes)]\n",
    "    \n",
    "    mlc_mpe_avg += [np.mean(mlc_mpes)]\n",
    "    mlc_mpe_err += [np.std(mlc_mpes)]\n",
    "    \n",
    "    sqr_mpe_avg += [np.mean(sqr_mpes)]\n",
    "    sqr_mpe_err += [np.std(sqr_mpes)]\n",
    "    \n",
    "    print(bce_mpe_avg[-1], mse_mpe_avg[-1], mlc_mpe_avg[-1], sqr_mpe_avg[-1])\n",
    "\n",
    "bce_mae_avg = np.array(bce_mae_avg)\n",
    "mse_mae_avg = np.array(mse_mae_avg)\n",
    "mlc_mae_avg = np.array(mlc_mae_avg)\n",
    "sqr_mae_avg = np.array(sqr_mae_avg)\n",
    "\n",
    "bce_mae_err = np.array(bce_mae_err)\n",
    "mse_mae_err = np.array(mse_mae_err)\n",
    "mlc_mae_err = np.array(mlc_mae_err)\n",
    "sqr_mae_err = np.array(sqr_mae_err)\n",
    "\n",
    "bce_mpe_avg = np.array(bce_mpe_avg)\n",
    "mse_mpe_avg = np.array(mse_mpe_avg)\n",
    "mlc_mpe_avg = np.array(mlc_mpe_avg)\n",
    "sqr_mpe_avg = np.array(sqr_mpe_avg)\n",
    "\n",
    "bce_mpe_err = np.array(bce_mpe_err)\n",
    "mse_mpe_err = np.array(mse_mpe_err)\n",
    "mlc_mpe_err = np.array(mlc_mpe_err)\n",
    "sqr_mpe_err = np.array(sqr_mpe_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(mus, bce_mae_avg, c='brown', ls=':', label='BCE')\n",
    "plt.plot(mus, mse_mae_avg, c='green', ls='--', label='MSE')\n",
    "plt.plot(mus, mlc_mae_avg, c='red', ls='--', label='MLC')\n",
    "plt.plot(mus, sqr_mae_avg, c='blue', ls='-.', label='SQR')\n",
    "plt.legend()\n",
    "\n",
    "plt.yscale(\"log\", basey=10)\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$\\mu$')\n",
    "\n",
    "plt.savefig('plots/interp/set_{}/maes.png'.format(num),\n",
    "            dpi=1200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(mus, bce_mpe_avg, c='brown', ls=':', label='BCE')\n",
    "plt.plot(mus, mse_mpe_avg, c='green', ls='--', label='MSE')\n",
    "plt.plot(mus, mlc_mpe_avg, c='red', ls='--', label='MLC')\n",
    "plt.plot(mus, sqr_mpe_avg, c='blue', ls='-.', label='SQR')\n",
    "plt.legend()\n",
    "#plt.ylim(0, 5)\n",
    "\n",
    "#plt.xscale(\"log\", base=10)\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Percent Error (\\%)')\n",
    "plt.xlabel(r'$\\mu$')\n",
    "\n",
    "plt.savefig('plots/interp/set_{}/mpes.png'.format(num),\n",
    "            dpi=1200, \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Single Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-4, 4, 1000)\n",
    "bce_lr = avg_lr(get_preds(bce_lrs, xs)) + ('BCE',)\n",
    "mse_lr = avg_lr(get_preds(mse_lrs, xs)) + ('MSE',)\n",
    "mlc_lr = avg_lr(get_preds(mlc_lrs, xs)) + ('MLC',)\n",
    "sqr_lr = avg_lr(get_preds(sqr_lrs, xs)) + ('SQR',)\n",
    "\n",
    "bce_lrr = avg_lrr(get_preds(bce_lrs, xs), xs) + ('BCE',)\n",
    "mse_lrr = avg_lrr(get_preds(mse_lrs, xs), xs) + ('MSE',)\n",
    "mlc_lrr = avg_lrr(get_preds(mlc_lrs, xs), xs) + ('MLC',)\n",
    "sqr_lrr = avg_lrr(get_preds(sqr_lrs, xs), xs) + ('SQR',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([bce_lr, mse_lr, mlc_lr, sqr_lr], \n",
    "        xs=xs,\n",
    "        filename='plots/interp/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([bce_lrr, mse_lrr, mlc_lrr, sqr_lrr], \n",
    "         xs=xs,\n",
    "         filename='plots/interp/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Loss Comparison for Gamma Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "reps = 20\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce}\n",
    "mse_params = {'loss':mse}\n",
    "mlc_params = {'loss':exp_mlc, 'output':'linear'}\n",
    "sqr_params = {'loss':exp_sqr, 'output':'linear'}\n",
    "\n",
    "bce_filestr = 'models/scratch/set_' + str(num) + '/bce/model_{}.h5'\n",
    "mse_filestr = 'models/scratch/set_' + str(num) + '/mse/model_{}.h5'\n",
    "mlc_filestr = 'models/scratch/set_' + str(num) + '/mlc/model_{}.h5'\n",
    "sqr_filestr = 'models/scratch/set_' + str(num) + '/sqr/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    bce_model = train(**bce_params)\n",
    "    mse_model = train(**mse_params)\n",
    "    mlc_model = train(**mlc_params)\n",
    "    sqr_model = train(**sqr_params)\n",
    "    print()\n",
    "    bce_model.save_weights(bce_filestr.format(i))\n",
    "    mse_model.save_weights(mse_filestr.format(i))\n",
    "    mlc_model.save_weights(mlc_filestr.format(i))\n",
    "    sqr_model.save_weights(sqr_filestr.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in models.\n",
    "bce_lrs = [None] * reps\n",
    "mse_lrs = [None] * reps\n",
    "mlc_lrs = [None] * reps\n",
    "sqr_lrs = [None] * reps\n",
    "for i in range(reps):\n",
    "    bce_model = create_model(**bce_params)\n",
    "    bce_model.load_weights(bce_filestr.format(i))\n",
    "    bce_lrs[i] = odds_lr(bce_model)\n",
    "    \n",
    "    mse_model = create_model(**mse_params)\n",
    "    mse_model.load_weights(mse_filestr.format(i))\n",
    "    mse_lrs[i] = odds_lr(mse_model)\n",
    "    \n",
    "    mlc_model = create_model(**mlc_params)\n",
    "    mlc_model.load_weights(mlc_filestr.format(i))\n",
    "    mlc_lrs[i] = exp_lr(mlc_model)\n",
    "    \n",
    "    sqr_model = create_model(**sqr_params)\n",
    "    sqr_model.load_weights(sqr_filestr.format(i))\n",
    "    sqr_lrs[i] = exp_lr(sqr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_lr = avg_lr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lr = avg_lr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lr = avg_lr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lr = avg_lr(get_preds(sqr_lrs)) + ('SQR',)\n",
    "\n",
    "bce_lrr = avg_lrr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lrr = avg_lrr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lrr = avg_lrr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lrr = avg_lrr(get_preds(sqr_lrs)) + ('SQR',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([bce_lr, mse_lr, mlc_lr, sqr_lr], \n",
    "        filename='plots/scratch/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([bce_lrr, mse_lrr, mlc_lrr, sqr_lrr], \n",
    "         filename='plots/scratch/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Test on Non-Zero-Centered Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 10**6\n",
    "mu = 10\n",
    "d = 0.1\n",
    "sigma = 1\n",
    "\n",
    "# Background is Normal(μ - d, σ). Signal is Normal(μ + d, σ))\n",
    "bkgd = np.random.normal(mu - d, sigma, N)\n",
    "sgnl = np.random.normal(mu + d, sigma, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(x):\n",
    "    return np.exp(-(1/(2 * sigma**2)) * ( (x - 10.1)**2 - (x - 9.9)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 2\n",
    "reps = 20\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce}\n",
    "mse_params = {'loss':mse}\n",
    "mlc_params = {'loss':exp_mlc, 'output':'linear'}\n",
    "sqr_params = {'loss':exp_sqr, 'output':'linear'}\n",
    "\n",
    "bce_filestr = 'models/scratch/set_' + str(num) + '/bce/model_{}.h5'\n",
    "mse_filestr = 'models/scratch/set_' + str(num) + '/mse/model_{}.h5'\n",
    "mlc_filestr = 'models/scratch/set_' + str(num) + '/mlc/model_{}.h5'\n",
    "sqr_filestr = 'models/scratch/set_' + str(num) + '/sqr/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    bce_model = train(**bce_params)\n",
    "    mse_model = train(**mse_params)\n",
    "    mlc_model = train(**mlc_params)\n",
    "    sqr_model = train(**sqr_params)\n",
    "    print()\n",
    "    bce_model.save_weights(bce_filestr.format(i))\n",
    "    mse_model.save_weights(mse_filestr.format(i))\n",
    "    mlc_model.save_weights(mlc_filestr.format(i))\n",
    "    sqr_model.save_weights(sqr_filestr.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in models.\n",
    "bce_lrs = [None] * reps\n",
    "mse_lrs = [None] * reps\n",
    "mlc_lrs = [None] * reps\n",
    "sqr_lrs = [None] * reps\n",
    "for i in range(reps):\n",
    "    bce_model = create_model(**bce_params)\n",
    "    bce_model.load_weights(bce_filestr.format(i))\n",
    "    bce_lrs[i] = odds_lr(bce_model)\n",
    "    \n",
    "    mse_model = create_model(**mse_params)\n",
    "    mse_model.load_weights(mse_filestr.format(i))\n",
    "    mse_lrs[i] = odds_lr(mse_model)\n",
    "    \n",
    "    mlc_model = create_model(**mlc_params)\n",
    "    mlc_model.load_weights(mlc_filestr.format(i))\n",
    "    mlc_lrs[i] = exp_lr(mlc_model)\n",
    "    \n",
    "    sqr_model = create_model(**sqr_params)\n",
    "    sqr_model.load_weights(sqr_filestr.format(i))\n",
    "    sqr_lrs[i] = exp_lr(sqr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_lr = avg_lr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lr = avg_lr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lr = avg_lr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lr = avg_lr(get_preds(sqr_lrs)) + ('SQR',)\n",
    "\n",
    "bce_lrr = avg_lrr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lrr = avg_lrr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lrr = avg_lrr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lrr = avg_lrr(get_preds(sqr_lrs)) + ('SQR',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([bce_lr, mse_lr, mlc_lr, sqr_lr], \n",
    "        filename='plots/scratch/set_{}/lrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([bce_lrr, mse_lrr, mlc_lrr, sqr_lrr], \n",
    "         filename='plots/scratch/set_{}/lrrs.png'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnifold",
   "language": "python",
   "name": "omnifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
