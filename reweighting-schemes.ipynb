{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager\n",
    "rc('font', family='serif')\n",
    "rc('text', usetex=True)\n",
    "rc('font', size=22)\n",
    "rc('xtick', labelsize=15)\n",
    "rc('ytick', labelsize=15)\n",
    "rc('legend', fontsize=15)\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the data.\n",
    "N = 10**6\n",
    "mu = 0.1\n",
    "sigma = 1\n",
    "\n",
    "# Background is Normal(-μ, σ). Signal is Normal(μ, σ))\n",
    "bkgd = np.random.normal(-mu, sigma, N)\n",
    "sgnl = np.random.normal(mu, sigma, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "def bce(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + (1. - y_true) * K.log(1. - y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return -((y_true) * -K.square(1. - y_pred) + (1. - y_true) * -K.square(y_pred + K.epsilon()))\n",
    "\n",
    "def mlc(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + (1. - y_true) * (1. - y_pred))\n",
    "\n",
    "def square_mlc(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred**2) + (1. - y_true) * (1. - y_pred**2))\n",
    "\n",
    "def exp_mlc(y_true, y_pred):\n",
    "    return -((y_true) * y_pred + (1. - y_true) * (1. - K.exp(y_pred)))\n",
    "\n",
    "def square_sqr(y_true, y_pred):\n",
    "    return -((y_true) * -1. / K.sqrt(K.square(y_pred)) + (1. - y_true) * -K.sqrt(K.square(y_pred)))\n",
    "\n",
    "def exp_sqr(y_true, y_pred):\n",
    "    return -((y_true) * -1. / K.sqrt(K.exp(y_pred)) + (1. - y_true) * -K.sqrt(K.exp(y_pred)))\n",
    "\n",
    "def sqr(y_true, y_pred):\n",
    "    return -((y_true) * -1. / K.sqrt(y_pred + K.epsilon()) + (1. - y_true) * -K.sqrt(y_pred + K.epsilon()))\n",
    "\n",
    "def get_sqr(p):\n",
    "    def sqr_p(y_true, y_pred):\n",
    "        return -((y_true) * -K.pow(y_pred + K.epsilon(), -p/2) + (1. - y_true) * -K.pow(y_pred + K.epsilon(), p/2))\n",
    "    return sqr_p\n",
    "\n",
    "def get_exp_sqr(p):\n",
    "    def exp_sqr_p(y_true, y_pred):\n",
    "        return -((y_true) * -K.pow(K.exp(y_pred), -p/2) + (1. - y_true) * -K.pow(K.exp(y_pred), p/2))\n",
    "    return exp_sqr_p\n",
    "        \n",
    "# Likelihood ratios\n",
    "def lr(x):\n",
    "    return np.exp(-(1/(2 * sigma**2)) * ( (x - mu)**2 - (x + mu)**2))\n",
    "\n",
    "def odds_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f / (1. - f))\n",
    "    return model_lr\n",
    "\n",
    "def pure_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f)\n",
    "    return model_lr\n",
    "\n",
    "def square_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f**2)\n",
    "    return model_lr\n",
    "\n",
    "def exp_lr(model):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(np.exp(f))\n",
    "    return model_lr\n",
    "\n",
    "def pow_lr(model, p):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f**p)\n",
    "    return model_lr\n",
    "\n",
    "def exp_pow_lr(model, p):\n",
    "    def model_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(np.exp(f)**p)\n",
    "    return model_lr\n",
    "\n",
    "def make_mae(N_mae=10**4):\n",
    "    mu = 0.1\n",
    "    sigma = 1\n",
    "\n",
    "    bkgd_mae = np.random.normal(-mu, sigma, N_mae)\n",
    "    sgnl_mae = np.random.normal(mu, sigma, N_mae)\n",
    "    X_mae = np.concatenate([bkgd_mae, sgnl_mae])\n",
    "    \n",
    "    def mae(model_lr):\n",
    "        nonlocal X_mae\n",
    "        return np.abs(model_lr(X_mae) - lr(X_mae)).mean()\n",
    "    return mae\n",
    "    \n",
    "mae = make_mae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(patience=10,\n",
    "                              verbose=0,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "def create_model(hidden='relu', \n",
    "                 output='sigmoid', \n",
    "                 dropout=True):\n",
    "    model = Sequential()\n",
    "    if dropout:\n",
    "        model.add(Dense(64, activation=hidden, input_shape=(1, )))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(128, activation=hidden))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(64, activation=hidden))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(1, activation=output))\n",
    "    else: \n",
    "        model.add(Dense(64, activation=hidden, input_shape=(1, )))\n",
    "        model.add(Dense(128, activation=hidden))\n",
    "        model.add(Dense(64, activation=hidden))\n",
    "        model.add(Dense(1, activation=output))        \n",
    "    \n",
    "    return model\n",
    "\n",
    "def train(loss,\n",
    "          hidden='relu', \n",
    "          output='sigmoid', \n",
    "          dropout=True, \n",
    "          optimizer='adam', \n",
    "          metrics=['accuracy'], \n",
    "          verbose=0):\n",
    "    model = create_model(hidden, output, dropout)      \n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    trace = model.fit(X_train, \n",
    "                      y_train,\n",
    "                      epochs = 100, \n",
    "                      batch_size=int(0.1*N), \n",
    "                      validation_data=(X_test, y_test),\n",
    "                      callbacks=[earlystopping], \n",
    "                      verbose=verbose)\n",
    "    print(trace.history['val_loss'][-1], end = ' ')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def get_preds(model_lrs, xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in model_lrs, a list of model likelihood ratios and xs, a list of \n",
    "    # values on which to compute the likelihood ratios. Returns a 2D array. The \n",
    "    # nth row is the likelihood ratio predictions from the nth model in \n",
    "    # model_lrs.\n",
    "    return np.array([model_lr(xs) for model_lr in model_lrs])\n",
    "    \n",
    "def avg_lr(preds):\n",
    "    # Takes in a 2D array of multiple models' likelihood ratio predictions. \n",
    "    # Returns the average likelihood ratio prediction and its error.\n",
    "    return preds.mean(axis=0), preds.std(axis=0)\n",
    "\n",
    "def avg_lrr(preds, xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a 2D array of multiple models' likelihood ratio predictions. \n",
    "    # Returns the average ratio of predicted likelihood to true likelihood and \n",
    "    # its error.\n",
    "    lrr_preds = preds / lr(xs)\n",
    "    return lrr_preds.mean(axis=0), lrr_preds.std(axis=0)\n",
    "    \n",
    "def lr_plot(ensembles,\n",
    "            title=None,\n",
    "            filename=None,\n",
    "            cs = ['brown', 'green', 'red', 'blue'],\n",
    "            lss = [':', '--', '-.', ':'],\n",
    "            xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a list of pairs (lr_avg, lr_err). Plots them against the true \n",
    "    # likelihood.\n",
    "    fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "    \n",
    "    # Plot true likelihood\n",
    "    plt.plot(xs, lr(xs), label = 'Exact', c='k', ls='-')\n",
    "    \n",
    "    # Plot model likelihoods\n",
    "    for i in range(len(ensembles)):\n",
    "        avg, err, lbl = ensembles[i]\n",
    "        plt.plot(xs, avg, label=lbl, c=cs[i], ls=lss[i])\n",
    "        #plt.fill_between(xs, avg - err, avg + err, color=cs[i], alpha=0.1)\n",
    "    plt.legend()\n",
    "    ax_1.minorticks_on()\n",
    "    ax_1.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Likelihood Ratio')\n",
    "\n",
    "    # Plot background and signal\n",
    "    ax_2 = ax_1.twinx()\n",
    "    bins = np.linspace(-6, 6, 100)\n",
    "    plt.hist(sgnl, alpha=0.1, bins=bins)\n",
    "    plt.hist(bkgd, alpha=0.1, bins=bins)\n",
    "    ax_2.minorticks_on()\n",
    "    ax_2.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "    if title != None:\n",
    "        plt.title(title, loc=\"left\", fontsize=20)\n",
    "    if filename != None:\n",
    "        plt.savefig(filename, dpi=1200, bbox_inches='tight')\n",
    "\n",
    "def lrr_plot(ensembles,\n",
    "             title=None,\n",
    "             filename=None,\n",
    "             cs = ['brown', 'green', 'red', 'blue'],\n",
    "             lss = [':', '--', '-.', ':'],\n",
    "             xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a list of pairs (lrr_avg, lrr_err). Plots them.\n",
    "    fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "    \n",
    "    # Plot ratios of likelihood ratios\n",
    "    for i in range(len(ensembles)):\n",
    "        avg, err, lbl = ensembles[i]\n",
    "        plt.plot(xs, avg, label=lbl, c=cs[i], ls=lss[i])\n",
    "        #plt.fill_between(xs, avg - err, avg + err, color=cs[i], alpha=0.1)\n",
    "    plt.axhline(1,ls=\":\",color=\"grey\", lw=0.5)\n",
    "    plt.axvline(0,ls=\":\",color=\"grey\", lw=0.5)\n",
    "    plt.legend()\n",
    "    ax_1.minorticks_on()\n",
    "    ax_1.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylim(0.94, 1.06)\n",
    "    plt.ylabel('Ratio')\n",
    "\n",
    "    # Plot background and signal\n",
    "    ax_2 = ax_1.twinx()\n",
    "    bins = np.linspace(-6, 6, 100)\n",
    "    plt.hist(sgnl, alpha=0.1, bins=bins)\n",
    "    plt.hist(bkgd, alpha=0.1, bins=bins)\n",
    "    ax_2.minorticks_on()\n",
    "    ax_2.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    if title != None:\n",
    "        plt.title(title, loc=\"left\", fontsize=20)\n",
    "    if filename != None:\n",
    "        plt.savefig(filename, dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MLC $C$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':mlc, 'output':'relu'}\n",
    "params_2 = {'loss':square_mlc, 'output':'linear'}\n",
    "params_3 = {'loss':exp_mlc, 'output':'linear'}\n",
    "\n",
    "filestr_1 = 'models/mlc_c_param/set_0/linear/model_{}.h5'\n",
    "filestr_2 = 'models/mlc_c_param/set_0/square/model_{}.h5'\n",
    "filestr_3 = 'models/mlc_c_param/set_0/exp/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and save models\n",
    "%%time\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1 = train(**params_1)\n",
    "    model_2 = train(**params_2)\n",
    "    model_3 = train(**params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1)\n",
    "    lrs_2[i] = square_lr(model_2)\n",
    "    lrs_3[i] = exp_lr(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels for plotting.\n",
    "lr_1 = avg_lr(get_preds(lrs_1)) + ('MLC (linear)',)\n",
    "lr_2 = avg_lr(get_preds(lrs_2)) + ('MLC (square)',)\n",
    "lr_3 = avg_lr(get_preds(lrs_3)) + ('MLC (exponential)',)\n",
    "\n",
    "lrr_1 = avg_lrr(get_preds(lrs_1)) + ('MLC (linear)',)\n",
    "lrr_2 = avg_lrr(get_preds(lrs_2)) + ('MLC (square)',)\n",
    "lrr_3 = avg_lrr(get_preds(lrs_3)) + ('MLC (exponential)',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([lr_1, lr_2, lr_3], \n",
    "        r'MLC $C$ Parametrizations', \n",
    "        'plots/mlc_c_param/set_0/lrs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([lrr_1, lrr_2, lrr_3], \n",
    "         r'MLC $C$ Parametrizations', \n",
    "         'plots/mlc_c_param/set_0/lrrs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# SQR $C$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100\n",
    "\n",
    "# Model parameters\n",
    "params_1 = {'loss':sqr, 'output':'relu'}\n",
    "params_2 = {'loss':square_sqr, 'output':'linear'}\n",
    "params_3 = {'loss':exp_sqr, 'output':'linear'}\n",
    "\n",
    "filestr_1 = 'models/sqr_c_param/set_0/linear/model_{}.h5'\n",
    "filestr_2 = 'models/sqr_c_param/set_0/square/model_{}.h5'\n",
    "filestr_3 = 'models/sqr_c_param/set_0/exp/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and save models\n",
    "%%time\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    model_1 = train(**params_1)\n",
    "    model_2 = train(**params_2)\n",
    "    model_3 = train(**params_3)\n",
    "    print()\n",
    "    model_1.save_weights(filestr_1.format(i))\n",
    "    model_2.save_weights(filestr_2.format(i))\n",
    "    model_3.save_weights(filestr_3.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "for i in range(reps):\n",
    "    model_1 = create_model(**params_1)\n",
    "    model_2 = create_model(**params_2)\n",
    "    model_3 = create_model(**params_3)\n",
    "    model_1.load_weights(filestr_1.format(i))\n",
    "    model_2.load_weights(filestr_2.format(i))\n",
    "    model_3.load_weights(filestr_3.format(i))\n",
    "    \n",
    "    lrs_1[i] = pure_lr(model_1)\n",
    "    lrs_2[i] = square_lr(model_2)\n",
    "    lrs_3[i] = exp_lr(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels to \n",
    "# make plotting easier.\n",
    "lr_1 = avg_lr(get_preds(lrs_1)) + ('SQR (linear)',)\n",
    "lr_2 = avg_lr(get_preds(lrs_2)) + ('SQR (square)',)\n",
    "lr_3 = avg_lr(get_preds(lrs_3)) + ('SQR (exp)',)\n",
    "\n",
    "lrr_1 = avg_lrr(get_preds(lrs_1)) + ('SQR (linear)',)\n",
    "lrr_2 = avg_lrr(get_preds(lrs_2)) + ('SQR (square)',)\n",
    "lrr_3 = avg_lrr(get_preds(lrs_3)) + ('SQR (exponential)',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([lr_1, lr_2, lr_3], \n",
    "        r'SQR $C$ Parametrizations', \n",
    "        'plots/sqr_c_param/set_0/lrs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrr_plot([lrr_1, lrr_2, lrr_3], \n",
    "         r'SQR $C$ Parametrizations', \n",
    "         'plots/sqr_c_param/set_0/lrrs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SQR $A$/$B$ Parametrizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 20\n",
    "\n",
    "ps = np.round(np.linspace(-2, 2, 81), 2)\n",
    "sqr_filestr = 'models/sqr_ab_param/set_3/linear/model_{}_{}.h5'\n",
    "exp_filestr = 'models/sqr_ab_param/set_3/exp/model_{}_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "for p in ps:\n",
    "    print('===================================================\\n{}'.format(p))\n",
    "    sqr_params = {'loss': get_sqr(p), 'output':'relu'}\n",
    "    exp_params = {'loss': get_exp_sqr(p), 'output':'linear'}\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        sqr_model = train(**sqr_params)\n",
    "        exp_model = train(**exp_params)\n",
    "        print()\n",
    "        sqr_model.save_weights(sqr_filestr.format(p, i))\n",
    "        exp_model.save_weights(exp_filestr.format(p, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get model likelihood ratios.\n",
    "sqr_lrs = {}\n",
    "exp_lrs = {}\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    sqr_lrs[p] = [None] * reps\n",
    "    exp_lrs[p] = [None] * reps\n",
    "    sqr_params = {'loss': get_sqr(p), 'output':'relu'}\n",
    "    exp_params = {'loss': get_exp_sqr(p), 'output':'linear'}\n",
    "    for i in range(reps):\n",
    "        sqr_model = create_model(**sqr_params)\n",
    "        exp_model = create_model(**exp_params)\n",
    "        sqr_model.load_weights(sqr_filestr.format(p, i))\n",
    "        exp_model.load_weights(exp_filestr.format(p, i))\n",
    "        sqr_lrs[p][i] = pow_lr(sqr_model, p)\n",
    "        exp_lrs[p][i] = exp_pow_lr(exp_model, p)\n",
    "        print(i, end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sqr_mae_avg = []\n",
    "sqr_mae_err = []\n",
    "exp_mae_avg = []\n",
    "exp_mae_err = []\n",
    "\n",
    "for p in ps:\n",
    "    sqr_maes = [mae(lr) for lr in sqr_lrs[p]]\n",
    "    exp_maes = [mae(lr) for lr in exp_lrs[p]]\n",
    "    sqr_mae_avg += [np.mean(sqr_maes)]\n",
    "    sqr_mae_err += [np.std(sqr_maes)]\n",
    "    exp_mae_avg += [np.mean(exp_maes)]\n",
    "    exp_mae_err += [np.std(exp_maes)]\n",
    "    print(p, '\\t', sqr_mae_avg[-1], '\\t', exp_mae_avg[-1])\n",
    "    print(p, '\\t', sqr_mae_avg[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqr_mae_avg = np.array(sqr_mae_avg)\n",
    "sqr_mae_err = np.array(sqr_mae_err)\n",
    "exp_mae_avg = np.array(exp_mae_avg)\n",
    "exp_mae_err = np.array(exp_mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(ps, sqr_mae_avg, c='blue', label='linear')\n",
    "plt.plot(ps, exp_mae_avg, c='red', label='exponential')\n",
    "plt.legend()\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$p$')\n",
    "\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "plt.title(r\"SQR $A/B$ Parametrization\",loc=\"left\",fontsize=20);\n",
    "plt.savefig('plots/sqr_ab_param/set_0/maes.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce}\n",
    "mse_params = {'loss':mse}\n",
    "mlc_params = {'loss':exp_mlc, 'output':'linear'}\n",
    "sqr_params = {'loss':exp_sqr, 'output':'linear'}\n",
    "\n",
    "bce_filestr = 'models/loss_comp/set_0/bce/model_{}_{}.h5'\n",
    "mse_filestr = 'models/loss_comp/set_0/mse/model_{}_{}.h5'\n",
    "mlc_filestr = 'models/loss_comp/set_0/mlc/model_{}_{}.h5'\n",
    "sqr_filestr = 'models/loss_comp/set_0/sqr/model_{}_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "%%time\n",
    "\n",
    "bce_lrs = {}\n",
    "mse_lrs = {}\n",
    "mlc_lrs = {}\n",
    "sqr_lrs = {}\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Generate data\n",
    "    bkgd = np.random.normal(-mu, 1, N)\n",
    "    sgnl = np.random.normal(mu, 1, N)\n",
    "    X = np.concatenate([bkgd, sgnl])\n",
    "    y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        bce_model = train(**bce_params)\n",
    "        mse_model = train(**mse_params)\n",
    "        mlc_model = train(**mlc_params)\n",
    "        sqr_model = train(**sqr_params)\n",
    "        print()\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        mse_model.save_weights(mse_filestr.format(N, i))\n",
    "        mlc_model.save_weights(mlc_filestr.format(N, i))\n",
    "        sqr_model.save_weights(sqr_filestr.format(N, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute errors\n",
    "bce_mae_avg = []\n",
    "mse_mae_avg = []\n",
    "mlc_mae_avg = []\n",
    "sqr_mae_avg = []\n",
    "\n",
    "bce_mae_err = []\n",
    "mse_mae_err = []\n",
    "mlc_mae_err = []\n",
    "sqr_mae_err = []\n",
    "\n",
    "for N in Ns:\n",
    "    print(N)\n",
    "    bce_lrs = [None] * reps\n",
    "    mse_lrs = [None] * reps\n",
    "    mlc_lrs = [None] * reps\n",
    "    sqr_lrs = [None] * reps\n",
    "    for i in range(reps):\n",
    "        bce_model = create_model(**bce_params)\n",
    "        bce_model.load_weights(bce_filestr.format(N, i))\n",
    "        bce_lrs[i] = odds_lr(bce_model)\n",
    "\n",
    "        mse_model = create_model(**mse_params)\n",
    "        mse_model.load_weights(mse_filestr.format(N, i))\n",
    "        mse_lrs[i] = odds_lr(mse_model)\n",
    "\n",
    "        mlc_model = create_model(**mlc_params)\n",
    "        mlc_model.load_weights(mlc_filestr.format(N, i))\n",
    "        mlc_lrs[i] = exp_lr(mlc_model)\n",
    "\n",
    "        sqr_model = create_model(**sqr_params)\n",
    "        sqr_model.load_weights(sqr_filestr.format(N, i))\n",
    "        sqr_lrs[i] = exp_lr(sqr_model)\n",
    "    \n",
    "    bce_maes = [mae(lr) for lr in bce_lrs]\n",
    "    mse_maes = [mae(lr) for lr in mse_lrs]\n",
    "    mlc_maes = [mae(lr) for lr in mlc_lrs]\n",
    "    sqr_maes = [mae(lr) for lr in sqr_lrs]\n",
    "    \n",
    "    bce_mae_avg += [np.mean(bce_maes)]\n",
    "    bce_mae_err += [np.std(bce_maes)]\n",
    "    \n",
    "    mse_mae_avg += [np.mean(mse_maes)]\n",
    "    mse_mae_err += [np.std(mse_maes)]\n",
    "    \n",
    "    mlc_mae_avg += [np.mean(mlc_maes)]\n",
    "    mlc_mae_err += [np.std(mlc_maes)]\n",
    "    \n",
    "    sqr_mae_avg += [np.mean(sqr_maes)]\n",
    "    sqr_mae_err += [np.std(sqr_maes)]\n",
    "\n",
    "bce_mae_avg = np.array(bce_mae_avg)\n",
    "mse_mae_avg = np.array(mse_mae_avg)\n",
    "mlc_mae_avg = np.array(mlc_mae_avg)\n",
    "sqr_mae_avg = np.array(sqr_mae_avg)\n",
    "\n",
    "bce_mae_err = np.array(bce_mae_err)\n",
    "mse_mae_err = np.array(mse_mae_err)\n",
    "mlc_mae_err = np.array(mlc_mae_err)\n",
    "sqr_mae_err = np.array(sqr_mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(Ns, bce_mae_avg, c='brown', ls=':', label='BCE')\n",
    "plt.plot(Ns, mse_mae_avg, c='green', ls='--', label='MSE')\n",
    "plt.plot(Ns, mlc_mae_avg, c='red', ls='--', label='MLC')\n",
    "plt.plot(Ns, sqr_mae_avg, c='blue', ls='-.', label='SQR')\n",
    "#plt.fill_between(Ns, bce_mae_avg - bce_mae_err, bce_mae_avg + bce_mae_err, color='brown', alpha=0.1)\n",
    "#plt.fill_between(Ns, mse_mae_avg - mse_mae_err, mse_mae_avg + mse_mae_err, color='green', alpha=0.1)\n",
    "#plt.fill_between(Ns, mlc_mae_avg - mlc_mae_err, mlc_mae_avg + mlc_mae_err, color='red', alpha=0.1)\n",
    "#plt.fill_between(Ns, sqr_mae_avg - sqr_mae_err, sqr_mae_avg + sqr_mae_err, color='blue', alpha=0.1)\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\", base=10)\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$N$')\n",
    "\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "plt.savefig('plots/loss_comp/set_0/maes.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Likelihood Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10**6\n",
    "reps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in models.\n",
    "bce_lrs = [None] * reps\n",
    "mse_lrs = [None] * reps\n",
    "mlc_lrs = [None] * reps\n",
    "sqr_lrs = [None] * reps\n",
    "for i in range(reps):\n",
    "    bce_model = create_model(**bce_params)\n",
    "    bce_model.load_weights(bce_filestr.format(N, i))\n",
    "    bce_lrs[i] = odds_lr(bce_model)\n",
    "    \n",
    "    mse_model = create_model(**mse_params)\n",
    "    mse_model.load_weights(mse_filestr.format(N, i))\n",
    "    mse_lrs[i] = odds_lr(mse_model)\n",
    "    \n",
    "    mlc_model = create_model(**mlc_params)\n",
    "    mlc_model.load_weights(mlc_filestr.format(N, i))\n",
    "    mlc_lrs[i] = exp_lr(mlc_model)\n",
    "    \n",
    "    sqr_model = create_model(**sqr_params)\n",
    "    sqr_model.load_weights(sqr_filestr.format(N, i))\n",
    "    sqr_lrs[i] = exp_lr(sqr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_lr = avg_lr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lr = avg_lr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lr = avg_lr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lr = avg_lr(get_preds(sqr_lrs)) + ('SQR',)\n",
    "\n",
    "bce_lrr = avg_lrr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lrr = avg_lrr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lrr = avg_lrr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lrr = avg_lrr(get_preds(sqr_lrs)) + ('SQR',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([bce_lr, mse_lr, mlc_lr, sqr_lr], \n",
    "        filename='plots/loss_comp/set_0/lrs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrr_plot([bce_lrr, mse_lrr, mlc_lrr, sqr_lrr], \n",
    "         filename='plots/loss_comp/set_0/lrrs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_mae = np.mean([mae(lr) for lr in bce_lrs])\n",
    "mse_mae = np.mean([mae(lr) for lr in mse_lrs])\n",
    "mlc_mae = np.mean([mae(lr) for lr in mlc_lrs])\n",
    "sqr_mae = np.mean([mae(lr) for lr in sqr_lrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bce_mae, mse_mae, mlc_mae, sqr_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Interpolation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the data.\n",
    "N = 10**6\n",
    "mu = 1.5\n",
    "sigma = 1\n",
    "\n",
    "# Background is Normal(-μ, σ). Signal is Normal(μ, σ))\n",
    "bkgd = np.random.normal(-mu, sigma, N)\n",
    "sgnl = np.random.normal(mu, sigma, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 10\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce}\n",
    "mse_params = {'loss':mse}\n",
    "mlc_params = {'loss':exp_mlc, 'output':'linear'}\n",
    "sqr_params = {'loss':exp_sqr, 'output':'linear'}\n",
    "\n",
    "bce_filestr = 'models/loss_comp/set_1/bce/model_{}.h5'\n",
    "mse_filestr = 'models/loss_comp/set_1/mse/model_{}.h5'\n",
    "mlc_filestr = 'models/loss_comp/set_1/mlc/model_{}.h5'\n",
    "sqr_filestr = 'models/loss_comp/set_1/sqr/model_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    bce_model = train(**bce_params)\n",
    "    mse_model = train(**mse_params)\n",
    "    mlc_model = train(**mlc_params)\n",
    "    sqr_model = train(**sqr_params)\n",
    "    print()\n",
    "    bce_model.save_weights(bce_filestr.format(i))\n",
    "    mse_model.save_weights(mse_filestr.format(i))\n",
    "    mlc_model.save_weights(mlc_filestr.format(i))\n",
    "    mlc_model.save_weights(sqr_filestr.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in models.\n",
    "bce_lrs = [None] * reps\n",
    "mse_lrs = [None] * reps\n",
    "mlc_lrs = [None] * reps\n",
    "sqr_lrs = [None] * reps\n",
    "for i in range(reps):\n",
    "    bce_model = create_model(**bce_params)\n",
    "    bce_model.load_weights(bce_filestr.format(i))\n",
    "    bce_lrs[i] = odds_lr(bce_model)\n",
    "    \n",
    "    mse_model = create_model(**mse_params)\n",
    "    mse_model.load_weights(mse_filestr.format(i))\n",
    "    mse_lrs[i] = odds_lr(mse_model)\n",
    "    \n",
    "    mlc_model = create_model(**mlc_params)\n",
    "    mlc_model.load_weights(mlc_filestr.format(i))\n",
    "    mlc_lrs[i] = exp_lr(mlc_model)\n",
    "    \n",
    "    sqr_model = create_model(**sqr_params)\n",
    "    sqr_model.load_weights(sqr_filestr.format(i))\n",
    "    sqr_lrs[i] = exp_lr(sqr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_lr = avg_lr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lr = avg_lr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lr = avg_lr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lr = avg_lr(get_preds(sqr_lrs)) + ('SQR',)\n",
    "\n",
    "bce_lrr = avg_lrr(get_preds(bce_lrs)) + ('BCE',)\n",
    "mse_lrr = avg_lrr(get_preds(mse_lrs)) + ('MSE',)\n",
    "mlc_lrr = avg_lrr(get_preds(mlc_lrs)) + ('MLC',)\n",
    "sqr_lrr = avg_lrr(get_preds(sqr_lrs)) + ('SQR',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([bce_lr, mse_lr, mlc_lr, sqr_lr], \n",
    "        filename='plots/loss_comp/set_1/lrs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([bce_lrr, mse_lrr, mlc_lrr, sqr_lrr], \n",
    "         filename='plots/loss_comp/set_1/lrrs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.linspace(0.45, 2, 32), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnifold",
   "language": "python",
   "name": "omifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
