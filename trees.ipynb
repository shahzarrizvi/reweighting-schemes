{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ced574-924b-4fd3-9444-614365da7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2777dc-b825-4800-bc82-d1b23953c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from joblib import dump, load \n",
    "\n",
    "# Utility imports\n",
    "from utils.losses import *\n",
    "from utils.plotting import *\n",
    "from utils.training import *\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c301cf-f760-4479-aeef-27c5a063035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526a150-2df1-4284-b6da-d1b4959d5352",
   "metadata": {
    "tags": []
   },
   "source": [
    "# $d = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cae75b-8b8b-44bb-a06d-78c677817809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 1\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d)).reshape(-1, 1)\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0202c93-a106-408d-b6fc-9af61d07f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 ===================================================\n",
      "1000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 ===================================================\n",
      "10000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 ===================================================\n",
      "100000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 ===================================================\n",
      "1000000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 ===================================================\n",
      "10000000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 "
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d6730-4b33-40bd-8abb-acf1be1d2f30",
   "metadata": {
    "tags": []
   },
   "source": [
    "# $d = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12422843-2cf2-4280-b1b4-aae3127e5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 2\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1a1f4c-7d62-4617-9eaf-1c2ab3f56bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "1000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "10000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "100000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "1000000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "10000000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n"
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d942469-7ef3-4907-87eb-c9296e3409bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# $d=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a9f85bd-b60b-473c-bcc8-373a9d120f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 4\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3e63d-4966-43eb-af89-f6ae1d3370eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "1000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "10000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "100000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "===================================================\n",
      "1000000\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 "
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b039a-fa91-4a35-8233-c4a017babc44",
   "metadata": {
    "tags": []
   },
   "source": [
    "# $d=8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81baf6-0352-4b70-bcc8-ff37baeac13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 8\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72def4-b63c-46e2-92d5-1d724b5d079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b33f6-be09-404b-bbca-7e567a651b1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# $d=16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78be7a-1c20-4cde-bd24-d5a46012377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 16\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5262859-deb7-413f-b674-9c84a157ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca2309-9077-432f-933c-77be9ede35e1",
   "metadata": {},
   "source": [
    "# $d = 32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f08136-c5dc-4649-989b-4f4cea166cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 32\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9e44b-a9fb-49c9-923d-9c414e2c6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multifold",
   "language": "python",
   "name": "multifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
