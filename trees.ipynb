{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ced574-924b-4fd3-9444-614365da7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2777dc-b825-4800-bc82-d1b23953c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Utility imports\n",
    "from utils.losses import *\n",
    "from utils.plotting import *\n",
    "from utils.training import *\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c301cf-f760-4479-aeef-27c5a063035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526a150-2df1-4284-b6da-d1b4959d5352",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# $d = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cae75b-8b8b-44bb-a06d-78c677817809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 1\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d)).reshape(-1, 1)\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0202c93-a106-408d-b6fc-9af61d07f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ':\\t')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d6730-4b33-40bd-8abb-acf1be1d2f30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# $d = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12422843-2cf2-4280-b1b4-aae3127e5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 2\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a1f4c-7d62-4617-9eaf-1c2ab3f56bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = 10**np.arange(5, 8)\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ':\\t')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d942469-7ef3-4907-87eb-c9296e3409bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# $d=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f85bd-b60b-473c-bcc8-373a9d120f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 4\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3e63d-4966-43eb-af89-f6ae1d3370eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ':\\t')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b039a-fa91-4a35-8233-c4a017babc44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# $d=8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81baf6-0352-4b70-bcc8-ff37baeac13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 8\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72def4-b63c-46e2-92d5-1d724b5d079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ':\\t')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b33f6-be09-404b-bbca-7e567a651b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# $d=16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78be7a-1c20-4cde-bd24-d5a46012377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 16\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5262859-deb7-413f-b674-9c84a157ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ':\\t')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca2309-9077-432f-933c-77be9ede35e1",
   "metadata": {},
   "source": [
    "# $d = 32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f08136-c5dc-4649-989b-4f4cea166cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 32\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f9e44b-a9fb-49c9-923d-9c414e2c6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "10000000\n",
      "0.6882202447947383 \t 21\n",
      "31:\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 13:59:40.661488: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 13:59:41.261656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21271 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6882731914520264 \t 100\t\n",
      "32:\t0.688291609287262 \t 100\t\n",
      "33:\t0.6882471442222595 \t 94\t\n",
      "34:\t0.6882668733596802 \t 55\t\n",
      "35:\t0.6882753968238831 \t 76\t\n",
      "36:\t0.6882576942443848 \t 100\t\n",
      "37:\t0.688265323638916 \t 69\t\n",
      "38:\t0.6882765293121338 \t 100\t\n",
      "39:\t0.6882578730583191 \t 89\t\n",
      "40:\t0.6882681846618652 \t 76\t\n",
      "41:\t0.6882495880126953 \t 62\t\n",
      "42:\t0.6882864832878113 \t 100\t\n",
      "43:\t0.688258171081543 \t 87\t\n",
      "44:\t0.6882637143135071 \t 81\t\n",
      "45:\t0.688267707824707 \t 100\t\n",
      "46:\t0.6882681250572205 \t 74\t\n",
      "47:\t0.6882712244987488 \t 100\t\n",
      "48:\t0.6882588863372803 \t 63\t\n",
      "49:\t0.6882491707801819 \t 75\t\n",
      "50:\t0.6882544755935669 \t 95\t\n",
      "51:\t0.688260018825531 \t 57\t\n",
      "52:\t0.6882814764976501 \t 100\t\n",
      "53:\t0.6882668137550354 \t 91\t\n",
      "54:\t0.6882739067077637 \t 91\t\n",
      "55:\t0.6882550120353699 \t 86\t\n",
      "56:\t0.6882740259170532 \t 100\t\n",
      "57:\t0.6882724761962891 \t 87\t\n",
      "58:\t0.6882892847061157 \t 82\t\n",
      "59:\t0.6882728934288025 \t 88\t\n",
      "60:\t0.6882638335227966 \t 81\t\n",
      "61:\t0.688271701335907 \t 70\t\n",
      "62:\t0.6882848739624023 \t 76\t\n",
      "63:\t0.6882895827293396 \t 100\t\n",
      "64:\t0.6882631778717041 \t 86\t\n",
      "65:\t0.6882600784301758 \t 100\t\n",
      "66:\t0.6882755160331726 \t 100\t\n",
      "67:\t0.6882813572883606 \t 74\t\n",
      "68:\t0.6882433295249939 \t 100\t\n",
      "69:\t0.6882401704788208 \t 68\t\n",
      "70:\t0.688264012336731 \t 73\t\n",
      "71:\t0.6882705688476562 \t 70\t\n",
      "72:\t0.688286542892456 \t 98\t\n",
      "73:\t0.6882549524307251 \t 63\t\n",
      "74:\t0.6882659792900085 \t 70\t\n",
      "75:\t0.6882914304733276 \t 76\t\n",
      "76:\t0.6882585883140564 \t 72\t\n",
      "77:\t0.6882628202438354 \t 72\t\n",
      "78:\t0.6882397532463074 \t 81\t\n",
      "79:\t0.6882596015930176 \t 97\t\n",
      "80:\t0.6882585883140564 \t 57\t\n",
      "81:\t0.6882845759391785 \t 62\t\n",
      "82:\t0.6882728338241577 \t 89\t\n",
      "83:\t0.6882416009902954 \t 98\t\n",
      "84:\t0.6882858276367188 \t 74\t\n",
      "85:\t0.688334584236145 \t 100\t\n",
      "86:\t0.6883010268211365 \t 57\t\n",
      "87:\t0.688262403011322 \t 100\t\n",
      "88:\t0.6882687211036682 \t 78\t\n",
      "89:\t0.6882685422897339 \t 56\t\n",
      "90:\t0.6882680654525757 \t 69\t\n",
      "91:\t0.688281774520874 \t 89\t\n",
      "92:\t0.6882554292678833 \t 65\t\n",
      "93:\t0.6882675290107727 \t 82\t\n",
      "94:\t0.6882792711257935 \t 57\t\n",
      "95:\t0.6882596611976624 \t 84\t\n",
      "96:\t0.688305139541626 \t 100\t\n",
      "97:\t0.6882662177085876 \t 97\t\n",
      "98:\t0.6882899403572083 \t 69\t\n",
      "99:\t0.6882607936859131 \t 79\t\n"
     ]
    }
   ],
   "source": [
    "Ns = [10**7]\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "    \n",
    "    for i in range(31, 100):\n",
    "        print(i, end = ':\\t')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multifold",
   "language": "python",
   "name": "multifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
