{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ced574-924b-4fd3-9444-614365da7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2777dc-b825-4800-bc82-d1b23953c263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump, load \n",
    "\n",
    "# Utility imports\n",
    "from utils.losses import *\n",
    "from utils.plotting import *\n",
    "from utils.training import *\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c301cf-f760-4479-aeef-27c5a063035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eff551-de89-49c5-a2c0-a1c15ae11183",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526a150-2df1-4284-b6da-d1b4959d5352",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cae75b-8b8b-44bb-a06d-78c677817809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 1\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d)).reshape(-1, 1)\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')\n",
    "\n",
    "bkgd = stats.norm(-0.1, 1)\n",
    "sgnl = stats.norm(+0.1, 1)\n",
    "\n",
    "lr = make_lr(bkgd, sgnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c89e58-6e56-4b84-9385-049327bed049",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10**6\n",
    "data, m, s = split_data(X[:N], y[:N])\n",
    "\n",
    "bce_lrs = [None] * reps\n",
    "gbc_lrs = [None] * reps\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    bce_model = create_model(**bce_params)\n",
    "    bce_model.load_weights(bce_filestr.format(N, i))\n",
    "    bce_lrs[i] = odds_lr(bce_model, m, s)\n",
    "\n",
    "    gbc_model = load(gbc_filestr.format(N, i))\n",
    "    gbc_lrs[i] = tree_lr(gbc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856c227-271c-440f-95d0-3e93becf92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-6, 6, 1201).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca7c19-d2bc-4bc6-b872-8a44b142272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_preds = get_preds(bce_lrs, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a6431-0b68-4d35-a8c3-8c37c3ea4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_preds = get_preds(gbc_lrs, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130a1cc-e58a-4743-9016-e06387cf46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bce = bce_preds.mean(axis = 0)\n",
    "avg_gbc = gbc_preds.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e0a31-4089-402d-ab48-f62fb0d35123",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_plot([bce_preds, gbc_preds], ['BCE', 'GBC'], lr, xs.reshape(-1), \n",
    "           figsize = (w, h), title = '\\it Likelihood Ratio Models', \n",
    "           filename = 'plots/lr_models.png') "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2945cb9-735d-4029-a433-32efe7aa5f8b",
   "metadata": {},
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d6730-4b33-40bd-8abb-acf1be1d2f30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12422843-2cf2-4280-b1b4-aae3127e5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 2\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a1f4c-7d62-4617-9eaf-1c2ab3f56bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d942469-7ef3-4907-87eb-c9296e3409bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f85bd-b60b-473c-bcc8-373a9d120f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 4\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3e63d-4966-43eb-af89-f6ae1d3370eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(91, reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b039a-fa91-4a35-8233-c4a017babc44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d=8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81baf6-0352-4b70-bcc8-ff37baeac13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 8\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72def4-b63c-46e2-92d5-1d724b5d079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b33f6-be09-404b-bbca-7e567a651b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d=16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78be7a-1c20-4cde-bd24-d5a46012377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 16\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5262859-deb7-413f-b674-9c84a157ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca2309-9077-432f-933c-77be9ede35e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f08136-c5dc-4649-989b-4f4cea166cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 32\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9e44b-a9fb-49c9-923d-9c414e2c6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed990a-9a86-46df-a2b5-45d88cdb0e88",
   "metadata": {},
   "source": [
    "# Zenodo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7beb4-a137-4bfc-a7a5-5cbc00b6b5ee",
   "metadata": {},
   "source": [
    "## $d = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982a7583-5b0d-48b8-b4f1-c37fda6ba098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 1\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d)).reshape(-1, 1)\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8fdd1-bf3c-49dd-9e78-a2051e91857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0.9300370988249779 \t 11\n",
      "0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 08:06:47.141047: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 08:06:47.715220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22243 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343477606773376 \t 11\t1 0.7395363450050354 \t 13\t2 0.7321134805679321 \t 11\t3 0.7334631085395813 \t 11\t4 0.7235618829727173 \t 11\t5 0.7205410599708557 \t 11\t6 0.7434526085853577 \t 11\t7 0.7404569983482361 \t 11\t8 0.739315927028656 \t 13\t9 0.7340620160102844 \t 11\t10 0.7243669629096985 \t 12\t11 0.7452961802482605 \t 18\t12 0.7284832000732422 \t 11\t13 0.7443119883537292 \t 11\t14 0.7229510545730591 \t 11\t15 0.7280807495117188 \t 11\t16 0.7416480779647827 \t 11\t17 0.7267101407051086 \t 12\t18 0.727083683013916 \t 11\t19 0.7150323390960693 \t 11\t20 0.7355436086654663 \t 11\t21 0.7389186024665833 \t 11\t22 0.7348420023918152 \t 11\t23 0.7321674823760986 \t 12\t24 0.7340015172958374 \t 11\t25 0.7204300761222839 \t 13\t26 0.7411311864852905 \t 11\t27 0.72242271900177 \t 11\t28 0.7186024188995361 \t 11\t29 0.7358741164207458 \t 11\t30 0.7357438802719116 \t 13\t31 0.7386594414710999 \t 14\t32 0.7243064045906067 \t 13\t33 0.7336468696594238 \t 11\t34 0.7279472947120667 \t 11\t35 0.7523735761642456 \t 11\t36 0.7208036780357361 \t 11\t37 0.7277060151100159 \t 12\t38 0.7290754914283752 \t 11\t39 0.7223617434501648 \t 11\t40 0.7292479872703552 \t 11\t41 0.72411048412323 \t 11\t42 0.7342311143875122 \t 12\t43 0.731158971786499 \t 11\t44 0.7269352078437805 \t 11\t45 0.7281236052513123 \t 11\t46 0.7291674017906189 \t 14\t47 0.73665452003479 \t 14\t48 0.7331929802894592 \t 16\t49 0.7176485657691956 \t 11\t50 0.7343025803565979 \t 11\t51 0.7384144067764282 \t 12\t52 0.7251771688461304 \t 11\t53 0.7213380932807922 \t 11\t54 0.7508831024169922 \t 15\t55 0.7256828546524048 \t 11\t56 0.721649706363678 \t 11\t57 0.7287647724151611 \t 14\t58 0.7194644212722778 \t 12\t59 0.7443112134933472 \t 13\t60 0.7205601334571838 \t 11\t61 0.7381644248962402 \t 12\t62 0.7237892150878906 \t 11\t63 0.7360292673110962 \t 14\t64 0.7406395077705383 \t 11\t65 0.7237112522125244 \t 11\t66 0.7404961585998535 \t 13\t67 0.7342633008956909 \t 11\t68 0.7271904945373535 \t 14\t69 0.7293660640716553 \t 11\t70 0.7233138084411621 \t 11\t71 0.726593017578125 \t 11\t72 0.7317983508110046 \t 13\t73 0.7411046624183655 \t 11\t74 0.71866774559021 \t 11\t75 0.7346468567848206 \t 11\t76 0.7356905341148376 \t 12\t77 0.7394430041313171 \t 12\t78 0.7407222986221313 \t 11\t79 0.7280852794647217 \t 11\t80 0.7334765791893005 \t 11\t81 0.7470771670341492 \t 12\t82 0.7387419939041138 \t 11\t83 0.7374575138092041 \t 11\t84 0.7408897280693054 \t 11\t85 0.7386338114738464 \t 11\t86 0.7124642729759216 \t 11\t87 0.7247927784919739 \t 11\t88 0.7420572638511658 \t 15\t89 0.7372874617576599 \t 11\t90 0.7207868099212646 \t 11\t91 0.7353695631027222 \t 11\t92 0.7444363236427307 \t 11\t93 0.7395352125167847 \t 12\t94 0.7317602038383484 \t 11\t95 0.7440763711929321 \t 12\t96 0.7375497221946716 \t 16\t97 0.7303478717803955 \t 11\t98 0.7225309014320374 \t 11\t99 0.7307790517807007 \t 11\t\n",
      "===================================================\n",
      "1000\n",
      "0.7274283577203751 \t 11\n",
      "0 0.688127338886261 \t 12\t1 0.6865047812461853 \t 13\t2 0.6868351101875305 \t 26\t3 0.6868392825126648 \t 12\t4 0.6869341135025024 \t 19\t5 0.6861022710800171 \t 23\t6 0.687416136264801 \t 30\t7 0.6858158111572266 \t 23\t8 0.6864166259765625 \t 31\t9 0.6861482858657837 \t 23\t10 0.6878883838653564 \t 22\t11 0.687270998954773 \t 20\t12 0.6877328157424927 \t 30\t13 0.6862033009529114 \t 14\t14 0.6866095066070557 \t 14\t15 0.686951756477356 \t 11\t16 0.6871314644813538 \t 19\t17 0.6871407628059387 \t 14\t18 0.6875283122062683 \t 19\t19 0.6870280504226685 \t 19\t20 0.6869549751281738 \t 12\t21 0.6873953342437744 \t 15\t22 0.6876143217086792 \t 14\t23 0.687006950378418 \t 21\t24 0.6865280866622925 \t 15\t25 0.6867890954017639 \t 16\t26 0.6870480179786682 \t 12\t27 0.6882086396217346 \t 14\t28 0.6871100068092346 \t 20\t29 0.6860540509223938 \t 11\t30 0.6865981221199036 \t 17\t31 0.6866846084594727 \t 20\t32 0.6868696212768555 \t 17\t33 0.6878536343574524 \t 15\t34 0.6880928874015808 \t 21\t35 0.6875844597816467 \t 22\t36 0.6870816946029663 \t 18\t37 0.6868539452552795 \t 12\t38 0.687091052532196 \t 22\t39 0.6862052083015442 \t 23\t40 0.6871997117996216 \t 12\t41 0.6861708760261536 \t 14\t42 0.6878865957260132 \t 12\t43 0.6870124340057373 \t 13\t44 0.6879163384437561 \t 17\t45 0.6864380240440369 \t 21\t46 0.6871263980865479 \t 14\t47 0.6869605779647827 \t 39\t48 0.6866742968559265 \t 17\t49 0.6861315369606018 \t 12\t50 0.6857870817184448 \t 13\t51 0.6870720982551575 \t 42\t52 0.6867977380752563 \t 22\t53 0.6875101327896118 \t 15\t54 0.6868135333061218 \t 14\t55 0.6865555644035339 \t 20\t56 0.6880230903625488 \t 26\t57 0.6867395043373108 \t 14\t58 0.6871678233146667 \t 33\t59 0.6859631538391113 \t 14\t60 0.6867691874504089 \t 13\t61 0.6881904006004333 \t 52\t62 0.685805082321167 \t 13\t63 0.6859678030014038 \t 17\t64 0.688080906867981 \t 17\t65 0.6867595314979553 \t 27\t66 0.6875249147415161 \t 15\t67 0.686416506767273 \t 14\t68 0.6863493919372559 \t 15\t69 0.6872568130493164 \t 14\t70 0.6870588660240173 \t 34\t71 0.6878463625907898 \t 13\t72 0.6872818470001221 \t 22\t73 0.6872188448905945 \t 18\t74 0.686782956123352 \t 18\t75 0.6869657039642334 \t 23\t76 0.6862908005714417 \t 15\t77 0.6866839528083801 \t 18\t78 0.6862943172454834 \t 14\t79 0.6870744824409485 \t 13\t80 0.6875633597373962 \t 25\t81 0.6869673728942871 \t 24\t82 0.6868187189102173 \t 13\t83 0.6880639791488647 \t 15\t84 0.6868988275527954 \t 28\t85 0.6864516139030457 \t 17\t86 0.6869805455207825 \t 15\t87 0.6868576407432556 \t 16\t88 0.6862417459487915 \t 22\t89 0.6867197155952454 \t 18\t90 0.6867659091949463 \t 23\t91 0.6871723532676697 \t 15\t92 0.685994029045105 \t 26\t93 0.6874477863311768 \t 19\t94 0.686322033405304 \t 23\t95 0.6866973638534546 \t 14\t96 0.6869049668312073 \t 21\t97 0.6868618130683899 \t 24\t98 0.6869447827339172 \t 13\t99 0.6869614124298096 \t 13\t\n",
      "===================================================\n",
      "10000\n",
      "0.6967026446580887 \t 11\n",
      "0 0.6929359436035156 \t 39\t1 0.6935632824897766 \t 29\t2 0.6935275793075562 \t 29\t3 0.6929673552513123 \t 34\t4 0.6932574510574341 \t 34\t5 0.693165123462677 \t 27\t6 0.6928344964981079 \t 33\t7 0.6931012868881226 \t 18\t8 0.6927337646484375 \t 33\t9 0.6932898163795471 \t 28\t10 0.6930893659591675 \t 60\t11 0.6933186054229736 \t 38\t12 0.6938557624816895 \t 39\t13 0.6935607194900513 \t 37\t14 0.692777156829834 \t 28\t15 0.6933010816574097 \t 12\t16 "
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf622c3-cfce-4a54-b8d5-2dca4a76c167",
   "metadata": {},
   "source": [
    "## $d = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e462f-21a5-4517-a390-57d7e4e498fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 2\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c1e2a-1e85-4736-b009-fcac789b5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c198e6-0986-41aa-a9a7-d28f318d178d",
   "metadata": {},
   "source": [
    "## $d = 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9764d4-4e06-4426-b662-c1551a4c8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 4\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15382cf7-0ebb-41ab-bc6f-037c5c058056",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8d17d-d03a-4d22-9a8f-537bfb822352",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23a752-df10-4f18-bc9f-222e20f10212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 8\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5ea4b-dc38-470e-a65d-9c3217dcc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef99106-1889-4016-afdc-36c47f2bb0a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 11$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77dcda-85fc-4e15-afc9-2081a23d9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 11\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ba1cb-8b9c-4545-bb0d-9ddbaf89bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multifold",
   "language": "python",
   "name": "multifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
