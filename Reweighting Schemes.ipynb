{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager\n",
    "rc('font', family='serif')\n",
    "rc('text', usetex=True)\n",
    "rc('font', size=22)\n",
    "rc('xtick', labelsize=15)\n",
    "rc('ytick', labelsize=15)\n",
    "rc('legend', fontsize=15)\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reweighting Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10**6 # Sample size\n",
    "mu = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the data.\n",
    "\n",
    "# Background is Normal(-μ, 1)\n",
    "# Signal is Normal(μ, 1))\n",
    "bgd = np.random.normal(-mu, 1, N)\n",
    "sig = np.random.normal(mu, 1, N)\n",
    "X = np.concatenate([bgd, sig])\n",
    "y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(patience=10,\n",
    "                              verbose=0,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "def bce(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + (1. - y_true) * K.log(1. - y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return -((y_true) * -K.square(1. - y_pred) + (1. - y_true) * -K.square(y_pred + K.epsilon()))\n",
    "\n",
    "def sqr(y_true, y_pred):    \n",
    "    return -((y_true) * -1. / K.sqrt(y_pred + K.epsilon()) + (1. - y_true) * -K.sqrt(y_pred + K.epsilon()))\n",
    "\n",
    "def mlc(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + (1. - y_true) * (1. - y_pred))\n",
    "\n",
    "# Models\n",
    "def train(loss):\n",
    "    match_params = {'bce': ['relu', 'relu', 'relu', 'sigmoid', bce, 'adam', 2],\n",
    "                    'mse': ['relu', 'relu', 'relu', 'sigmoid', mse, 'adam', 2],\n",
    "                    'sqr': ['relu', 'relu', 'relu', 'relu', sqr, RMSprop(lr=1e-5, momentum=1), 2],\n",
    "                    'mlc': ['relu', 'relu', 'relu', 'relu', mlc, 'rmsprop', 0.5]}\n",
    "    params = match_params[loss]\n",
    "    \n",
    "    i = 1\n",
    "    while True:\n",
    "        print('Training {}: '.format(i) + loss.upper())\n",
    "        i += 1\n",
    "        inputs = Input((1, ))\n",
    "        layer_1 = Dense(64, activation=params[0])(inputs)\n",
    "        layer_2 = Dense(128, activation=params[1])(layer_1)\n",
    "        layer_3 = Dense(64, activation=params[2])(layer_2)\n",
    "        outputs = Dense(1, activation=params[3])(layer_3)\n",
    "        \n",
    "        model = Model(inputs=inputs, outputs = outputs)\n",
    "        model.compile(loss=params[4], \n",
    "                      optimizer=params[5], \n",
    "                      metrics='accuracy')\n",
    "        \n",
    "        trace = model.fit(X_train, \n",
    "                          y_train, \n",
    "                          epochs = 100, \n",
    "                          batch_size=int(0.1*N), \n",
    "                          validation_data=(X_test, y_test), \n",
    "                          callbacks=[earlystopping], \n",
    "                          verbose=0)\n",
    "        \n",
    "        if trace.history['val_loss'][-1] < params[6]:\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "0 Training 1: BCE\n",
      "1 Training 1: BCE\n",
      "2 Training 1: BCE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint('==================================================')\\nmse_model = train('mse')\\n\\nprint('==================================================')\\nsqr_model = train('sqr')         \\n\\nprint('==================================================')\\nmlc_model = train('mlc')\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train models\n",
    "ensemble_bce = []\n",
    "ensemble_mse = []\n",
    "ensemble_sqr = []\n",
    "ensemble_mlc = []\n",
    "\n",
    "print('==================================================')\n",
    "for _ in range(3):\n",
    "    print(_, end = ' ')\n",
    "    ensemble_bce += [train('bce')]\n",
    "\n",
    "'''\n",
    "print('==================================================')\n",
    "mse_model = train('mse')\n",
    "\n",
    "print('==================================================')\n",
    "sqr_model = train('sqr')         \n",
    "\n",
    "print('==================================================')\n",
    "mlc_model = train('mlc')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(x):\n",
    "    return np.exp(-0.5*( (x - mu)**2 - (x + mu)**2))\n",
    "\n",
    "def bce_lr(x):\n",
    "    f = bce_model.predict(x)\n",
    "    return np.squeeze(f / (1. - f))\n",
    "\n",
    "def mse_lr(x):\n",
    "    f = mse_model.predict(x)\n",
    "    return np.squeeze(f / (1. - f))\n",
    "\n",
    "def sqr_lr(x):\n",
    "    f = sqr_model.predict(x)\n",
    "    return np.squeeze(f)\n",
    "\n",
    "def mlc_lr(x):\n",
    "    f = mlc_model.predict(x)\n",
    "    return np.squeeze(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make the below plots, but with average neural networks instead of a particular one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-6, 6, 1000)\n",
    "\n",
    "fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(xs, lr(xs), label = 'Exact', c = 'k', ls='-')\n",
    "plt.plot(xs, bce_lr(xs), label = 'BCE', c = 'brown', ls=':')\n",
    "plt.plot(xs, mse_lr(xs), label = 'MSE', c = 'green', ls='--')\n",
    "plt.plot(xs, sqr_lr(xs), label = 'SQR', c = 'blue', ls='-.')\n",
    "plt.plot(xs, mlc_lr(xs), label = 'MLC', c = 'red', ls='--')\n",
    "plt.legend()\n",
    "ax_1.minorticks_on()\n",
    "ax_1.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Likelihood Ratio')\n",
    "\n",
    "ax_2 = ax_1.twinx()\n",
    "bins = np.linspace(-6, 6, 100)\n",
    "plt.hist(sig, alpha=0.1, bins=bins)\n",
    "plt.hist(bgd, alpha=0.1, bins=bins)\n",
    "ax_2.minorticks_on()\n",
    "ax_2.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xlim(-6, 6)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "plt.savefig('plots/lrs.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(xs, bce_lr(xs) / lr(xs), label = 'BCE', c = 'brown', ls=':')\n",
    "plt.plot(xs, mse_lr(xs) / lr(xs), label = 'MSE', c = 'green', ls='--')\n",
    "plt.plot(xs, sqr_lr(xs) / lr(xs), label = 'SQR', c = 'blue', ls='-.')\n",
    "plt.plot(xs, mlc_lr(xs) / lr(xs), label = 'MLC', c = 'red', ls='--')\n",
    "plt.axhline(1,ls=\":\",color=\"grey\", lw=0.5)\n",
    "plt.axvline(0,ls=\":\",color=\"grey\", lw=0.5)\n",
    "plt.legend()\n",
    "ax_1.minorticks_on()\n",
    "ax_1.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylim(0.94, 1.06)\n",
    "plt.ylabel('Ratio')\n",
    "\n",
    "ax_2 = ax_1.twinx()\n",
    "bins = np.linspace(-6, 6, 100)\n",
    "plt.hist(sig, alpha=0.1, bins=bins)\n",
    "plt.hist(bgd, alpha=0.1, bins=bins)\n",
    "ax_2.minorticks_on()\n",
    "ax_2.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xlim(-6, 6)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "plt.savefig('plots/lr_ratios.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**np.arange(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = 10**np.arange(1, 10)\n",
    "mu = 0.1\n",
    "earlystopping = EarlyStopping(patience=10,\n",
    "                              verbose=1,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_models = []\n",
    "mse_models = []\n",
    "sqr_models = []\n",
    "mlc_models = []\n",
    "\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Generate data\n",
    "    bgd = np.random.normal(-mu, 1, N)\n",
    "    sig = np.random.normal(mu, 1, N)\n",
    "    X = np.concatenate([bgd, sig])\n",
    "    y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # BCE\n",
    "    bce_models.append(train('bce'))\n",
    "    \n",
    "    # MSE\n",
    "    mse_models.append(train('mse'))\n",
    "    \n",
    "    # SQR\n",
    "    sqr_models.append(train('sqr'))\n",
    "    \n",
    "    # MLC\n",
    "    mlc_models.append(train('mlc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(Ns)):\n",
    "    bce_models[i - 1].save_weights('models/bce_model_{}.h5'.format(i))\n",
    "    mse_models[i - 1].save_weights('models/mse_model_{}.h5'.format(i))\n",
    "    sqr_models[i - 1].save_weights('models/sqr_model_{}.h5'.format(i))\n",
    "    mlc_models[i - 1].save_weights('models/mlc_model_{}.h5'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bce_lr(model):\n",
    "    def model_bce_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f / (1. - f))\n",
    "    return model_bce_lr\n",
    "\n",
    "def get_mse_lr(model):\n",
    "    def model_mse_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f / (1. - f))\n",
    "    return model_mse_lr\n",
    "\n",
    "def get_sqr_lr(model):\n",
    "    def model_sqr_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f)\n",
    "    return model_sqr_lr\n",
    "\n",
    "def get_mlc_lr(model):\n",
    "    def model_mlc_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f)\n",
    "    return model_mlc_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute errors.\n",
    "\n",
    "N = 10**6\n",
    "\n",
    "bgd = np.random.normal(-mu, 1, N)\n",
    "sig = np.random.normal(mu, 1, N)\n",
    "X = np.concatenate([bgd, sig])\n",
    "\n",
    "bce_maes = []\n",
    "mse_maes = []\n",
    "sqr_maes = []\n",
    "mlc_maes = []\n",
    "for i in range(len(Ns)):\n",
    "    model_bce_lr = get_bce_lr(bce_models[i])\n",
    "    bce_maes += [np.mean(np.abs(model_bce_lr(X) - lr(X)))]\n",
    "    \n",
    "    model_mse_lr = get_mse_lr(mse_models[i])\n",
    "    mse_maes += [np.mean(np.abs(model_mse_lr(X) - lr(X)))]\n",
    "    \n",
    "    model_sqr_lr = get_sqr_lr(sqr_models[i])\n",
    "    sqr_maes += [np.mean(np.abs(model_sqr_lr(X) - lr(X)))]\n",
    "    \n",
    "    model_mlc_lr = get_mlc_lr(mlc_models[i])\n",
    "    mlc_maes += [np.mean(np.abs(model_mlc_lr(X) - lr(X)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(xs, model_bce_lr(xs) / lr(xs), label = 'BCE', c = 'brown', ls=':')\n",
    "plt.plot(xs, model_mse_lr(xs) / lr(xs), label = 'MSE', c = 'green', ls='--')\n",
    "plt.plot(xs, model_sqr_lr(xs) / lr(xs), label = 'SQR', c = 'blue', ls='-.')\n",
    "plt.plot(xs, model_mlc_lr(xs) / lr(xs), label = 'MLC', c = 'red', ls='--')\n",
    "plt.axhline(1,ls=\":\",color=\"grey\", lw=0.5)\n",
    "plt.axvline(0,ls=\":\",color=\"grey\", lw=0.5)\n",
    "plt.legend()\n",
    "ax_1.minorticks_on()\n",
    "ax_1.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylim(0.94, 1.06)\n",
    "plt.ylabel('Ratio')\n",
    "\n",
    "ax_2 = ax_1.twinx()\n",
    "bins = np.linspace(-6, 6, 100)\n",
    "plt.hist(sig, alpha=0.1, bins=bins)\n",
    "plt.hist(bgd, alpha=0.1, bins=bins)\n",
    "ax_2.minorticks_on()\n",
    "ax_2.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.xlim(-6, 6)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "plt.savefig('plots/lr_ratios.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(Ns[:-1], bce_maes, c='brown', ls=':', label='BCE')\n",
    "plt.plot(Ns[:-1], mse_maes, c='green', ls='--', label='MSE')\n",
    "plt.plot(Ns[:-1], sqr_maes, c='blue', ls='-.', label='SQR')\n",
    "plt.plot(Ns[:-1], mlc_maes, c='red', ls='--', label='MLC')\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\", basex=10)\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$N$')\n",
    "\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "plt.savefig('plots/ns_lr_ratios.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Lambda, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "    \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patches\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLC loss\n",
    "\n",
    "N = 100000\n",
    "\n",
    "theta0 = 0.1\n",
    "\n",
    "X_MC = np.random.normal(-theta0,1,N)\n",
    "X_data = np.random.normal(theta0,1,N)\n",
    "X_MLE_train, X_MLE_val, Y_MLE_train, Y_MLE_val = train_test_split(np.concatenate([X_data,X_MC]), np.concatenate([np.ones(len(X_data)),np.zeros(len(X_MC))]), test_size=0.5)\n",
    "\n",
    "\n",
    "def CustomLoss2(y_true, y_pred):\n",
    "    return -y_true*K.log(y_pred**2+0.00000001) + (1.-y_true)*y_pred**2\n",
    "\n",
    "def CustomLoss(y_true, y_pred):\n",
    "    return -y_true*K.log(y_pred+0.00000001) + (1.-y_true)*y_pred\n",
    "\n",
    "model_MLE2 = Sequential()\n",
    "model_MLE2.add(Dense(64, activation='relu',input_shape =(1,))) \n",
    "model_MLE2.add(Dense(128, activation='relu'))\n",
    "model_MLE2.add(Dense(64, activation='relu'))\n",
    "model_MLE2.add(Dense(1, activation='linear')) #was sigmoid\n",
    "model_MLE2.compile(loss=lambda y_true, y_pred: CustomLoss2(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "hist_MLE2 = model_MLE2.fit(X_MLE_train, Y_MLE_train, epochs=100, batch_size=int(0.01*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val),callbacks=[earlystopping])\n",
    "\n",
    "model_MLE = Sequential()\n",
    "model_MLE.add(Dense(64, activation='relu',input_shape =(1,))) \n",
    "model_MLE.add(Dense(128, activation='relu'))\n",
    "model_MLE.add(Dense(64, activation='relu'))\n",
    "model_MLE.add(Dense(1, activation='relu')) #was sigmoid\n",
    "model_MLE.compile(loss=lambda y_true, y_pred: CustomLoss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "hist_MLE = model_MLE.fit(X_MLE_train, Y_MLE_train, epochs=100, batch_size=int(0.01*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val),callbacks=[earlystopping])\n",
    "\n",
    "model_BCE = Sequential()\n",
    "model_BCE.add(Dense(64, activation='relu',input_shape =(1,))) \n",
    "model_BCE.add(Dense(128, activation='relu'))\n",
    "model_BCE.add(Dense(64, activation='relu'))\n",
    "model_BCE.add(Dense(1, activation='sigmoid'))\n",
    "model_BCE.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "hist_BCE = model_BCE.fit(X_MLE_train, Y_MLE_train, epochs=100, batch_size=int(0.01*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val),callbacks=[earlystopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.yaxis.set_ticks_position('both')\n",
    "ax1.xaxis.set_ticks_position('both')\n",
    "ax1.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax1.minorticks_on()\n",
    "\n",
    "xx = np.linspace(-3,3,100)\n",
    "preds_BCE = model_BCE.predict(xx)\n",
    "plotBCE = plt.plot(xx,preds_BCE/(1.-preds_BCE),label=\"NN (BCE)\",ls=\":\",lw=5,color='green')\n",
    "preds_test2 = model_MLE2.predict(xx)**2\n",
    "plot12 = plt.plot(xx,preds_test2,label=\"NN (MLC, squared)\",ls=\":\",color='green')\n",
    "preds_test = model_MLE.predict(xx)\n",
    "plot11 = plt.plot(xx,preds_test,label=\"NN (MLC, linear)\",ls=\"-\",color='green')\n",
    "plot2 = plt.plot(xx,np.exp(-((xx-theta0)**2-(xx+theta0)**2)/(2*1**2)),label=\"exact\",color='orange')\n",
    "plt.ylim([0,2])\n",
    "plt.axvline(0,ls=\":\",color=\"grey\")\n",
    "plt.axhline(1,ls=\":\",color=\"grey\")\n",
    "plt.xlabel(r\"$x$\",fontsize=20)\n",
    "plt.ylabel(\"likelihood ratio\",fontsize=20)\n",
    "plt.title(r\"$\\mu_{MC} = \"+str(theta0)+r\", \\mu_{data}=0.5$\",loc=\"right\",fontsize=20)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "_,_,_=plt.hist(X_MLE_train[Y_MLE_train==0],bins=np.linspace(-3,3,50),alpha=0.3,label=\"Back.\",color='red')\n",
    "_,_,_=plt.hist(X_MLE_train[Y_MLE_train==1],bins=np.linspace(-3,3,50),alpha=0.3,label=\"Signal\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "ax2.set_ylabel(\"histogram\",color='red',fontsize=20)\n",
    "\n",
    "for label in ax2.yaxis.get_majorticklabels():\n",
    "        label.set_fontsize(20)\n",
    "\n",
    "leg = plt.legend([plotBCE[0], plot11[0],plot12[0],plot2[0]],['BCE', 'MLC, linear','MLC, squared','Exact'], loc=\"upper left\",frameon=False,fontsize=18)\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.gca().add_artist(leg)\n",
    "\n",
    "#plt.savefig(\"ensembleLearnPlots/MLCloss.pdf\",bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnifold",
   "language": "python",
   "name": "omifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
