{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import rc\n",
    "import matplotlib.font_manager\n",
    "rc('font', family='serif')\n",
    "rc('text', usetex=True)\n",
    "rc('font', size=22)\n",
    "rc('xtick', labelsize=15)\n",
    "rc('ytick', labelsize=15)\n",
    "rc('legend', fontsize=15)\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 21:27:35.738114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-23 21:28:03.996542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-23 21:28:03.996930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-23 21:28:03.999577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-23 21:28:04.002533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-23 21:28:04.002947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-23 21:28:04.005939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-23 21:28:04.007580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-23 21:28:04.012390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-23 21:28:04.015631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "N = 10**6\n",
    "mu = 0.1\n",
    "sigma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the data.\n",
    "\n",
    "# Background is Normal(-μ, 1)\n",
    "# Signal is Normal(μ, 1))\n",
    "bkgd = np.random.normal(-mu, sigma, N)\n",
    "sgnl = np.random.normal(mu, sigma, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "def bce(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + (1. - y_true) * K.log(1. - y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return -((y_true) * -K.square(1. - y_pred) + (1. - y_true) * -K.square(y_pred + K.epsilon()))\n",
    "\n",
    "def sqr(y_true, y_pred):\n",
    "    return -((y_true) * -1. / K.sqrt(y_pred + K.epsilon()) + (1. - y_true) * -K.sqrt(y_pred + K.epsilon()))\n",
    "\n",
    "def mlc(y_true, y_pred):\n",
    "    return -((y_true) * K.log(y_pred + K.epsilon()) + (1. - y_true) * (1. - y_pred))\n",
    "\n",
    "def square_mlc(y_true, y_pred):\n",
    "    return -((y_true) * K.log( (y_pred + K.epsilon())**2 ) + (1. - y_true) * (1. - y_pred**2))\n",
    "\n",
    "def exp_mlc(y_true, y_pred):\n",
    "    return -((y_true) * y_pred + (1. - y_true) * (1. - K.exp(y_pred)))\n",
    "        \n",
    "# Likelihood ratios\n",
    "def lr(x):\n",
    "    return np.exp(-(1/(2 * sigma**2)) * ( (x - mu)**2 - (x + mu)**2))\n",
    "\n",
    "def get_bce_lr(model):\n",
    "    def model_bce_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f / (1. - f))\n",
    "    return model_bce_lr\n",
    "\n",
    "def get_mse_lr(model):\n",
    "    def model_mse_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f / (1. - f))\n",
    "    return model_mse_lr\n",
    "\n",
    "def get_mlc_lr(model):\n",
    "    def model_mlc_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f)\n",
    "    return model_mlc_lr\n",
    "\n",
    "def get_square_mlc_lr(model):\n",
    "    def model_square_mlc_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f**2)\n",
    "    return model_square_mlc_lr\n",
    "\n",
    "def get_exp_mlc_lr(model):\n",
    "    def model_exp_mlc_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(np.exp(f))\n",
    "    return model_exp_mlc_lr\n",
    "\n",
    "def get_sqr_lr(model):\n",
    "    def model_sqr_lr(x):\n",
    "        f = model.predict(x)\n",
    "        return np.squeeze(f)\n",
    "    return model_sqr_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(patience=10,\n",
    "                              verbose=0,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "def train(loss, \n",
    "          hidden='relu', \n",
    "          output='sigmoid', \n",
    "          dropout=True, \n",
    "          optimizer='adam', \n",
    "          metrics=['accuracy'], \n",
    "          verbose=0):\n",
    "    model = Sequential()\n",
    "    if dropout:\n",
    "        model.add(Dense(64, activation=hidden, input_shape=(1, )))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(128, activation=hidden))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(64, activation=hidden))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Dense(1, activation=output))\n",
    "    else: \n",
    "        model.add(Dense(64, activation=hidden, input_shape=(1, )))\n",
    "        model.add(Dense(128, activation=hidden))\n",
    "        model.add(Dense(64, activation=hidden))\n",
    "        model.add(Dense(1, activation=output))        \n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    trace = model.fit(X_train, \n",
    "                      y_train,\n",
    "                      epochs = 100, \n",
    "                      batch_size=int(0.1*N), \n",
    "                      validation_data=(X_test, y_test),\n",
    "                      callbacks=[earlystopping], \n",
    "                      verbose=verbose)\n",
    "    print(trace.history['val_loss'][-1], end = ' ')\n",
    "    \n",
    "    lr_match = {bce: get_bce_lr, \n",
    "                mse: get_mse_lr, \n",
    "                mlc: get_mlc_lr,\n",
    "                square_mlc: get_square_mlc_lr,\n",
    "                exp_mlc: get_exp_mlc_lr,\n",
    "                sqr: get_sqr_lr}\n",
    "    model_lr = lr_match[loss](model)\n",
    "    \n",
    "    return model, model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def get_preds(model_lrs, xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in model_lrs, a list of model likelihood ratios and xs, a list of \n",
    "    # values on which to compute the likelihood ratios. Returns a 2D array. The \n",
    "    # nth row is the likelihood ratio predictions from the nth model in \n",
    "    # model_lrs.\n",
    "    return np.array([model_lr(xs) for model_lr in model_lrs])\n",
    "    \n",
    "def avg_lr(preds):\n",
    "    # Takes in a 2D array of multiple models' likelihood ratio predictions. \n",
    "    # Returns the average likelihood ratio prediction and its error.\n",
    "    return preds.mean(axis=0), preds.std(axis=0)\n",
    "\n",
    "def avg_lrr(preds, xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a 2D array of multiple models' likelihood ratio predictions. \n",
    "    # Returns the average ratio of predicted likelihood to true likelihood and \n",
    "    # its error.\n",
    "    lrr_preds = preds / lr(xs)\n",
    "    return lrr_preds.mean(axis=0), lrr_preds.std(axis=0)\n",
    "    \n",
    "def lr_plot(ensembles,\n",
    "            filename=None,\n",
    "            cs = ['brown', 'green', 'red', 'blue'],\n",
    "            lss = [':', '--', '-.', ':'],\n",
    "            xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a list of pairs (lr_avg, lr_err). Plots them against the true \n",
    "    # likelihood.\n",
    "    fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "    \n",
    "    # Plot true likelihood\n",
    "    plt.plot(xs, lr(xs), label = 'Exact', c='k', ls='-')\n",
    "    \n",
    "    # Plot model likelihoods\n",
    "    for i in range(len(ensembles)):\n",
    "        avg, err, lbl = ensembles[i]\n",
    "        plt.plot(xs, avg, label=lbl, c=cs[i], ls=lss[i])\n",
    "        plt.fill_between(xs, avg - err, avg + err, color=cs[i], alpha=0.1)\n",
    "    plt.legend()\n",
    "    ax_1.minorticks_on()\n",
    "    ax_1.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Likelihood Ratio')\n",
    "\n",
    "    # Plot background and signal\n",
    "    ax_2 = ax_1.twinx()\n",
    "    bins = np.linspace(-6, 6, 100)\n",
    "    plt.hist(sgnl, alpha=0.1, bins=bins)\n",
    "    plt.hist(bkgd, alpha=0.1, bins=bins)\n",
    "    ax_2.minorticks_on()\n",
    "    ax_2.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "    if filename != None:\n",
    "        plt.savefig(filename, dpi=1200, bbox_inches='tight')\n",
    "\n",
    "def lrr_plot(ensembles,\n",
    "             filename=None,\n",
    "             cs = ['brown', 'green', 'red', 'blue'],\n",
    "             lss = [':', '--', '-.', ':'],\n",
    "             xs=np.linspace(-6, 6, 1000)):\n",
    "    # Takes in a list of pairs (lrr_avg, lrr_err). Plots them.\n",
    "    fig, ax_1 = plt.subplots(figsize = (10, 6))\n",
    "    \n",
    "    # Plot ratios of likelihood ratios\n",
    "    for i in range(len(ensembles)):\n",
    "        avg, err, lbl = ensembles[i]\n",
    "        plt.plot(xs, avg, label=lbl, c=cs[i], ls=lss[i])\n",
    "        plt.fill_between(xs, avg - err, avg + err, color=cs[i], alpha=0.1)\n",
    "    plt.axhline(1,ls=\":\",color=\"grey\", lw=0.5)\n",
    "    plt.axvline(0,ls=\":\",color=\"grey\", lw=0.5)\n",
    "    plt.legend()\n",
    "    ax_1.minorticks_on()\n",
    "    ax_1.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylim(0.94, 1.06)\n",
    "    plt.ylabel('Ratio')\n",
    "\n",
    "    # Plot background and signal\n",
    "    ax_2 = ax_1.twinx()\n",
    "    bins = np.linspace(-6, 6, 100)\n",
    "    plt.hist(sgnl, alpha=0.1, bins=bins)\n",
    "    plt.hist(bkgd, alpha=0.1, bins=bins)\n",
    "    ax_2.minorticks_on()\n",
    "    ax_2.tick_params(direction='in', which='both',length=5)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20)\n",
    "    if filename != None:\n",
    "        plt.savefig(filename, dpi=1200, bbox_inches='tight')\n",
    "    \n",
    "#def mae_plot(model_lrs):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Reweighting Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100\n",
    "\n",
    "# model parameters\n",
    "params_1 = {'loss':mlc, 'hidden':'relu', 'output':'relu'}\n",
    "params_2 = {'loss':square_mlc, 'hidden':'relu', 'output':'linear'}\n",
    "params_3 = {'loss':exp_mlc, 'hidden':'relu', 'output':'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "models_1 = [None] * reps\n",
    "models_2 = [None] * reps\n",
    "models_3 = [None] * reps\n",
    "\n",
    "lrs_1 = [None] * reps\n",
    "lrs_2 = [None] * reps\n",
    "lrs_3 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    models_1[i], lrs_1[i] = train(**params_1)\n",
    "    models_2[i], lrs_2[i] = train(**params_2)\n",
    "    models_3[i], lrs_3[i] = train(**params_3)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(reps):\n",
    "    models_1[i].save_weights('models/ratios/mlc/mlc_model_{}.h5'.format(i))\n",
    "    models_2[i].save_weights('models/ratios/mlc/square_mlc_model_{}.h5'.format(i))\n",
    "    models_3[i].save_weights('models/ratios/mlc/exp_mlc_model_{}.h5'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels to \n",
    "# make plotting easier.\n",
    "lr_1 = avg_lr(get_preds(lrs_1)) + ('linear',)\n",
    "lr_2 = avg_lr(get_preds(lrs_2)) + ('square',)\n",
    "lr_3 = avg_lr(get_preds(lrs_3)) + ('exponential',)\n",
    "\n",
    "lrr_1 = avg_lrr(get_preds(lrs_1)) + ('linear',)\n",
    "lrr_2 = avg_lrr(get_preds(lrs_2)) + ('square',)\n",
    "lrr_3 = avg_lrr(get_preds(lrs_3)) + ('exponential',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([lr_1, lr_2, lr_3], 'plots/mlc_param_lr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([lrr_1, lrr_2, lrr_3], 'plots/mlc_param_lrrs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100\n",
    "\n",
    "bce_params = {'loss':bce}\n",
    "mse_params = {'loss':mse}\n",
    "mlc_params = {'loss':exp_mlc, 'hidden':'relu', 'output':'linear'}\n",
    "sqr_params = {'loss':sqr, 'output':'relu'}\n",
    "\n",
    "Ns = 10**np.arange(2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(model_lr):\n",
    "    # Takes in model_lr, a model likelihood ratio. Returns the expected absolute\n",
    "    # error for that model.\n",
    "    return np.abs(model_lr(X) - lr(X)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 21:28:04.523623: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-03-23 21:28:04.530694: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2994530000 Hz\n",
      "2022-03-23 21:28:04.531874: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7adb1c4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-23 21:28:04.531900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-23 21:28:04.640794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7adb863d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-23 21:28:04.640824: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 6000, Compute Capability 7.5\n",
      "2022-03-23 21:28:04.642168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-03-23 21:28:04.642217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-23 21:28:04.642229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-23 21:28:04.642240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-23 21:28:04.642251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-23 21:28:04.642261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-23 21:28:04.642272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-23 21:28:04.642282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-23 21:28:04.644667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-03-23 21:28:04.644694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-23 21:28:04.646545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-23 21:28:04.646555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-03-23 21:28:04.646562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-03-23 21:28:04.649332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21896 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-03-23 21:28:05.407050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6990693807601929 \n",
      "1 0.6992847919464111 \n",
      "2 0.6991275548934937 \n",
      "3 0.6978055834770203 \n",
      "4 0.7003640532493591 \n",
      "5 0.7020862102508545 \n",
      "6 0.7002569437026978 \n",
      "7 0.7039097547531128 \n",
      "8 0.6994238495826721 \n",
      "9 0.7010352611541748 \n",
      "10 0.7036917209625244 \n",
      "11 0.6981343030929565 \n",
      "12 0.7014122009277344 \n",
      "13 0.6966906189918518 \n",
      "14 0.697354793548584 \n",
      "15 0.7018502950668335 \n",
      "16 0.6980582475662231 \n",
      "17 0.7014383673667908 \n",
      "18 0.6979420185089111 \n",
      "19 "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bce_models = {}\n",
    "bce_lrs = {}\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    bce_models[N] = [None] * reps\n",
    "    bce_lrs[N] = [None] * reps\n",
    "    \n",
    "    # Generate data\n",
    "    bkgd = np.random.normal(-mu, 1, N)\n",
    "    sgnl = np.random.normal(mu, 1, N)\n",
    "    X = np.concatenate([bkgd, sgnl])\n",
    "    y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        bce_models[N][i], bce_lrs[N][i] = train(**bce_params)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute errors.\n",
    "\n",
    "N = 10**4\n",
    "\n",
    "bkgd = np.random.normal(-mu, 1, N)\n",
    "sgnl = np.random.normal(mu, 1, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "\n",
    "bce_mae_avg = []\n",
    "bce_mae_err = []\n",
    "for N in Ns:\n",
    "    bce_maes = [mae(lr) for lr in bce_lrs[N]]\n",
    "    \n",
    "    bce_mae_avg += [np.mean(bce_maes)]\n",
    "    bce_mae_err += [np.std(bce_maes)]\n",
    "\n",
    "bce_mae_avg = np.array(bce_mae_avg)\n",
    "bce_mae_err = np.array(bce_mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    for i in range(reps):\n",
    "        bce_models[N][i].save_weights('models/maes/bce/bce_model_{}_{}.h5'.format(N, i))\n",
    "\n",
    "np.save('lr_data/bce_mae_avg.npy', bce_mae_avg)\n",
    "np.save('lr_data/bce_mae_err.npy', bce_mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bce_models = {}\n",
    "mse_models = {}\n",
    "mlc_models = {}\n",
    "sqr_models = {}\n",
    "\n",
    "bce_lrs = {}\n",
    "mse_lrs = {}\n",
    "mlc_lrs = {}\n",
    "sqr_lrs = {}\n",
    "\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Set up lists\n",
    "    bce_models[N] = [None] * reps\n",
    "    mse_models[N] = [None] * reps\n",
    "    mlc_models[N] = [None] * reps\n",
    "    sqr_models[N] = [None] * reps\n",
    "    \n",
    "    bce_lrs[N] = [None] * reps\n",
    "    mse_lrs[N] = [None] * reps\n",
    "    mlc_lrs[N] = [None] * reps\n",
    "    sqr_lrs[N] = [None] * reps\n",
    "    \n",
    "    # Generate data\n",
    "    bkgd = np.random.normal(-mu, 1, N)\n",
    "    sgnl = np.random.normal(mu, 1, N)\n",
    "    X = np.concatenate([bkgd, sgnl])\n",
    "    y = np.concatenate([np.zeros(N), np.ones(N)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        bce_lrs[N][i] = train(**bce_params)[1]\n",
    "        mse_lrs[N][i] = train(**mse_params)[1]\n",
    "        mlc_lrs[N][i] = train(**mlc_params)[1]\n",
    "        sqr_lrs[N][i] = train(**sqr_params)[1]\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate mean absolute errors.\n",
    "\n",
    "N = 10**3\n",
    "\n",
    "bkgd = np.random.normal(-mu, 1, N)\n",
    "sgnl = np.random.normal(mu, 1, N)\n",
    "X = np.concatenate([bkgd, sgnl])\n",
    "\n",
    "bce_mae_avg = []\n",
    "mse_mae_avg = []\n",
    "mlc_mae_avg = []\n",
    "sqr_mae_avg = []\n",
    "\n",
    "bce_mae_err = []\n",
    "mse_mae_err = []\n",
    "mlc_mae_err = []\n",
    "sqr_mae_err = []\n",
    "\n",
    "for N in Ns:\n",
    "    bce_maes = [mae(lr) for lr in bce_lrs[N]]\n",
    "    mse_maes = [mae(lr) for lr in mse_lrs[N]]\n",
    "    mlc_maes = [mae(lr) for lr in mlc_lrs[N]]\n",
    "    sqr_maes = [mae(lr) for lr in sqr_lrs[N]]\n",
    "    \n",
    "    bce_mae_avg += [np.mean(bce_maes)]\n",
    "    bce_mae_err += [np.std(bce_maes)]\n",
    "    mse_mae_avg += [np.mean(mse_maes)]\n",
    "    mse_mae_err += [np.std(mse_maes)]\n",
    "    \n",
    "    mlc_mae_avg += [np.mean(mlc_maes)]\n",
    "    mlc_mae_err += [np.std(mlc_maes)]\n",
    "    \n",
    "    sqr_mae_avg += [np.mean(sqr_maes)]\n",
    "    sqr_mae_err += [np.std(sqr_maes)]\n",
    "\n",
    "bce_mae_avg = np.array(bce_mae_avg)\n",
    "mse_mae_avg = np.array(mse_mae_avg)\n",
    "mlc_mae_avg = np.array(mlc_mae_avg)\n",
    "sqr_mae_avg = np.array(sqr_mae_avg)\n",
    "\n",
    "bce_mae_err = np.array(bce_mae_err)\n",
    "mse_mae_err = np.array(mse_mae_err)\n",
    "mlc_mae_err = np.array(mlc_mae_err)\n",
    "sqr_mae_err = np.array(sqr_mae_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "\n",
    "plt.plot(Ns, bce_mae_avg, c='brown', ls=':', label='BCE')\n",
    "plt.plot(Ns, mse_mae_avg, c='green', ls='--', label='MSE')\n",
    "plt.plot(Ns, mlc_mae_avg, c='red', ls='--', label='MLC')\n",
    "plt.plot(Ns, sqr_mae_avg, c='blue', ls='-.', label='SQR')\n",
    "plt.fill_between(Ns, bce_mae_avg - bce_mae_err, bce_mae_avg + bce_mae_err, color='brown', alpha=0.1)\n",
    "plt.fill_between(Ns, mse_mae_avg - mse_mae_err, mse_mae_avg + mse_mae_err, color='green', alpha=0.1)\n",
    "plt.fill_between(Ns, mlc_mae_avg - mlc_mae_err, mlc_mae_avg + mlc_mae_err, color='red', alpha=0.1)\n",
    "plt.fill_between(Ns, sqr_mae_avg - sqr_mae_err, sqr_mae_avg + sqr_mae_err, color='blue', alpha=0.1)\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\", base=10)\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(direction='in', which='both',length=5)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel(r'$N$')\n",
    "\n",
    "plt.title(r\"$\\mu_{\\rm{sgnl}}=\"+str(mu)+r\", \\mu_{\\rm{bkgd}}=\"+str(-mu)+r\"$\",loc=\"right\",fontsize=20);\n",
    "plt.savefig('plots/maes.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 10\n",
    "\n",
    "# Parameters to compare\n",
    "params_1 = {'loss':sqr, 'hidden':'relu', 'output':'relu'}\n",
    "params_2 = {'loss':sqr, 'hidden':'relu', 'output':'elu'}\n",
    "params_3 = {'loss':sqr, 'hidden':'elu', 'output':'relu'}\n",
    "params_4 = {'loss':sqr, 'hidden':'elu', 'output':'elu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "models_1 = [None] * reps\n",
    "models_2 = [None] * reps\n",
    "models_3 = [None] * reps\n",
    "models_4 = [None] * reps\n",
    "\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    models_1[i] = train(**params_1)[1]\n",
    "    models_2[i] = train(**params_2)[1]\n",
    "    models_3[i] = train(**params_3)[1]\n",
    "    models_4[i] = train(**params_4)[1]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average predictions and errors. Add on the labels to \n",
    "# make plotting easier.\n",
    "sqr_lr_1 = avg_lr(get_preds(models_1)) + ('ReLU/ReLU',)\n",
    "sqr_lr_2 = avg_lr(get_preds(models_2)) + ('ReLU/ELU',)\n",
    "sqr_lr_3 = avg_lr(get_preds(models_3)) + ('ELU/ReLU',)\n",
    "sqr_lr_4 = avg_lr(get_preds(models_4)) + ('ELU/ELU',)\n",
    "\n",
    "sqr_lrr_1 = avg_lrr(get_preds(models_1)) + ('ReLU/ReLU',)\n",
    "sqr_lrr_2 = avg_lrr(get_preds(models_2)) + ('ReLU/ELU',)\n",
    "sqr_lrr_3 = avg_lrr(get_preds(models_3)) + ('ELU/ReLU',)\n",
    "sqr_lrr_4 = avg_lrr(get_preds(models_4)) + ('ELU/ELU',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_plot([sqr_lr_1, sqr_lr_2, sqr_lr_3, sqr_lr_4], 'plots/sqr_lr_comparisons.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_plot([sqr_lrr_1, sqr_lrr_2, sqr_lrr_3, sqr_lrr_4], 'plots/sqr_lrr_comparisons.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = np.linspace(-6, 6, 1000)\n",
    "\n",
    "sqr_lrs_1 = np.array([sqr_lr(xs) for sqr_lr in models_1[100:200]])\n",
    "sqr_lrs_2 = np.array([sqr_lr(xs) for sqr_lr in models_2[100:200]])\n",
    "sqr_lrs_3 = np.array([sqr_lr(xs) for sqr_lr in models_3[100:200]])\n",
    "sqr_lrs_4 = np.array([sqr_lr(xs) for sqr_lr in models_4[100:200]])\n",
    "\n",
    "lrr_1 = sqr_lrs_1 / lr(xs)\n",
    "lrr_2 = sqr_lrs_2 / lr(xs)\n",
    "lrr_3 = sqr_lrs_3 / lr(xs)\n",
    "lrr_4 = sqr_lrs_4 / lr(xs)\n",
    "\n",
    "lrr_bar_1 = lrr_1.mean(axis=0)\n",
    "lrr_bar_2 = lrr_2.mean(axis=0)\n",
    "lrr_bar_3 = lrr_3.mean(axis=0)\n",
    "lrr_bar_4 = lrr_4.mean(axis=0)\n",
    "\n",
    "lrr_err_1 = lrr_1.std(axis=0)\n",
    "lrr_err_2 = lrr_2.std(axis=0)\n",
    "lrr_err_3 = lrr_3.std(axis=0)\n",
    "lrr_err_4 = lrr_4.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(xs, lrr_bar_1, label = 'relu/relu', c = 'brown', ls=':')\n",
    "plt.plot(xs, lrr_bar_2, label = 'relu/elu', c = 'green', ls='--')\n",
    "plt.plot(xs, lrr_bar_3, label = 'elu/relu', c = 'blue', ls='-.')\n",
    "plt.plot(xs, lrr_bar_4, label = 'elu/elu', c = 'red', ls='--')\n",
    "plt.fill_between(xs, lrr_bar_1 - lrr_err_1, lrr_bar_1 + lrr_err_1, color='brown', alpha=0.1)\n",
    "plt.fill_between(xs, lrr_bar_2 - lrr_err_2, lrr_bar_2 + lrr_err_2, color='green', alpha=0.1)\n",
    "plt.fill_between(xs, lrr_bar_3 - lrr_err_3, lrr_bar_3 + lrr_err_3, color='blue', alpha=0.1)\n",
    "plt.fill_between(xs, lrr_bar_4 - lrr_err_4, lrr_bar_4 + lrr_err_4, color='red', alpha=0.1)\n",
    "plt.axhline(1,ls=\":\",color=\"grey\", lw=0.5)\n",
    "plt.axvline(0,ls=\":\",color=\"grey\", lw=0.5)\n",
    "plt.legend()\n",
    "plt.savefig('plots/sqr_cmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mae(data):\n",
    "    return np.abs(data - lr(xs)).sum(axis=1).mean(axis=0)\n",
    "\n",
    "mae(sqr_lrs_1), mae(sqr_lrs_2), mae(sqr_lrs_3), mae(sqr_lrs_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs, lr(xs), c='k', label='exact')\n",
    "plt.plot(xs, bce_rs_mean, c='green', label='relu/relu')\n",
    "plt.plot(xs, bce_es_mean, c='red', label='elu/elu')\n",
    "\n",
    "plt.fill_between(xs, bce_rs_mean - bce_rs_err, bce_rs_mean + bce_rs_err, color='green', alpha=0.1)\n",
    "plt.fill_between(xs, bce_es_mean - bce_es_err, bce_es_mean + bce_es_err, color='red', alpha=0.1)\n",
    "plt.legend();\n",
    "plt.ylim(0, 4)\n",
    "plt.savefig('plots/avg_lr_mlc_ee_rr_2.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs, bce_rs_mean / lr(xs), c='green', label='relu/relu')\n",
    "plt.plot(xs, bce_es_mean / lr(xs), c='red', label='elu/elu')\n",
    "plt.fill_between(xs, bce_rsr_mean - bce_rsr_err, bce_rsr_mean + bce_rsr_err, color='green', alpha=0.1)\n",
    "plt.fill_between(xs, bce_esr_mean - bce_esr_err, bce_esr_mean + bce_esr_err, color='red', alpha=0.1)\n",
    "\n",
    "#plt.ylim(0.5, 1.5)\n",
    "plt.legend();\n",
    "plt.savefig('plots/avg_lrr_mlc_eerr_1.png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc_rs_maes = []\n",
    "mlc_es_maes = []\n",
    "\n",
    "# This should be a sum\n",
    "for i in range(100):\n",
    "    model_mlc_lr = get_mlc_lr(bce_rs_models[i])\n",
    "    mlc_rs_maes += [np.mean(np.abs(model_mlc_lr(X) - lr(X)))]\n",
    "    \n",
    "    model_mlc_lr = get_mlc_lr(bce_es_models[i])\n",
    "    mlc_es_maes += [np.mean(np.abs(model_mlc_lr(X) - lr(X)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "22 mins sqr rs/es\n",
    "20 mins sqr rr/ee\n",
    "30 mins mlc rr/ee dropout\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Lambda, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "    \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patches\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLC loss\n",
    "\n",
    "N = 100000\n",
    "\n",
    "theta0 = 0.1\n",
    "\n",
    "X_MC = np.random.normal(-theta0,1,N)\n",
    "X_data = np.random.normal(theta0,1,N)\n",
    "X_MLE_train, X_MLE_val, Y_MLE_train, Y_MLE_val = train_test_split(np.concatenate([X_data,X_MC]), np.concatenate([np.ones(len(X_data)),np.zeros(len(X_MC))]), test_size=0.5)\n",
    "\n",
    "\n",
    "def CustomLoss2(y_true, y_pred):\n",
    "    return -y_true*K.log(y_pred**2+0.00000001) + (1.-y_true)*y_pred**2\n",
    "\n",
    "def CustomLoss(y_true, y_pred):\n",
    "    return -y_true*K.log(y_pred+0.00000001) + (1.-y_true)*y_pred\n",
    "\n",
    "model_MLE2 = Sequential()\n",
    "model_MLE2.add(Dense(64, activation='relu',input_shape =(1,))) \n",
    "model_MLE2.add(Dense(128, activation='relu'))\n",
    "model_MLE2.add(Dense(64, activation='relu'))\n",
    "model_MLE2.add(Dense(1, activation='linear')) #was sigmoid\n",
    "model_MLE2.compile(loss=lambda y_true, y_pred: CustomLoss2(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "hist_MLE2 = model_MLE2.fit(X_MLE_train, Y_MLE_train, epochs=100, batch_size=int(0.01*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val),callbacks=[earlystopping])\n",
    "\n",
    "model_MLE = Sequential()\n",
    "model_MLE.add(Dense(64, activation='relu',input_shape =(1,))) \n",
    "model_MLE.add(Dense(128, activation='relu'))\n",
    "model_MLE.add(Dense(64, activation='relu'))\n",
    "model_MLE.add(Dense(1, activation='relu')) #was sigmoid\n",
    "model_MLE.compile(loss=lambda y_true, y_pred: CustomLoss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "hist_MLE = model_MLE.fit(X_MLE_train, Y_MLE_train, epochs=100, batch_size=int(0.01*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val),callbacks=[earlystopping])\n",
    "\n",
    "model_BCE = Sequential()\n",
    "model_BCE.add(Dense(64, activation='relu',input_shape =(1,))) \n",
    "model_BCE.add(Dense(128, activation='relu'))\n",
    "model_BCE.add(Dense(64, activation='relu'))\n",
    "model_BCE.add(Dense(1, activation='sigmoid'))\n",
    "model_BCE.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "hist_BCE = model_BCE.fit(X_MLE_train, Y_MLE_train, epochs=100, batch_size=int(0.01*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val),callbacks=[earlystopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.yaxis.set_ticks_position('both')\n",
    "ax1.xaxis.set_ticks_position('both')\n",
    "ax1.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax1.minorticks_on()\n",
    "\n",
    "xx = np.linspace(-3,3,100)\n",
    "preds_BCE = model_BCE.predict(xx)\n",
    "plotBCE = plt.plot(xx,preds_BCE/(1.-preds_BCE),label=\"NN (BCE)\",ls=\":\",lw=5,color='green')\n",
    "preds_test2 = model_MLE2.predict(xx)**2\n",
    "plot12 = plt.plot(xx,preds_test2,label=\"NN (MLC, squared)\",ls=\":\",color='green')\n",
    "preds_test = model_MLE.predict(xx)\n",
    "plot11 = plt.plot(xx,preds_test,label=\"NN (MLC, linear)\",ls=\"-\",color='green')\n",
    "plot2 = plt.plot(xx,np.exp(-((xx-theta0)**2-(xx+theta0)**2)/(2*1**2)),label=\"exact\",color='orange')\n",
    "plt.ylim([0,2])\n",
    "plt.axvline(0,ls=\":\",color=\"grey\")\n",
    "plt.axhline(1,ls=\":\",color=\"grey\")\n",
    "plt.xlabel(r\"$x$\",fontsize=20)\n",
    "plt.ylabel(\"likelihood ratio\",fontsize=20)\n",
    "plt.title(r\"$\\mu_{MC} = \"+str(theta0)+r\", \\mu_{data}=0.5$\",loc=\"right\",fontsize=20)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "_,_,_=plt.hist(X_MLE_train[Y_MLE_train==0],bins=np.linspace(-3,3,50),alpha=0.3,label=\"Back.\",color='red')\n",
    "_,_,_=plt.hist(X_MLE_train[Y_MLE_train==1],bins=np.linspace(-3,3,50),alpha=0.3,label=\"Signal\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "ax2.set_ylabel(\"histogram\",color='red',fontsize=20)\n",
    "\n",
    "for label in ax2.yaxis.get_majorticklabels():\n",
    "        label.set_fontsize(20)\n",
    "\n",
    "leg = plt.legend([plotBCE[0], plot11[0],plot12[0],plot2[0]],['BCE', 'MLC, linear','MLC, squared','Exact'], loc=\"upper left\",frameon=False,fontsize=18)\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.gca().add_artist(leg)\n",
    "\n",
    "#plt.savefig(\"ensembleLearnPlots/MLCloss.pdf\",bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnifold",
   "language": "python",
   "name": "omnifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
