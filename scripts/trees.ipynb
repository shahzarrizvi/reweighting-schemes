{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ced574-924b-4fd3-9444-614365da7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules after executing each cell.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2777dc-b825-4800-bc82-d1b23953c263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump, load \n",
    "\n",
    "# Utility imports\n",
    "from utils.losses import *\n",
    "from utils.plotting import *\n",
    "from utils.training import *\n",
    "\n",
    "np.random.seed(666) # Need to do more to ensure data is the same across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c301cf-f760-4479-aeef-27c5a063035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" # pick a number < 4 on ML4HEP; < 3 on Voltan \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eff551-de89-49c5-a2c0-a1c15ae11183",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526a150-2df1-4284-b6da-d1b4959d5352",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $d = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cae75b-8b8b-44bb-a06d-78c677817809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 1\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d)).reshape(-1, 1)\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')\n",
    "\n",
    "bkgd = stats.norm(-0.1, 1)\n",
    "sgnl = stats.norm(+0.1, 1)\n",
    "\n",
    "lr = make_lr(bkgd, sgnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c89e58-6e56-4b84-9385-049327bed049",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10**6\n",
    "data, m, s = split_data(X[:N], y[:N])\n",
    "\n",
    "bce_lrs = [None] * reps\n",
    "gbc_lrs = [None] * reps\n",
    "for i in range(reps):\n",
    "    print(i, end = ' ')\n",
    "    bce_model = create_model(**bce_params)\n",
    "    bce_model.load_weights(bce_filestr.format(N, i))\n",
    "    bce_lrs[i] = odds_lr(bce_model, m, s)\n",
    "\n",
    "    gbc_model = load(gbc_filestr.format(N, i))\n",
    "    gbc_lrs[i] = tree_lr(gbc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856c227-271c-440f-95d0-3e93becf92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-6, 6, 1201).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca7c19-d2bc-4bc6-b872-8a44b142272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_preds = get_preds(bce_lrs, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a6431-0b68-4d35-a8c3-8c37c3ea4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_preds = get_preds(gbc_lrs, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130a1cc-e58a-4743-9016-e06387cf46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bce = bce_preds.mean(axis = 0)\n",
    "avg_gbc = gbc_preds.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e0a31-4089-402d-ab48-f62fb0d35123",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_plot([bce_preds, gbc_preds], ['BCE', 'GBC'], lr, xs.reshape(-1), \n",
    "           figsize = (w, h), title = '\\it Likelihood Ratio Models', \n",
    "           filename = 'plots/lr_models.png') "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2945cb9-735d-4029-a433-32efe7aa5f8b",
   "metadata": {},
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d6730-4b33-40bd-8abb-acf1be1d2f30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12422843-2cf2-4280-b1b4-aae3127e5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 2\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a1f4c-7d62-4617-9eaf-1c2ab3f56bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d942469-7ef3-4907-87eb-c9296e3409bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f85bd-b60b-473c-bcc8-373a9d120f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 4\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3e63d-4966-43eb-af89-f6ae1d3370eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(91, reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b039a-fa91-4a35-8233-c4a017babc44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d=8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81baf6-0352-4b70-bcc8-ff37baeac13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 8\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72def4-b63c-46e2-92d5-1d724b5d079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b33f6-be09-404b-bbca-7e567a651b1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d=16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78be7a-1c20-4cde-bd24-d5a46012377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 16\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5262859-deb7-413f-b674-9c84a157ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca2309-9077-432f-933c-77be9ede35e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f08136-c5dc-4649-989b-4f4cea166cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 32\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/trees/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/trees/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/trees/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9e44b-a9fb-49c9-923d-9c414e2c6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        #bce_model, trace = train(data, **bce_params)\n",
    "        #bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed990a-9a86-46df-a2b5-45d88cdb0e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Zenodo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7beb4-a137-4bfc-a7a5-5cbc00b6b5ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982a7583-5b0d-48b8-b4f1-c37fda6ba098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 1\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d)).reshape(-1, 1)\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa8fdd1-bf3c-49dd-9e78-a2051e91857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "10000000\n",
      "0.6910528750873685 \t 45\n",
      "87 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 19:32:06.351600: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 19:32:07.004419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22243 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6913653612136841 \t 100\t\n",
      "88 0.6912950277328491 \t 100\t\n",
      "89 0.6913024187088013 \t 100\t\n",
      "90 0.6912943720817566 \t 100\t\n",
      "91 0.6913145780563354 \t 100\t\n",
      "92 0.691287100315094 \t 100\t\n",
      "93 0.6912788152694702 \t 100\t\n",
      "94 0.6912984848022461 \t 100\t\n",
      "95 0.6912990808486938 \t 100\t\n",
      "96 0.6913532018661499 \t 100\t\n",
      "97 0.6912767887115479 \t 100\t\n",
      "98 0.6912504434585571 \t 100\t\n",
      "99 0.6913511753082275 \t 100\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ns = [10**7]\n",
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(87, reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf622c3-cfce-4a54-b8d5-2dca4a76c167",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07e462f-21a5-4517-a390-57d7e4e498fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 2\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201c1e2a-1e85-4736-b009-fcac789b5d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0.8233430308103561 \t 11\n",
      "0 0.7209652066230774 \t 11\t\n",
      "1 0.7217194437980652 \t 11\t\n",
      "2 0.7222219705581665 \t 12\t\n",
      "3 0.718004584312439 \t 11\t\n",
      "4 0.7417144179344177 \t 12\t\n",
      "5 0.7358759045600891 \t 14\t\n",
      "6 0.7359951734542847 \t 11\t\n",
      "7 0.7287700176239014 \t 11\t\n",
      "8 0.7308948040008545 \t 12\t\n",
      "9 0.7268415689468384 \t 15\t\n",
      "10 0.7184034585952759 \t 11\t\n",
      "11 0.7192142605781555 \t 11\t\n",
      "12 0.7209107875823975 \t 11\t\n",
      "13 0.7087037563323975 \t 11\t\n",
      "14 0.7129851579666138 \t 11\t\n",
      "15 0.7363764047622681 \t 11\t\n",
      "16 0.7295403480529785 \t 11\t\n",
      "17 0.7196835279464722 \t 11\t\n",
      "18 0.7183862924575806 \t 11\t\n",
      "19 0.7125200629234314 \t 11\t\n",
      "20 0.7262614369392395 \t 11\t\n",
      "21 0.7214400768280029 \t 16\t\n",
      "22 0.7001100182533264 \t 11\t\n",
      "23 0.7420414090156555 \t 11\t\n",
      "24 0.7349517941474915 \t 11\t\n",
      "25 0.7225614190101624 \t 11\t\n",
      "26 0.7295057773590088 \t 15\t\n",
      "27 0.7269763350486755 \t 13\t\n",
      "28 0.7192058563232422 \t 11\t\n",
      "29 0.7252163887023926 \t 11\t\n",
      "30 0.7308338284492493 \t 11\t\n",
      "31 0.7255899310112 \t 13\t\n",
      "32 0.7219876050949097 \t 11\t\n",
      "33 0.755247950553894 \t 14\t\n",
      "34 0.7198649644851685 \t 11\t\n",
      "35 0.7083088159561157 \t 11\t\n",
      "36 0.7348257303237915 \t 11\t\n",
      "37 0.7233579754829407 \t 11\t\n",
      "38 0.7383167743682861 \t 17\t\n",
      "39 0.7172127366065979 \t 11\t\n",
      "40 0.7174245715141296 \t 11\t\n",
      "41 0.7378077507019043 \t 11\t\n",
      "42 0.7173307538032532 \t 11\t\n",
      "43 0.7129726409912109 \t 11\t\n",
      "44 0.7232579588890076 \t 12\t\n",
      "45 0.7350007891654968 \t 11\t\n",
      "46 0.7142124176025391 \t 17\t\n",
      "47 0.725799560546875 \t 12\t\n",
      "48 0.7091288566589355 \t 11\t\n",
      "49 0.7255232334136963 \t 18\t\n",
      "50 0.7124450206756592 \t 11\t\n",
      "51 0.7103350162506104 \t 12\t\n",
      "52 0.7271595597267151 \t 11\t\n",
      "53 0.7416749000549316 \t 13\t\n",
      "54 0.7273536920547485 \t 11\t\n",
      "55 0.7110562324523926 \t 11\t\n",
      "56 0.7132622599601746 \t 14\t\n",
      "57 0.7158377766609192 \t 17\t\n",
      "58 0.7214462757110596 \t 11\t\n",
      "59 0.7372337579727173 \t 11\t\n",
      "60 0.7306222319602966 \t 13\t\n",
      "61 0.7285439968109131 \t 11\t\n",
      "62 0.7082908153533936 \t 11\t\n",
      "63 0.7288287281990051 \t 11\t\n",
      "64 0.7169317007064819 \t 11\t\n",
      "65 0.7455218434333801 \t 11\t\n",
      "66 0.7217365503311157 \t 11\t\n",
      "67 0.7082273960113525 \t 20\t\n",
      "68 0.7220839858055115 \t 12\t\n",
      "69 0.7207582592964172 \t 11\t\n",
      "70 0.7231526970863342 \t 12\t\n",
      "71 0.7086288332939148 \t 11\t\n",
      "72 0.7267302870750427 \t 11\t\n",
      "73 0.7483752369880676 \t 16\t\n",
      "74 0.7147663235664368 \t 11\t\n",
      "75 0.7182238698005676 \t 11\t\n",
      "76 0.7087045907974243 \t 11\t\n",
      "77 0.7386077046394348 \t 11\t\n",
      "78 0.7225378155708313 \t 11\t\n",
      "79 0.7307295203208923 \t 11\t\n",
      "80 0.7253713011741638 \t 15\t\n",
      "81 0.7232562899589539 \t 11\t\n",
      "82 0.7343586683273315 \t 11\t\n",
      "83 0.7065547108650208 \t 11\t\n",
      "84 0.7288985252380371 \t 11\t\n",
      "85 0.7225865721702576 \t 13\t\n",
      "86 0.7081311941146851 \t 11\t\n",
      "87 0.7169759273529053 \t 12\t\n",
      "88 0.7152965068817139 \t 11\t\n",
      "89 0.7161121964454651 \t 11\t\n",
      "90 0.7299960851669312 \t 16\t\n",
      "91 0.7235885858535767 \t 11\t\n",
      "92 0.7227853536605835 \t 12\t\n",
      "93 0.7195500135421753 \t 12\t\n",
      "94 0.7306280732154846 \t 11\t\n",
      "95 0.719919741153717 \t 11\t\n",
      "96 0.7213841080665588 \t 16\t\n",
      "97 0.7081873416900635 \t 11\t\n",
      "98 0.7199434638023376 \t 11\t\n",
      "99 0.7099135518074036 \t 11\t\n",
      "\n",
      "===================================================\n",
      "1000\n",
      "0.732753623187542 \t 11\n",
      "0 0.6948107481002808 \t 11\t\n",
      "1 0.6993615031242371 \t 11\t\n",
      "2 0.6944943070411682 \t 12\t\n",
      "3 0.6946748495101929 \t 11\t\n",
      "4 0.6958831548690796 \t 11\t\n",
      "5 0.6975688338279724 \t 11\t\n",
      "6 0.6953232288360596 \t 12\t\n",
      "7 0.6968148350715637 \t 11\t\n",
      "8 0.6955082416534424 \t 11\t\n",
      "9 0.6969946622848511 \t 13\t\n",
      "10 0.695650041103363 \t 11\t\n",
      "11 0.6977493762969971 \t 14\t\n",
      "12 0.6953422427177429 \t 12\t\n",
      "13 0.6956336498260498 \t 11\t\n",
      "14 0.6971385478973389 \t 12\t\n",
      "15 0.6974973082542419 \t 11\t\n",
      "16 0.6959450244903564 \t 12\t\n",
      "17 0.699376106262207 \t 13\t\n",
      "18 0.698219895362854 \t 11\t\n",
      "19 0.6937142610549927 \t 11\t\n",
      "20 0.6967792510986328 \t 12\t\n",
      "21 0.6949476003646851 \t 11\t\n",
      "22 0.6937541365623474 \t 11\t\n",
      "23 0.6958654522895813 \t 12\t\n",
      "24 0.6964705586433411 \t 12\t\n",
      "25 0.6971873641014099 \t 12\t\n",
      "26 0.6932254433631897 \t 11\t\n",
      "27 0.6934124231338501 \t 11\t\n",
      "28 0.6953170895576477 \t 11\t\n",
      "29 0.6963600516319275 \t 11\t\n",
      "30 0.6944831013679504 \t 12\t\n",
      "31 0.6955702304840088 \t 14\t\n",
      "32 0.6956347823143005 \t 11\t\n",
      "33 0.6952999830245972 \t 12\t\n",
      "34 0.6937354803085327 \t 11\t\n",
      "35 0.6968916654586792 \t 11\t\n",
      "36 0.6941534280776978 \t 13\t\n",
      "37 0.6955576539039612 \t 12\t\n",
      "38 0.694701611995697 \t 11\t\n",
      "39 0.6948017477989197 \t 11\t\n",
      "40 0.6954548954963684 \t 11\t\n",
      "41 0.6963121294975281 \t 11\t\n",
      "42 0.6934837698936462 \t 11\t\n",
      "43 0.6976433396339417 \t 11\t\n",
      "44 0.6945923566818237 \t 11\t\n",
      "45 0.6932157278060913 \t 12\t\n",
      "46 0.6976507306098938 \t 22\t\n",
      "47 0.6937413811683655 \t 11\t\n",
      "48 0.6949679851531982 \t 11\t\n",
      "49 0.6960007548332214 \t 11\t\n",
      "50 0.6949648261070251 \t 12\t\n",
      "51 0.6974020004272461 \t 13\t\n",
      "52 0.6964055299758911 \t 13\t\n",
      "53 0.6929866075515747 \t 11\t\n",
      "54 0.6970444917678833 \t 11\t\n",
      "55 0.6955022811889648 \t 11\t\n",
      "56 0.6956332921981812 \t 11\t\n",
      "57 0.696212112903595 \t 12\t\n",
      "58 0.6966878771781921 \t 11\t\n",
      "59 0.6953113079071045 \t 11\t\n",
      "60 0.6947870850563049 \t 11\t\n",
      "61 0.6964371204376221 \t 11\t\n",
      "62 0.695368230342865 \t 11\t\n",
      "63 0.6933913230895996 \t 11\t\n",
      "64 0.6957492232322693 \t 11\t\n",
      "65 0.6947917342185974 \t 11\t\n",
      "66 0.694555401802063 \t 11\t\n",
      "67 0.6977879405021667 \t 11\t\n",
      "68 0.6953409910202026 \t 11\t\n",
      "69 0.6963444948196411 \t 12\t\n",
      "70 0.6948388814926147 \t 11\t\n",
      "71 0.6962236762046814 \t 12\t\n",
      "72 0.6947793960571289 \t 13\t\n",
      "73 0.6975152492523193 \t 11\t\n",
      "74 0.6936997175216675 \t 12\t\n",
      "75 0.6937520503997803 \t 12\t\n",
      "76 0.6939128637313843 \t 11\t\n",
      "77 0.6962245106697083 \t 11\t\n",
      "78 0.699064314365387 \t 11\t\n",
      "79 0.6967940330505371 \t 11\t\n",
      "80 0.6955403685569763 \t 11\t\n",
      "81 0.6949403285980225 \t 11\t\n",
      "82 0.6946344971656799 \t 12\t\n",
      "83 0.6954929828643799 \t 20\t\n",
      "84 0.6950691342353821 \t 11\t\n",
      "85 0.6960011124610901 \t 12\t\n",
      "86 0.694873571395874 \t 11\t\n",
      "87 0.6961547136306763 \t 12\t\n",
      "88 0.6959729194641113 \t 12\t\n",
      "89 0.694981575012207 \t 11\t\n",
      "90 0.693794846534729 \t 12\t\n",
      "91 0.6935125589370728 \t 12\t\n",
      "92 0.6950325965881348 \t 12\t\n",
      "93 0.696563720703125 \t 11\t\n",
      "94 0.6944522857666016 \t 11\t\n",
      "95 0.6957774758338928 \t 11\t\n",
      "96 0.6941837668418884 \t 11\t\n",
      "97 0.6968517899513245 \t 12\t\n",
      "98 0.6947436332702637 \t 17\t\n",
      "99 0.6957802176475525 \t 11\t\n",
      "\n",
      "===================================================\n",
      "10000\n",
      "0.6989231345713138 \t 12\n",
      "0 0.6924486756324768 \t 17\t\n",
      "1 0.6924093961715698 \t 12\t\n",
      "2 0.6924736499786377 \t 11\t\n",
      "3 0.6927904486656189 \t 12\t\n",
      "4 0.6922908425331116 \t 12\t\n",
      "5 0.6922243237495422 \t 12\t\n",
      "6 0.6924728751182556 \t 11\t\n",
      "7 0.6922740936279297 \t 12\t\n",
      "8 0.6929473876953125 \t 14\t\n",
      "9 0.6929899454116821 \t 15\t\n",
      "10 0.6929091811180115 \t 14\t\n",
      "11 0.6924600601196289 \t 13\t\n",
      "12 0.6928442120552063 \t 13\t\n",
      "13 0.6925170421600342 \t 13\t\n",
      "14 0.6922069787979126 \t 11\t\n",
      "15 0.6924782395362854 \t 14\t\n",
      "16 0.6928467154502869 \t 11\t\n",
      "17 0.6927529573440552 \t 21\t\n",
      "18 0.693459689617157 \t 16\t\n",
      "19 0.6928234100341797 \t 16\t\n",
      "20 0.692933976650238 \t 12\t\n",
      "21 0.6926903128623962 \t 12\t\n",
      "22 0.692939281463623 \t 12\t\n",
      "23 0.692642092704773 \t 12\t\n",
      "24 0.6928144097328186 \t 17\t\n",
      "25 0.6929450631141663 \t 15\t\n",
      "26 0.692770779132843 \t 14\t\n",
      "27 0.6927943229675293 \t 20\t\n",
      "28 0.6927420496940613 \t 12\t\n",
      "29 0.6925967931747437 \t 18\t\n",
      "30 0.6925374269485474 \t 13\t\n",
      "31 0.6926382780075073 \t 16\t\n",
      "32 0.6927160620689392 \t 13\t\n",
      "33 0.6925074458122253 \t 13\t\n",
      "34 0.6926673054695129 \t 12\t\n",
      "35 0.6926741003990173 \t 19\t\n",
      "36 0.6924881935119629 \t 14\t\n",
      "37 0.6928539276123047 \t 20\t\n",
      "38 0.692908763885498 \t 17\t\n",
      "39 0.6930340528488159 \t 19\t\n",
      "40 0.6930732131004333 \t 15\t\n",
      "41 0.6926918029785156 \t 14\t\n",
      "42 0.6925486326217651 \t 25\t\n",
      "43 0.692918062210083 \t 23\t\n",
      "44 0.6923527717590332 \t 15\t\n",
      "45 0.693048357963562 \t 19\t\n",
      "46 0.6929820775985718 \t 16\t\n",
      "47 0.6925270557403564 \t 21\t\n",
      "48 0.6927841305732727 \t 14\t\n",
      "49 0.6923887133598328 \t 12\t\n",
      "50 0.6926109790802002 \t 35\t\n",
      "51 0.6925920248031616 \t 29\t\n",
      "52 0.6925435066223145 \t 13\t\n",
      "53 0.6924464106559753 \t 13\t\n",
      "54 0.6930832862854004 \t 13\t\n",
      "55 0.6924843788146973 \t 17\t\n",
      "56 0.692584216594696 \t 16\t\n",
      "57 0.6925774812698364 \t 12\t\n",
      "58 0.6927854418754578 \t 11\t\n",
      "59 0.6928701400756836 \t 13\t\n",
      "60 0.6929675936698914 \t 17\t\n",
      "61 0.6930478811264038 \t 14\t\n",
      "62 0.6926272511482239 \t 13\t\n",
      "63 0.6926467418670654 \t 14\t\n",
      "64 0.6922745704650879 \t 12\t\n",
      "65 0.6924946308135986 \t 12\t\n",
      "66 0.6926783323287964 \t 13\t\n",
      "67 0.6926534175872803 \t 12\t\n",
      "68 0.6925182342529297 \t 11\t\n",
      "69 0.6925989985466003 \t 12\t\n",
      "70 0.6924314498901367 \t 16\t\n",
      "71 0.6929001212120056 \t 12\t\n",
      "72 0.6930418014526367 \t 21\t\n",
      "73 0.6927662491798401 \t 20\t\n",
      "74 0.6921901106834412 \t 13\t\n",
      "75 0.6932202577590942 \t 16\t\n",
      "76 0.6925715804100037 \t 18\t\n",
      "77 0.6922255754470825 \t 12\t\n",
      "78 0.6924461722373962 \t 12\t\n",
      "79 0.6926564574241638 \t 11\t\n",
      "80 0.6927596926689148 \t 22\t\n",
      "81 0.6928081512451172 \t 12\t\n",
      "82 0.6923460960388184 \t 11\t\n",
      "83 0.6925914287567139 \t 12\t\n",
      "84 0.6927000284194946 \t 12\t\n",
      "85 0.6926702857017517 \t 11\t\n",
      "86 0.6928176879882812 \t 16\t\n",
      "87 0.6923617720603943 \t 13\t\n",
      "88 0.6928620338439941 \t 15\t\n",
      "89 0.6926019191741943 \t 12\t\n",
      "90 0.6925444602966309 \t 20\t\n",
      "91 0.6927139759063721 \t 14\t\n",
      "92 0.6923533082008362 \t 13\t\n",
      "93 0.6928432583808899 \t 12\t\n",
      "94 0.6930103302001953 \t 11\t\n",
      "95 0.6925451159477234 \t 12\t\n",
      "96 0.6925098896026611 \t 29\t\n",
      "97 0.6922690272331238 \t 19\t\n",
      "98 0.6928988099098206 \t 16\t\n",
      "99 0.6922965049743652 \t 12\t\n",
      "\n",
      "===================================================\n",
      "100000\n",
      "0.6923379176658392 \t 13\n",
      "0 0.6912754774093628 \t 53\t\n",
      "1 0.6913517117500305 \t 33\t\n",
      "2 0.6912661194801331 \t 29\t\n",
      "3 0.6912923455238342 \t 26\t\n",
      "4 0.6912810206413269 \t 23\t\n",
      "5 0.6912311911582947 \t 33\t\n",
      "6 0.6913929581642151 \t 26\t\n",
      "7 0.6912224292755127 \t 36\t\n",
      "8 0.6912862658500671 \t 44\t\n",
      "9 0.6913167834281921 \t 33\t\n",
      "10 0.6912825703620911 \t 23\t\n",
      "11 0.6912262439727783 \t 39\t\n",
      "12 0.6912808418273926 \t 29\t\n",
      "13 0.6913111805915833 \t 26\t\n",
      "14 0.6913869380950928 \t 32\t\n",
      "15 0.6913579106330872 \t 54\t\n",
      "16 0.6914093494415283 \t 34\t\n",
      "17 0.6912820935249329 \t 27\t\n",
      "18 0.6913228034973145 \t 25\t\n",
      "19 0.6913690567016602 \t 27\t\n",
      "20 0.6912108659744263 \t 37\t\n",
      "21 0.6912049055099487 \t 52\t\n",
      "22 0.6912842988967896 \t 30\t\n",
      "23 0.6914896965026855 \t 23\t\n",
      "24 0.6912662386894226 \t 42\t\n",
      "25 0.6913315057754517 \t 26\t\n",
      "26 0.6912417411804199 \t 43\t\n",
      "27 0.6912453174591064 \t 61\t\n",
      "28 0.691326379776001 \t 26\t\n",
      "29 0.6914120316505432 \t 38\t\n",
      "30 0.6913225650787354 \t 29\t\n",
      "31 0.6912387013435364 \t 38\t\n",
      "32 0.6911899447441101 \t 35\t\n",
      "33 0.6912885308265686 \t 43\t\n",
      "34 0.6912946701049805 \t 30\t\n",
      "35 0.6912398934364319 \t 36\t\n",
      "36 0.6912959218025208 \t 31\t\n",
      "37 0.6912549734115601 \t 23\t\n",
      "38 0.6911897659301758 \t 40\t\n",
      "39 0.6913447380065918 \t 32\t\n",
      "40 0.6914200186729431 \t 37\t\n",
      "41 0.6912378668785095 \t 34\t\n",
      "42 0.691296398639679 \t 24\t\n",
      "43 0.6912739276885986 \t 46\t\n",
      "44 0.6912807822227478 \t 44\t\n",
      "45 0.6913665533065796 \t 39\t\n",
      "46 0.6912217140197754 \t 69\t\n",
      "47 0.6913431286811829 \t 40\t\n",
      "48 0.6913269758224487 \t 23\t\n",
      "49 0.6912548542022705 \t 38\t\n",
      "50 0.6912632584571838 \t 31\t\n",
      "51 0.6913728713989258 \t 26\t\n",
      "52 0.6912668943405151 \t 33\t\n",
      "53 0.6912440061569214 \t 34\t\n",
      "54 0.691318690776825 \t 29\t\n",
      "55 0.6912860870361328 \t 28\t\n",
      "56 0.6912294030189514 \t 34\t\n",
      "57 0.6914351582527161 \t 24\t\n",
      "58 0.6912513971328735 \t 36\t\n",
      "59 0.6913132667541504 \t 55\t\n",
      "60 0.6913816928863525 \t 33\t\n",
      "61 0.6912429928779602 \t 34\t\n",
      "62 0.6912510991096497 \t 31\t\n",
      "63 0.6913198232650757 \t 39\t\n",
      "64 0.6913785934448242 \t 24\t\n",
      "65 0.6913554668426514 \t 30\t\n",
      "66 0.6913228631019592 \t 50\t\n",
      "67 0.6912134885787964 \t 27\t\n",
      "68 0.6912742853164673 \t 31\t\n",
      "69 0.6912452578544617 \t 24\t\n",
      "70 0.6912482976913452 \t 29\t\n",
      "71 0.6912686824798584 \t 26\t\n",
      "72 0.6913408637046814 \t 24\t\n",
      "73 0.6911082863807678 \t 27\t\n",
      "74 0.6913893818855286 \t 23\t\n",
      "75 0.6912423968315125 \t 49\t\n",
      "76 0.6912277340888977 \t 23\t\n",
      "77 0.6912469267845154 \t 26\t\n",
      "78 0.6912369728088379 \t 47\t\n",
      "79 0.6912919282913208 \t 28\t\n",
      "80 0.691268265247345 \t 28\t\n",
      "81 0.6913198232650757 \t 29\t\n",
      "82 0.6912564039230347 \t 37\t\n",
      "83 0.6912558674812317 \t 32\t\n",
      "84 0.6914176344871521 \t 35\t\n",
      "85 0.6913585662841797 \t 26\t\n",
      "86 0.6912627220153809 \t 39\t\n",
      "87 0.691285252571106 \t 22\t\n",
      "88 0.6912785172462463 \t 29\t\n",
      "89 0.6912277936935425 \t 23\t\n",
      "90 0.6912897825241089 \t 29\t\n",
      "91 0.6912347078323364 \t 23\t\n",
      "92 0.6911301016807556 \t 28\t\n",
      "93 0.6913565397262573 \t 36\t\n",
      "94 0.6913137435913086 \t 22\t\n",
      "95 0.6913283467292786 \t 31\t\n",
      "96 0.6913344264030457 \t 25\t\n",
      "97 0.6912931203842163 \t 37\t\n",
      "98 0.6912704706192017 \t 25\t\n",
      "99 0.6913352608680725 \t 33\t\n",
      "\n",
      "===================================================\n",
      "1000000\n",
      "0.6910087631967515 \t 27\n",
      "0 0.6914517879486084 \t 59\t\n",
      "1 0.691374659538269 \t 100\t\n",
      "2 0.6913537383079529 \t 100\t\n",
      "3 0.691339373588562 \t 100\t\n",
      "4 0.6915028095245361 \t 35\t\n",
      "5 0.6914808750152588 \t 71\t\n",
      "6 0.691480278968811 \t 55\t\n",
      "7 0.6913572549819946 \t 100\t\n",
      "8 0.6914363503456116 \t 79\t\n",
      "9 0.6914594769477844 \t 48\t\n",
      "10 0.6913997530937195 \t 100\t\n",
      "11 0.6914915442466736 \t 44\t\n",
      "12 0.6913720369338989 \t 100\t\n",
      "13 0.6914977431297302 \t 43\t\n",
      "14 0.6914551258087158 \t 58\t\n",
      "15 0.6914624571800232 \t 63\t\n",
      "16 0.6913964152336121 \t 90\t\n",
      "17 0.6914417147636414 \t 82\t\n",
      "18 0.6914456486701965 \t 70\t\n",
      "19 0.6913131475448608 \t 100\t\n",
      "20 0.6914743781089783 \t 51\t\n",
      "21 0.6914488673210144 \t 61\t\n",
      "22 0.6913557648658752 \t 100\t\n",
      "23 0.6914495229721069 \t 53\t\n",
      "24 0.6914830207824707 \t 51\t\n",
      "25 0.6914791464805603 \t 28\t\n",
      "26 0.6914843320846558 \t 44\t\n",
      "27 0.6914694905281067 \t 49\t\n",
      "28 0.6913907527923584 \t 100\t\n",
      "29 0.6914861798286438 \t 52\t\n",
      "30 0.6914698481559753 \t 81\t\n",
      "31 0.6914659738540649 \t 46\t\n",
      "32 0.6913893818855286 \t 100\t\n",
      "33 0.6914430856704712 \t 64\t\n",
      "34 0.6914613246917725 \t 56\t\n",
      "35 0.6914433836936951 \t 100\t\n",
      "36 0.69145667552948 \t 63\t\n",
      "37 0.6914190053939819 \t 100\t\n",
      "38 0.6914835572242737 \t 52\t\n",
      "39 0.6913391947746277 \t 100\t\n",
      "40 0.6914588212966919 \t 53\t\n",
      "41 0.6913893818855286 \t 100\t\n",
      "42 0.6913878917694092 \t 86\t\n",
      "43 0.6914117336273193 \t 85\t\n",
      "44 0.6914348006248474 \t 82\t\n",
      "45 0.6914949417114258 \t 39\t\n",
      "46 0.6914013624191284 \t 100\t\n",
      "47 0.6913291215896606 \t 100\t\n",
      "48 0.6914423704147339 \t 65\t\n",
      "49 0.6914242506027222 \t 91\t\n",
      "50 0.6914440393447876 \t 57\t\n",
      "51 0.6913997530937195 \t 96\t\n",
      "52 0.6914263963699341 \t 70\t\n",
      "53 0.6914110779762268 \t 76\t\n",
      "54 0.6914202570915222 \t 81\t\n",
      "55 0.6914551258087158 \t 66\t\n",
      "56 0.6914637684822083 \t 46\t\n",
      "57 0.6914544105529785 \t 59\t\n",
      "58 0.6913202404975891 \t 100\t\n",
      "59 0.6914671063423157 \t 59\t\n",
      "60 0.6913393139839172 \t 100\t\n",
      "61 0.6914781928062439 \t 85\t\n",
      "62 0.6914576292037964 \t 44\t\n",
      "63 0.6914551258087158 \t 47\t\n",
      "64 0.6914221048355103 \t 71\t\n",
      "65 0.6913722157478333 \t 100\t\n",
      "66 0.6914160251617432 \t 88\t\n",
      "67 0.6914593577384949 \t 66\t\n",
      "68 0.6914392113685608 \t 66\t\n",
      "69 0.6913735270500183 \t 100\t\n",
      "70 0.6914993524551392 \t 44\t\n",
      "71 0.6914533972740173 \t 75\t\n",
      "72 0.6913595795631409 \t 100\t\n",
      "73 0.6914618611335754 \t 51\t\n",
      "74 0.691403329372406 \t 89\t\n",
      "75 0.6915140748023987 \t 40\t\n",
      "76 0.6914421916007996 \t 100\t\n",
      "77 0.6914421916007996 \t 50\t\n",
      "78 0.69134122133255 \t 100\t\n",
      "79 0.6914525032043457 \t 68\t\n",
      "80 0.6914346218109131 \t 100\t\n",
      "81 0.6914191246032715 \t 82\t\n",
      "82 0.6914622783660889 \t 60\t\n",
      "83 0.6914154887199402 \t 66\t\n",
      "84 0.6914523243904114 \t 61\t\n",
      "85 0.6914631724357605 \t 44\t\n",
      "86 0.6914633512496948 \t 46\t\n",
      "87 0.6914474368095398 \t 59\t\n",
      "88 0.6913397312164307 \t 100\t\n",
      "89 0.6914553642272949 \t 61\t\n",
      "90 0.691474974155426 \t 44\t\n",
      "91 0.6914086937904358 \t 80\t\n",
      "92 0.6913962960243225 \t 100\t\n",
      "93 0.6913930177688599 \t 100\t\n",
      "94 0.6913204789161682 \t 100\t\n",
      "95 0.6914476156234741 \t 63\t\n",
      "96 0.6914207339286804 \t 75\t\n",
      "97 0.691446840763092 \t 69\t\n",
      "98 0.6915112137794495 \t 28\t\n",
      "99 0.6914616227149963 \t 42\t\n",
      "\n",
      "===================================================\n",
      "10000000\n",
      "0.6907671455825418 \t 44\n",
      "0 0.6908367872238159 \t 100\t\n",
      "1 0.6909074187278748 \t 100\t\n",
      "2 0.6908218264579773 \t 100\t\n",
      "3 0.6909608244895935 \t 100\t\n",
      "4 0.6908385753631592 \t 100\t\n",
      "5 0.690834105014801 \t 100\t\n",
      "6 0.6909276843070984 \t 100\t\n",
      "7 0.6908357739448547 \t 100\t\n",
      "8 0.690941572189331 \t 100\t\n",
      "9 0.690987229347229 \t 100\t\n",
      "10 0.6908235549926758 \t 100\t\n",
      "11 0.6910064220428467 \t 100\t\n",
      "12 0.6908401846885681 \t 100\t\n",
      "13 0.6908483505249023 \t 100\t\n",
      "14 0.690890908241272 \t 100\t\n",
      "15 0.6908673644065857 \t 100\t\n",
      "16 0.6908314228057861 \t 100\t\n",
      "17 0.6908740401268005 \t 100\t\n",
      "18 0.6908825039863586 \t 100\t\n",
      "19 0.6909831166267395 \t 100\t\n",
      "20 0.6911001801490784 \t 100\t\n",
      "21 0.6908407211303711 \t 100\t\n",
      "22 0.6909663081169128 \t 100\t\n",
      "23 0.6909382939338684 \t 100\t\n",
      "24 0.6908720135688782 \t 100\t\n",
      "25 0.6910626888275146 \t 100\t\n",
      "26 0.690776526927948 \t 100\t\n",
      "27 0.690853476524353 \t 100\t\n",
      "28 0.6908643245697021 \t 100\t\n",
      "29 0.690881073474884 \t 100\t\n",
      "30 0.6907824873924255 \t 100\t\n",
      "31 0.6908721923828125 \t 100\t\n",
      "32 0.6908005475997925 \t 100\t\n",
      "33 0.6909250020980835 \t 100\t\n",
      "34 0.6909023523330688 \t 100\t\n",
      "35 0.6910008192062378 \t 100\t\n",
      "36 0.6908489465713501 \t 100\t\n",
      "37 0.6908792853355408 \t 100\t\n",
      "38 0.690888524055481 \t 100\t\n",
      "39 0.690946102142334 \t 100\t\n",
      "40 0.6908835172653198 \t 100\t\n",
      "41 0.6908644437789917 \t 100\t\n",
      "42 0.6909077167510986 \t 100\t\n",
      "43 0.6908261179924011 \t 100\t\n",
      "44 0.6909704804420471 \t 100\t\n",
      "45 0.6910956501960754 \t 100\t\n",
      "46 0.6908143162727356 \t 100\t\n",
      "47 0.6908438205718994 \t 100\t\n",
      "48 0.6910609602928162 \t 100\t\n",
      "49 0.6908723711967468 \t 100\t\n",
      "50 0.6908276677131653 \t 100\t\n",
      "51 0.6911851167678833 \t 100\t\n",
      "52 0.6909649968147278 \t 100\t\n",
      "53 0.6908131837844849 \t 100\t\n",
      "54 0.690808892250061 \t 100\t\n",
      "55 0.6908090114593506 \t 100\t\n",
      "56 0.6907991766929626 \t 100\t\n",
      "57 0.6908833980560303 \t 100\t\n",
      "58 0.6908484101295471 \t 100\t\n",
      "59 0.6908249258995056 \t 100\t\n",
      "60 0.6909117102622986 \t 100\t\n",
      "61 0.6908115148544312 \t 100\t\n",
      "62 0.691189706325531 \t 100\t\n",
      "63 0.6908919811248779 \t 100\t\n",
      "64 0.6909708380699158 \t 100\t\n",
      "65 0.6908828020095825 \t 100\t\n",
      "66 0.6909191012382507 \t 100\t\n",
      "67 0.6908730268478394 \t 100\t\n",
      "68 0.6908149123191833 \t 100\t\n",
      "69 0.6912842988967896 \t 100\t\n",
      "70 0.6908084750175476 \t 100\t\n",
      "71 0.6907699704170227 \t 100\t\n",
      "72 0.6908652782440186 \t 100\t\n",
      "73 0.6908326745033264 \t 100\t\n",
      "74 0.6908295750617981 \t 100\t\n",
      "75 0.6909744739532471 \t 100\t\n",
      "76 0.6908137202262878 \t 100\t\n",
      "77 0.6907969117164612 \t 100\t\n",
      "78 0.6913272738456726 \t 100\t\n",
      "79 0.6908600926399231 \t 100\t\n",
      "80 0.6908813118934631 \t 100\t\n",
      "81 0.690834105014801 \t 100\t\n",
      "82 0.690873920917511 \t 100\t\n",
      "83 0.6908621191978455 \t 100\t\n",
      "84 0.6909527778625488 \t 100\t\n",
      "85 0.6908001899719238 \t 100\t\n",
      "86 0.6909260749816895 \t 100\t\n",
      "87 0.6908146739006042 \t 100\t\n",
      "88 0.6908388137817383 \t 100\t\n",
      "89 0.6909295320510864 \t 100\t\n",
      "90 0.6908484697341919 \t 100\t\n",
      "91 0.6908791065216064 \t 100\t\n",
      "92 0.6907953023910522 \t 100\t\n",
      "93 0.6909123063087463 \t 100\t\n",
      "94 0.6908243894577026 \t 100\t\n",
      "95 0.6909257769584656 \t 100\t\n",
      "96 0.6908531785011292 \t 100\t\n",
      "97 0.6907684803009033 \t 100\t\n",
      "98 0.6910619139671326 \t 100\t\n",
      "99 0.6907920837402344 \t 100\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c198e6-0986-41aa-a9a7-d28f318d178d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $d = 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9764d4-4e06-4426-b662-c1551a4c8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 4\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15382cf7-0ebb-41ab-bc6f-037c5c058056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0 0.7466009259223938 \t 11\t\n",
      "1 0.8381830453872681 \t 11\t\n",
      "2 0.8478952050209045 \t 11\t\n",
      "3 0.8248729705810547 \t 11\t\n",
      "4 0.7957172989845276 \t 11\t\n",
      "5 0.7961660027503967 \t 11\t\n",
      "6 0.834848165512085 \t 11\t\n",
      "7 0.7948175668716431 \t 11\t\n",
      "8 0.8257989287376404 \t 11\t\n",
      "9 0.8306968808174133 \t 11\t\n",
      "10 0.8431758284568787 \t 11\t\n",
      "11 0.7667405605316162 \t 11\t\n",
      "12 0.7827409505844116 \t 11\t\n",
      "13 0.7838733196258545 \t 11\t\n",
      "14 0.7603791952133179 \t 11\t\n",
      "15 0.7988912463188171 \t 11\t\n",
      "16 0.7955183386802673 \t 13\t\n",
      "17 0.8104608058929443 \t 11\t\n",
      "18 0.8033779859542847 \t 11\t\n",
      "19 0.7997717261314392 \t 11\t\n",
      "20 0.8333974480628967 \t 11\t\n",
      "21 0.7899810671806335 \t 11\t\n",
      "22 0.7763407826423645 \t 11\t\n",
      "23 0.791546106338501 \t 11\t\n",
      "24 0.7738641500473022 \t 11\t\n",
      "25 0.7564486861228943 \t 11\t\n",
      "26 0.8258960247039795 \t 11\t\n",
      "27 0.8423086404800415 \t 14\t\n",
      "28 0.8169330358505249 \t 11\t\n",
      "29 0.8344702124595642 \t 11\t\n",
      "30 0.770388126373291 \t 11\t\n",
      "31 0.8008155226707458 \t 11\t\n",
      "32 0.7987943887710571 \t 11\t\n",
      "33 0.8391361832618713 \t 11\t\n",
      "34 0.8129070997238159 \t 11\t\n",
      "35 0.8220988512039185 \t 11\t\n",
      "36 0.7585231065750122 \t 11\t\n",
      "37 0.8180997371673584 \t 11\t\n",
      "38 0.7967648506164551 \t 12\t\n",
      "39 0.7844899892807007 \t 11\t\n",
      "40 0.8128706216812134 \t 11\t\n",
      "41 0.813661515712738 \t 11\t\n",
      "42 0.8124596476554871 \t 11\t\n",
      "43 0.7783756852149963 \t 11\t\n",
      "44 0.783302903175354 \t 11\t\n",
      "45 0.7795726656913757 \t 11\t\n",
      "46 0.818075954914093 \t 11\t\n",
      "47 0.8257298469543457 \t 11\t\n",
      "48 0.7885093092918396 \t 11\t\n",
      "49 0.7431756854057312 \t 11\t\n",
      "50 0.7829570174217224 \t 11\t\n",
      "51 0.8492977023124695 \t 11\t\n",
      "52 0.8199533224105835 \t 11\t\n",
      "53 0.7965548634529114 \t 11\t\n",
      "54 0.7813547253608704 \t 11\t\n",
      "55 0.7862799167633057 \t 11\t\n",
      "56 0.7531344890594482 \t 11\t\n",
      "57 0.7750651836395264 \t 11\t\n",
      "58 0.8433169722557068 \t 11\t\n",
      "59 0.7958614826202393 \t 11\t\n",
      "60 0.801140546798706 \t 11\t\n",
      "61 0.7937330603599548 \t 11\t\n",
      "62 0.8099371194839478 \t 11\t\n",
      "63 0.7602877616882324 \t 11\t\n",
      "64 0.7899768948554993 \t 11\t\n",
      "65 0.7961746454238892 \t 11\t\n",
      "66 0.823386549949646 \t 11\t\n",
      "67 0.792793869972229 \t 12\t\n",
      "68 0.7706709504127502 \t 11\t\n",
      "69 0.832334578037262 \t 17\t\n",
      "70 0.8264790177345276 \t 11\t\n",
      "71 0.8342639207839966 \t 11\t\n",
      "72 0.8458352088928223 \t 11\t\n",
      "73 0.8051405549049377 \t 11\t\n",
      "74 0.7770808935165405 \t 11\t\n",
      "75 0.8483644127845764 \t 11\t\n",
      "76 0.8003196716308594 \t 11\t\n",
      "77 0.8179776072502136 \t 11\t\n",
      "78 0.7884339094161987 \t 11\t\n",
      "79 0.7817396521568298 \t 11\t\n",
      "80 0.8073131442070007 \t 11\t\n",
      "81 0.8119852542877197 \t 11\t\n",
      "82 0.7625952363014221 \t 11\t\n",
      "83 0.8289840817451477 \t 11\t\n",
      "84 0.7807254195213318 \t 11\t\n",
      "85 0.8189109563827515 \t 13\t\n",
      "86 0.814375102519989 \t 11\t\n",
      "87 0.8611447215080261 \t 11\t\n",
      "88 0.8210838437080383 \t 11\t\n",
      "89 0.7775525450706482 \t 11\t\n",
      "90 0.7890088558197021 \t 11\t\n",
      "91 0.8126314282417297 \t 11\t\n",
      "92 0.7817124724388123 \t 11\t\n",
      "93 0.8207941651344299 \t 12\t\n",
      "94 0.7743454575538635 \t 11\t\n",
      "95 0.7979796528816223 \t 11\t\n",
      "96 0.7874531745910645 \t 11\t\n",
      "97 0.837220311164856 \t 11\t\n",
      "98 0.757316529750824 \t 11\t\n",
      "99 0.7945185899734497 \t 11\t\n",
      "\n",
      "===================================================\n",
      "1000\n",
      "0 0.6939880847930908 \t 15\t\n",
      "1 0.6940476298332214 \t 15\t\n",
      "2 0.6934632658958435 \t 14\t\n",
      "3 0.6933698654174805 \t 14\t\n",
      "4 0.6900712847709656 \t 11\t\n",
      "5 0.6991291046142578 \t 15\t\n",
      "6 0.6917738318443298 \t 15\t\n",
      "7 0.6967867016792297 \t 11\t\n",
      "8 0.6976697444915771 \t 15\t\n",
      "9 0.6925151944160461 \t 11\t\n",
      "10 0.7007520198822021 \t 14\t\n",
      "11 0.7053707838058472 \t 16\t\n",
      "12 0.7014948725700378 \t 12\t\n",
      "13 0.690910279750824 \t 12\t\n",
      "14 0.6915615797042847 \t 14\t\n",
      "15 0.7002352476119995 \t 18\t\n",
      "16 0.6966632604598999 \t 15\t\n",
      "17 0.6963265538215637 \t 13\t\n",
      "18 0.6950576305389404 \t 12\t\n",
      "19 0.6928219795227051 \t 11\t\n",
      "20 0.6918415427207947 \t 14\t\n",
      "21 0.6938363909721375 \t 13\t\n",
      "22 0.7000617384910583 \t 13\t\n",
      "23 0.6930409669876099 \t 11\t\n",
      "24 0.6967794299125671 \t 14\t\n",
      "25 0.695758044719696 \t 13\t\n",
      "26 0.6941950917243958 \t 16\t\n",
      "27 0.6915454864501953 \t 13\t\n",
      "28 0.6938381195068359 \t 17\t\n",
      "29 0.699830174446106 \t 16\t\n",
      "30 0.6931828260421753 \t 12\t\n",
      "31 0.6944941282272339 \t 16\t\n",
      "32 0.6939222812652588 \t 15\t\n",
      "33 0.6921191215515137 \t 16\t\n",
      "34 0.6949436068534851 \t 12\t\n",
      "35 0.6974091529846191 \t 15\t\n",
      "36 0.6938902735710144 \t 16\t\n",
      "37 0.6958574652671814 \t 15\t\n",
      "38 0.6949530243873596 \t 16\t\n",
      "39 0.6962939500808716 \t 14\t\n",
      "40 0.6990418434143066 \t 18\t\n",
      "41 0.6892723441123962 \t 11\t\n",
      "42 0.69490647315979 \t 14\t\n",
      "43 0.6938527226448059 \t 14\t\n",
      "44 0.6940722465515137 \t 12\t\n",
      "45 0.6937384009361267 \t 11\t\n",
      "46 0.699070394039154 \t 15\t\n",
      "47 0.6889720559120178 \t 11\t\n",
      "48 0.698874294757843 \t 12\t\n",
      "49 0.6948146224021912 \t 11\t\n",
      "50 0.6938897967338562 \t 14\t\n",
      "51 0.7010432481765747 \t 17\t\n",
      "52 0.6924362778663635 \t 14\t\n",
      "53 0.698093831539154 \t 15\t\n",
      "54 0.6966741681098938 \t 14\t\n",
      "55 0.6954751014709473 \t 13\t\n",
      "56 0.6956607699394226 \t 13\t\n",
      "57 0.6954874396324158 \t 12\t\n",
      "58 0.695898175239563 \t 13\t\n",
      "59 0.6929088234901428 \t 12\t\n",
      "60 0.6952422857284546 \t 18\t\n",
      "61 0.6926325559616089 \t 12\t\n",
      "62 0.6923410892486572 \t 14\t\n",
      "63 0.6933167576789856 \t 12\t\n",
      "64 0.6903694868087769 \t 12\t\n",
      "65 0.6957640051841736 \t 14\t\n",
      "66 0.6940385699272156 \t 12\t\n",
      "67 0.6994936466217041 \t 16\t\n",
      "68 0.6959735155105591 \t 17\t\n",
      "69 0.7020153999328613 \t 15\t\n",
      "70 0.698686420917511 \t 16\t\n",
      "71 0.6949489712715149 \t 16\t\n",
      "72 0.69792640209198 \t 12\t\n",
      "73 0.6987429857254028 \t 15\t\n",
      "74 0.7010690569877625 \t 12\t\n",
      "75 0.6928210258483887 \t 16\t\n",
      "76 0.6945129632949829 \t 14\t\n",
      "77 0.6932675838470459 \t 18\t\n",
      "78 0.7018746137619019 \t 14\t\n",
      "79 0.7032647728919983 \t 19\t\n",
      "80 0.6926009654998779 \t 12\t\n",
      "81 0.6939513087272644 \t 16\t\n",
      "82 0.7002487778663635 \t 17\t\n",
      "83 0.6969532370567322 \t 13\t\n",
      "84 0.6977912187576294 \t 15\t\n",
      "85 0.7011562585830688 \t 14\t\n",
      "86 0.6933549642562866 \t 15\t\n",
      "87 0.6991866230964661 \t 18\t\n",
      "88 0.6959068179130554 \t 16\t\n",
      "89 0.6890029907226562 \t 13\t\n",
      "90 0.692888617515564 \t 12\t\n",
      "91 0.6958562135696411 \t 15\t\n",
      "92 0.6949310302734375 \t 11\t\n",
      "93 0.699962317943573 \t 17\t\n",
      "94 0.6930102705955505 \t 17\t\n",
      "95 0.694644570350647 \t 12\t\n",
      "96 0.7020697593688965 \t 14\t\n",
      "97 0.6964532732963562 \t 12\t\n",
      "98 0.703839123249054 \t 18\t\n",
      "99 0.6951972842216492 \t 14\t\n",
      "\n",
      "===================================================\n",
      "10000\n",
      "0 0.6878412961959839 \t 22\t\n",
      "1 0.6881718635559082 \t 17\t\n",
      "2 0.6871044039726257 \t 18\t\n",
      "3 0.6879018545150757 \t 15\t\n",
      "4 0.6875214576721191 \t 15\t\n",
      "5 0.687484085559845 \t 17\t\n",
      "6 0.6873047947883606 \t 21\t\n",
      "7 0.6875371336936951 \t 16\t\n",
      "8 0.6877878904342651 \t 19\t\n",
      "9 0.6870182752609253 \t 17\t\n",
      "10 0.6875438690185547 \t 17\t\n",
      "11 0.6869699954986572 \t 16\t\n",
      "12 0.6873665452003479 \t 15\t\n",
      "13 0.6874140501022339 \t 17\t\n",
      "14 0.6878465414047241 \t 14\t\n",
      "15 0.6876795887947083 \t 16\t\n",
      "16 0.6870952844619751 \t 15\t\n",
      "17 0.6870637536048889 \t 15\t\n",
      "18 0.687283456325531 \t 19\t\n",
      "19 0.6874059438705444 \t 19\t\n",
      "20 0.6874139308929443 \t 17\t\n",
      "21 0.6874412894248962 \t 19\t\n",
      "22 0.6880187392234802 \t 15\t\n",
      "23 0.6882104873657227 \t 14\t\n",
      "24 0.6882529854774475 \t 21\t\n",
      "25 0.6868683695793152 \t 17\t\n",
      "26 0.6872006058692932 \t 15\t\n",
      "27 0.687747597694397 \t 14\t\n",
      "28 0.6878177523612976 \t 14\t\n",
      "29 0.6876834034919739 \t 16\t\n",
      "30 0.6871084570884705 \t 17\t\n",
      "31 0.6866660714149475 \t 15\t\n",
      "32 0.6870537996292114 \t 16\t\n",
      "33 0.6877831220626831 \t 17\t\n",
      "34 0.6874120235443115 \t 15\t\n",
      "35 0.6878366470336914 \t 17\t\n",
      "36 0.6879644989967346 \t 18\t\n",
      "37 0.6875556707382202 \t 15\t\n",
      "38 0.6877928376197815 \t 37\t\n",
      "39 0.6876017451286316 \t 20\t\n",
      "40 0.6869696974754333 \t 14\t\n",
      "41 0.6878293752670288 \t 16\t\n",
      "42 0.6879652142524719 \t 13\t\n",
      "43 0.6878084540367126 \t 15\t\n",
      "44 0.6873703002929688 \t 15\t\n",
      "45 0.6879675984382629 \t 16\t\n",
      "46 0.6877978444099426 \t 16\t\n",
      "47 0.6874237656593323 \t 15\t\n",
      "48 0.6878132820129395 \t 15\t\n",
      "49 0.6873002648353577 \t 18\t\n",
      "50 0.6873121857643127 \t 14\t\n",
      "51 0.6880110502243042 \t 19\t\n",
      "52 0.6875002384185791 \t 17\t\n",
      "53 0.6874797940254211 \t 18\t\n",
      "54 0.687774121761322 \t 15\t\n",
      "55 0.6885002851486206 \t 14\t\n",
      "56 0.6879119873046875 \t 14\t\n",
      "57 0.6871038675308228 \t 16\t\n",
      "58 0.6874062418937683 \t 17\t\n",
      "59 0.6875778436660767 \t 18\t\n",
      "60 0.6879027485847473 \t 16\t\n",
      "61 0.6876229643821716 \t 19\t\n",
      "62 0.6871712803840637 \t 14\t\n",
      "63 0.6871435046195984 \t 17\t\n",
      "64 0.6871727108955383 \t 18\t\n",
      "65 0.6870759129524231 \t 16\t\n",
      "66 0.6871362924575806 \t 15\t\n",
      "67 0.6877153515815735 \t 22\t\n",
      "68 0.6873796582221985 \t 16\t\n",
      "69 0.6871965527534485 \t 15\t\n",
      "70 0.6878682374954224 \t 16\t\n",
      "71 0.68739914894104 \t 16\t\n",
      "72 0.6875233054161072 \t 16\t\n",
      "73 0.6867881417274475 \t 14\t\n",
      "74 0.6876223683357239 \t 15\t\n",
      "75 0.6875086426734924 \t 15\t\n",
      "76 0.687522828578949 \t 16\t\n",
      "77 0.6882174611091614 \t 15\t\n",
      "78 0.687597930431366 \t 16\t\n",
      "79 0.687282919883728 \t 16\t\n",
      "80 0.6878678798675537 \t 15\t\n",
      "81 0.687018871307373 \t 16\t\n",
      "82 0.6873669624328613 \t 18\t\n",
      "83 0.6883258819580078 \t 17\t\n",
      "84 0.6872578859329224 \t 14\t\n",
      "85 0.6876911520957947 \t 15\t\n",
      "86 0.6878604292869568 \t 16\t\n",
      "87 0.6874688267707825 \t 18\t\n",
      "88 0.6876505613327026 \t 15\t\n",
      "89 0.6873345971107483 \t 15\t\n",
      "90 0.6879172921180725 \t 16\t\n",
      "91 0.6874484419822693 \t 15\t\n",
      "92 0.6867012977600098 \t 16\t\n",
      "93 0.6869897246360779 \t 18\t\n",
      "94 0.6872463822364807 \t 17\t\n",
      "95 0.6876916289329529 \t 18\t\n",
      "96 0.6881981492042542 \t 15\t\n",
      "97 0.6870772242546082 \t 18\t\n",
      "98 0.6878530383110046 \t 18\t\n",
      "99 0.6872604489326477 \t 15\t\n",
      "\n",
      "===================================================\n",
      "100000\n",
      "0 0.6839964985847473 \t 96\t\n",
      "1 0.6836224794387817 \t 100\t\n",
      "2 0.6836123466491699 \t 88\t\n",
      "3 0.6839454770088196 \t 100\t\n",
      "4 0.6844156980514526 \t 64\t\n",
      "5 0.6838582754135132 \t 100\t\n",
      "6 0.6840420961380005 \t 92\t\n",
      "7 0.6839701533317566 \t 74\t\n",
      "8 0.6838521957397461 \t 98\t\n",
      "9 0.6841951608657837 \t 71\t\n",
      "10 0.6838411688804626 \t 100\t\n",
      "11 0.6842746138572693 \t 64\t\n",
      "12 0.6839020848274231 \t 100\t\n",
      "13 0.6841785907745361 \t 95\t\n",
      "14 0.6841030716896057 \t 99\t\n",
      "15 0.6837300062179565 \t 100\t\n",
      "16 0.6843084096908569 \t 59\t\n",
      "17 0.6839819550514221 \t 82\t\n",
      "18 0.684299111366272 \t 86\t\n",
      "19 0.6849613785743713 \t 23\t\n",
      "20 0.6841298937797546 \t 88\t\n",
      "21 0.6839351058006287 \t 85\t\n",
      "22 0.6840885281562805 \t 100\t\n",
      "23 0.6838624477386475 \t 96\t\n",
      "24 0.6840084195137024 \t 100\t\n",
      "25 0.6836289763450623 \t 100\t\n",
      "26 0.6840046048164368 \t 84\t\n",
      "27 0.6838414669036865 \t 100\t\n",
      "28 0.6838660836219788 \t 93\t\n",
      "29 0.6842454671859741 \t 77\t\n",
      "30 0.6845574975013733 \t 40\t\n",
      "31 0.683867335319519 \t 100\t\n",
      "32 0.6837859153747559 \t 100\t\n",
      "33 0.6840047836303711 \t 100\t\n",
      "34 0.6842709183692932 \t 80\t\n",
      "35 0.6841477155685425 \t 73\t\n",
      "36 0.6839663982391357 \t 100\t\n",
      "37 0.6840156316757202 \t 100\t\n",
      "38 0.6839261054992676 \t 96\t\n",
      "39 0.68404221534729 \t 94\t\n",
      "40 0.6841981410980225 \t 61\t\n",
      "41 0.6839273571968079 \t 87\t\n",
      "42 0.6835665106773376 \t 95\t\n",
      "43 0.6840773224830627 \t 100\t\n",
      "44 0.6843113303184509 \t 80\t\n",
      "45 0.6840732097625732 \t 91\t\n",
      "46 0.6840699315071106 \t 83\t\n",
      "47 0.6843819618225098 \t 72\t\n",
      "48 0.684037983417511 \t 100\t\n",
      "49 0.6847001314163208 \t 38\t\n",
      "50 0.6841564178466797 \t 65\t\n",
      "51 0.6841761469841003 \t 82\t\n",
      "52 0.684093177318573 \t 85\t\n",
      "53 0.6839774250984192 \t 92\t\n",
      "54 0.6841416954994202 \t 77\t\n",
      "55 0.6844720244407654 \t 59\t\n",
      "56 0.6844996809959412 \t 87\t\n",
      "57 0.6840177178382874 \t 79\t\n",
      "58 0.6846859455108643 \t 46\t\n",
      "59 0.6840978264808655 \t 85\t\n",
      "60 0.6841694712638855 \t 83\t\n",
      "61 0.6848041415214539 \t 36\t\n",
      "62 0.6840543746948242 \t 65\t\n",
      "63 0.6848762631416321 \t 38\t\n",
      "64 0.6841353178024292 \t 78\t\n",
      "65 0.6842977404594421 \t 59\t\n",
      "66 0.6841009259223938 \t 81\t\n",
      "67 0.6846014857292175 \t 52\t\n",
      "68 0.6839356422424316 \t 100\t\n",
      "69 0.6840968728065491 \t 100\t\n",
      "70 0.6841835975646973 \t 82\t\n",
      "71 0.6841490864753723 \t 97\t\n",
      "72 0.6840622425079346 \t 100\t\n",
      "73 0.6839856505393982 \t 83\t\n",
      "74 0.6836465001106262 \t 100\t\n",
      "75 0.6841750144958496 \t 87\t\n",
      "76 0.6845999956130981 \t 50\t\n",
      "77 0.6839462518692017 \t 88\t\n",
      "78 0.6840118765830994 \t 90\t\n",
      "79 0.6840752363204956 \t 86\t\n",
      "80 0.6840757727622986 \t 100\t\n",
      "81 0.6835252046585083 \t 100\t\n",
      "82 0.684201717376709 \t 100\t\n",
      "83 0.6841505765914917 \t 76\t\n",
      "84 0.6840208768844604 \t 86\t\n",
      "85 0.6839565634727478 \t 100\t\n",
      "86 0.6839510798454285 \t 100\t\n",
      "87 0.6835376024246216 \t 100\t\n",
      "88 0.6840254664421082 \t 85\t\n",
      "89 0.6848247051239014 \t 44\t\n",
      "90 0.6838163137435913 \t 100\t\n",
      "91 0.6840851306915283 \t 100\t\n",
      "92 0.6841004490852356 \t 89\t\n",
      "93 0.684463620185852 \t 65\t\n",
      "94 0.6838335990905762 \t 100\t\n",
      "95 0.683746337890625 \t 100\t\n",
      "96 0.6843035817146301 \t 83\t\n",
      "97 0.6838005185127258 \t 97\t\n",
      "98 0.6846364736557007 \t 50\t\n",
      "99 0.6839487552642822 \t 85\t\n",
      "\n",
      "===================================================\n",
      "1000000\n",
      "0 0.6805218458175659 \t 100\t\n",
      "1 0.6804499626159668 \t 100\t\n",
      "2 0.6808834671974182 \t 100\t\n",
      "3 0.6806765198707581 \t 100\t\n",
      "4 0.680784285068512 \t 100\t\n",
      "5 0.6809542775154114 \t 100\t\n",
      "6 0.6811466217041016 \t 100\t\n",
      "7 0.6807569861412048 \t 100\t\n",
      "8 0.6807907223701477 \t 100\t\n",
      "9 0.6810551285743713 \t 100\t\n",
      "10 0.6807224750518799 \t 100\t\n",
      "11 0.680811882019043 \t 100\t\n",
      "12 0.6810274720191956 \t 100\t\n",
      "13 0.6808512210845947 \t 100\t\n",
      "14 0.6804748177528381 \t 100\t\n",
      "15 0.6809346079826355 \t 100\t\n",
      "16 0.6809054017066956 \t 100\t\n",
      "17 0.6810970902442932 \t 100\t\n",
      "18 0.6812875270843506 \t 100\t\n",
      "19 0.681083619594574 \t 100\t\n",
      "20 0.6813148856163025 \t 100\t\n",
      "21 0.6807617545127869 \t 100\t\n",
      "22 0.6808031797409058 \t 100\t\n",
      "23 0.6809210181236267 \t 100\t\n",
      "24 0.6806758046150208 \t 100\t\n",
      "25 0.6808426380157471 \t 100\t\n",
      "26 0.6807926893234253 \t 100\t\n",
      "27 0.6808048486709595 \t 100\t\n",
      "28 0.6811808347702026 \t 100\t\n",
      "29 0.6808976531028748 \t 100\t\n",
      "30 0.6808951497077942 \t 100\t\n",
      "31 0.6811233162879944 \t 100\t\n",
      "32 0.6806537508964539 \t 100\t\n",
      "33 0.6803337931632996 \t 100\t\n",
      "34 0.6810766458511353 \t 100\t\n",
      "35 0.6807526350021362 \t 100\t\n",
      "36 0.6803516745567322 \t 100\t\n",
      "37 0.680600106716156 \t 100\t\n",
      "38 0.6809991598129272 \t 100\t\n",
      "39 0.6807295680046082 \t 100\t\n",
      "40 0.6812318563461304 \t 100\t\n",
      "41 0.6813194155693054 \t 100\t\n",
      "42 0.6808319091796875 \t 100\t\n",
      "43 0.6807379722595215 \t 100\t\n",
      "44 0.6813360452651978 \t 100\t\n",
      "45 0.6809031367301941 \t 100\t\n",
      "46 0.6808725595474243 \t 100\t\n",
      "47 0.6807834506034851 \t 100\t\n",
      "48 0.6810698509216309 \t 100\t\n",
      "49 0.6812520027160645 \t 100\t\n",
      "50 0.6807320713996887 \t 100\t\n",
      "51 0.6808008551597595 \t 100\t\n",
      "52 0.6809341311454773 \t 100\t\n",
      "53 0.6808161735534668 \t 100\t\n",
      "54 0.6805744767189026 \t 100\t\n",
      "55 0.6808664798736572 \t 100\t\n",
      "56 0.6804623007774353 \t 100\t\n",
      "57 0.6803941130638123 \t 100\t\n",
      "58 0.6808516383171082 \t 100\t\n",
      "59 0.6810370087623596 \t 100\t\n",
      "60 0.6805272698402405 \t 100\t\n",
      "61 0.6809872388839722 \t 100\t\n",
      "62 0.6806687712669373 \t 100\t\n",
      "63 0.6811590790748596 \t 100\t\n",
      "64 0.6809283494949341 \t 100\t\n",
      "65 0.6809289455413818 \t 100\t\n",
      "66 0.6815006136894226 \t 100\t\n",
      "67 0.681018590927124 \t 100\t\n",
      "68 0.6808105707168579 \t 100\t\n",
      "69 0.6808778643608093 \t 100\t\n",
      "70 0.6807914972305298 \t 100\t\n",
      "71 0.6806944012641907 \t 100\t\n",
      "72 0.6807796359062195 \t 100\t\n",
      "73 0.680880606174469 \t 100\t\n",
      "74 0.6808694005012512 \t 100\t\n",
      "75 0.6809480786323547 \t 100\t\n",
      "76 0.6803892850875854 \t 100\t\n",
      "77 0.6813274621963501 \t 100\t\n",
      "78 0.6807709336280823 \t 100\t\n",
      "79 0.6810178160667419 \t 100\t\n",
      "80 0.6806928515434265 \t 100\t\n",
      "81 0.6807172894477844 \t 100\t\n",
      "82 0.681067705154419 \t 100\t\n",
      "83 0.6806639432907104 \t 100\t\n",
      "84 0.6807590126991272 \t 100\t\n",
      "85 0.6807304620742798 \t 100\t\n",
      "86 0.6806464791297913 \t 100\t\n",
      "87 0.6808092594146729 \t 100\t\n",
      "88 0.6804333329200745 \t 100\t\n",
      "89 0.6806455254554749 \t 100\t\n",
      "90 0.6807502508163452 \t 100\t\n",
      "91 0.6811993718147278 \t 100\t\n",
      "92 0.6805343627929688 \t 100\t\n",
      "93 0.6811177730560303 \t 100\t\n",
      "94 0.6808034181594849 \t 100\t\n",
      "95 0.680963933467865 \t 100\t\n",
      "96 0.6809667348861694 \t 100\t\n",
      "97 0.6805943250656128 \t 100\t\n",
      "98 0.6806064248085022 \t 100\t\n",
      "99 0.680861234664917 \t 100\t\n",
      "\n",
      "===================================================\n",
      "10000000\n",
      "0 0.6797746419906616 \t 100\t\n",
      "1 0.6795443296432495 \t 100\t\n",
      "2 0.6797698736190796 \t 100\t\n",
      "3 0.6792302131652832 \t 100\t\n",
      "4 0.6805655360221863 \t 100\t\n",
      "5 0.6797940135002136 \t 100\t\n",
      "6 0.6808609366416931 \t 100\t\n",
      "7 0.6793485879898071 \t 100\t\n",
      "8 0.6802868843078613 \t 100\t\n",
      "9 0.6796316504478455 \t 100\t\n",
      "10 0.6795077919960022 \t 100\t\n",
      "11 0.6802092790603638 \t 100\t\n",
      "12 0.6794143915176392 \t 100\t\n",
      "13 0.6799605488777161 \t 100\t\n",
      "14 0.6796298027038574 \t 100\t\n",
      "15 0.6798079013824463 \t 100\t\n",
      "16 0.680533230304718 \t 100\t\n",
      "17 0.6798089146614075 \t 100\t\n",
      "18 0.6798385977745056 \t 100\t\n",
      "19 0.6799489259719849 \t 100\t\n",
      "20 0.6793398857116699 \t 100\t\n",
      "21 0.67996746301651 \t 100\t\n",
      "22 0.6793773770332336 \t 100\t\n",
      "23 0.6794338226318359 \t 100\t\n",
      "24 0.6799653172492981 \t 100\t\n",
      "25 0.6798248291015625 \t 100\t\n",
      "26 0.679603099822998 \t 100\t\n",
      "27 0.6796044707298279 \t 100\t\n",
      "28 0.6791560053825378 \t 100\t\n",
      "29 0.680307924747467 \t 100\t\n",
      "30 0.6797850131988525 \t 100\t\n",
      "31 0.6800018548965454 \t 100\t\n",
      "32 0.6799262166023254 \t 100\t\n",
      "33 0.6806307435035706 \t 100\t\n",
      "34 0.6797515153884888 \t 100\t\n",
      "35 0.6795841455459595 \t 100\t\n",
      "36 0.6797903180122375 \t 100\t\n",
      "37 0.6794509291648865 \t 100\t\n",
      "38 0.67989182472229 \t 100\t\n",
      "39 0.6794681549072266 \t 100\t\n",
      "40 0.6796486973762512 \t 100\t\n",
      "41 0.6805142760276794 \t 100\t\n",
      "42 0.6799349784851074 \t 100\t\n",
      "43 0.6803805828094482 \t 100\t\n",
      "44 0.679763913154602 \t 100\t\n",
      "45 0.6794800758361816 \t 100\t\n",
      "46 0.6796019077301025 \t 100\t\n",
      "47 0.6797792911529541 \t 100\t\n",
      "48 0.6801108121871948 \t 100\t\n",
      "49 0.6796154975891113 \t 100\t\n",
      "50 0.6799824237823486 \t 100\t\n",
      "51 0.6793946623802185 \t 100\t\n",
      "52 0.6801143884658813 \t 100\t\n",
      "53 0.6805781126022339 \t 100\t\n",
      "54 0.679368793964386 \t 100\t\n",
      "55 0.6794100999832153 \t 100\t\n",
      "56 0.6794218420982361 \t 100\t\n",
      "57 0.6802225112915039 \t 100\t\n",
      "58 0.6797965168952942 \t 100\t\n",
      "59 0.6793609857559204 \t 100\t\n",
      "60 0.6796169281005859 \t 100\t\n",
      "61 0.68023282289505 \t 100\t\n",
      "62 0.6795191764831543 \t 100\t\n",
      "63 0.6795833110809326 \t 100\t\n",
      "64 0.6790294051170349 \t 100\t\n",
      "65 0.6805201768875122 \t 100\t\n",
      "66 0.6796345114707947 \t 100\t\n",
      "67 0.6800476312637329 \t 100\t\n",
      "68 0.6801869869232178 \t 100\t\n",
      "69 0.6795861721038818 \t 100\t\n",
      "70 0.6796406507492065 \t 100\t\n",
      "71 0.6805055141448975 \t 100\t\n",
      "72 0.6793423891067505 \t 100\t\n",
      "73 0.6795042753219604 \t 100\t\n",
      "74 0.680812656879425 \t 100\t\n",
      "75 0.6799036264419556 \t 100\t\n",
      "76 0.6797134876251221 \t 100\t\n",
      "77 0.6797295808792114 \t 100\t\n",
      "78 0.6805940866470337 \t 100\t\n",
      "79 0.6794717311859131 \t 100\t\n",
      "80 0.679604172706604 \t 100\t\n",
      "81 0.6796898245811462 \t 100\t\n",
      "82 0.6795920729637146 \t 100\t\n",
      "83 0.6798688173294067 \t 100\t\n",
      "84 0.6789067983627319 \t 100\t\n",
      "85 0.6797956824302673 \t 100\t\n",
      "86 0.6799293756484985 \t 100\t\n",
      "87 0.6794409155845642 \t 100\t\n",
      "88 0.6793387532234192 \t 100\t\n",
      "89 0.6790609955787659 \t 100\t\n",
      "90 0.6793236136436462 \t 100\t\n",
      "91 0.6804203391075134 \t 100\t\n",
      "92 0.6798232793807983 \t 100\t\n",
      "93 0.6794654130935669 \t 100\t\n",
      "94 0.6803458333015442 \t 100\t\n",
      "95 0.6801688075065613 \t 100\t\n",
      "96 0.67939293384552 \t 100\t\n",
      "97 0.6796421408653259 \t 100\t\n",
      "98 0.6808155179023743 \t 100\t\n",
      "99 0.6794615983963013 \t 100\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    #bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    #X_trn, X_vld, y_trn, y_vld = data\n",
    "    #bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    #trace = bdt_model.evals_result()['validation_0']\n",
    "    #print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    #bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8d17d-d03a-4d22-9a8f-537bfb822352",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d23a752-df10-4f18-bc9f-222e20f10212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 8\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5ea4b-dc38-470e-a65d-9c3217dcc73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0.9518972730636597 \t 11\n",
      "0 0.709384024143219 \t 18\t\n",
      "1 0.6903370022773743 \t 11\t\n",
      "2 0.7108402848243713 \t 27\t\n",
      "3 0.6931536793708801 \t 31\t\n",
      "4 0.7491366863250732 \t 14\t\n",
      "5 0.7155307531356812 \t 19\t\n",
      "6 0.7148614525794983 \t 30\t\n",
      "7 0.6891833543777466 \t 11\t\n",
      "8 0.6990330219268799 \t 12\t\n",
      "9 0.7314398884773254 \t 13\t\n",
      "10 0.6853344440460205 \t 14\t\n",
      "11 0.6971005201339722 \t 30\t\n",
      "12 0.7055714130401611 \t 23\t\n",
      "13 0.7031133770942688 \t 11\t\n",
      "14 0.6690502762794495 \t 11\t\n",
      "15 0.7138792276382446 \t 24\t\n",
      "16 0.6743512153625488 \t 14\t\n",
      "17 0.7229437232017517 \t 19\t\n",
      "18 0.7388466596603394 \t 27\t\n",
      "19 0.7298656702041626 \t 18\t\n",
      "20 0.7127333879470825 \t 14\t\n",
      "21 0.6981571316719055 \t 12\t\n",
      "22 0.7467792630195618 \t 11\t\n",
      "23 0.7420686483383179 \t 13\t\n",
      "24 0.7143241167068481 \t 12\t\n",
      "25 0.7168168425559998 \t 20\t\n",
      "26 0.7774333357810974 \t 25\t\n",
      "27 0.7238531708717346 \t 11\t\n",
      "28 0.7375357151031494 \t 15\t\n",
      "29 0.6954509615898132 \t 12\t\n",
      "30 0.7315837740898132 \t 13\t\n",
      "31 0.7061780691146851 \t 12\t\n",
      "32 0.7016160488128662 \t 14\t\n",
      "33 0.6699199080467224 \t 33\t\n",
      "34 0.7319837212562561 \t 29\t\n",
      "35 0.6994376182556152 \t 11\t\n",
      "36 0.6985298991203308 \t 11\t\n",
      "37 0.6926833987236023 \t 19\t\n",
      "38 0.7123429775238037 \t 11\t\n",
      "39 0.7307416796684265 \t 20\t\n",
      "40 0.6952579021453857 \t 19\t\n",
      "41 0.782962441444397 \t 15\t\n",
      "42 0.6791807413101196 \t 21\t\n",
      "43 0.7025118470191956 \t 12\t\n",
      "44 0.6870179772377014 \t 14\t\n",
      "45 0.6905309557914734 \t 21\t\n",
      "46 0.7015548944473267 \t 14\t\n",
      "47 0.7520163655281067 \t 29\t\n",
      "48 0.7206225395202637 \t 13\t\n",
      "49 0.7416555881500244 \t 16\t\n",
      "50 0.709735095500946 \t 26\t\n",
      "51 0.7089530229568481 \t 11\t\n",
      "52 0.7230337262153625 \t 16\t\n",
      "53 0.6718707084655762 \t 22\t\n",
      "54 0.7250135540962219 \t 17\t\n",
      "55 0.6820834279060364 \t 11\t\n",
      "56 0.7074435949325562 \t 12\t\n",
      "57 0.688452959060669 \t 20\t\n",
      "58 0.7314817905426025 \t 11\t\n",
      "59 0.7170465588569641 \t 14\t\n",
      "60 0.702341616153717 \t 13\t\n",
      "61 0.666179895401001 \t 11\t\n",
      "62 0.7127292156219482 \t 11\t\n",
      "63 0.7010020613670349 \t 11\t\n",
      "64 0.7164983153343201 \t 11\t\n",
      "65 0.7060964703559875 \t 15\t\n",
      "66 0.7190104722976685 \t 12\t\n",
      "67 0.7139549255371094 \t 18\t\n",
      "68 0.7013193368911743 \t 17\t\n",
      "69 0.6594247221946716 \t 16\t\n",
      "70 0.746380627155304 \t 13\t\n",
      "71 0.6900457739830017 \t 14\t\n",
      "72 0.6925997138023376 \t 14\t\n",
      "73 0.7272960543632507 \t 16\t\n",
      "74 0.6920022368431091 \t 20\t\n",
      "75 0.7644491791725159 \t 16\t\n",
      "76 0.7016369700431824 \t 14\t\n",
      "77 0.7044133543968201 \t 11\t\n",
      "78 0.7323266863822937 \t 20\t\n",
      "79 0.7196840047836304 \t 23\t\n",
      "80 0.782949686050415 \t 14\t\n",
      "81 0.7717683911323547 \t 13\t\n",
      "82 0.7059258818626404 \t 13\t\n",
      "83 0.706663191318512 \t 12\t\n",
      "84 0.7186335921287537 \t 20\t\n",
      "85 0.7201023101806641 \t 13\t\n",
      "86 0.7331074476242065 \t 11\t\n",
      "87 0.71026211977005 \t 18\t\n",
      "88 0.7546181678771973 \t 12\t\n",
      "89 0.7066775560379028 \t 14\t\n",
      "90 0.7191600203514099 \t 12\t\n",
      "91 0.7146489024162292 \t 17\t\n",
      "92 0.7370787262916565 \t 18\t\n",
      "93 0.7350326776504517 \t 26\t\n",
      "94 0.7397605776786804 \t 12\t\n",
      "95 0.7058631777763367 \t 16\t\n",
      "96 0.6842207312583923 \t 14\t\n",
      "97 0.7300035953521729 \t 16\t\n",
      "98 0.681471586227417 \t 14\t\n",
      "99 0.7250635027885437 \t 12\t\n",
      "\n",
      "===================================================\n",
      "1000\n",
      "0.6078300537653267 \t 23\n",
      "0 0.6143078804016113 \t 24\t\n",
      "1 0.620725691318512 \t 32\t\n",
      "2 0.6287177205085754 \t 23\t\n",
      "3 0.633126974105835 \t 25\t\n",
      "4 0.6325826048851013 \t 21\t\n",
      "5 0.6381672620773315 \t 26\t\n",
      "6 0.6333668231964111 \t 35\t\n",
      "7 0.6304200291633606 \t 17\t\n",
      "8 0.6450865268707275 \t 20\t\n",
      "9 0.6292452812194824 \t 22\t\n",
      "10 0.6404582262039185 \t 27\t\n",
      "11 0.6440305113792419 \t 19\t\n",
      "12 0.6261605024337769 \t 21\t\n",
      "13 0.6314833164215088 \t 25\t\n",
      "14 0.6504704356193542 \t 34\t\n",
      "15 0.6394928693771362 \t 30\t\n",
      "16 0.6225827932357788 \t 20\t\n",
      "17 0.6324000954627991 \t 18\t\n",
      "18 0.6275679469108582 \t 22\t\n",
      "19 0.6359745860099792 \t 27\t\n",
      "20 0.6310551762580872 \t 26\t\n",
      "21 0.631714403629303 \t 27\t\n",
      "22 0.6405708193778992 \t 18\t\n",
      "23 0.6292231678962708 \t 20\t\n",
      "24 0.6426370739936829 \t 20\t\n",
      "25 0.6288697719573975 \t 22\t\n",
      "26 0.634560227394104 \t 28\t\n",
      "27 0.6429110169410706 \t 25\t\n",
      "28 0.6189242601394653 \t 21\t\n",
      "29 0.6417050361633301 \t 20\t\n",
      "30 0.6289882063865662 \t 19\t\n",
      "31 0.6273749470710754 \t 22\t\n",
      "32 0.637649416923523 \t 20\t\n",
      "33 0.6286323070526123 \t 17\t\n",
      "34 0.6297308206558228 \t 22\t\n",
      "35 0.6257867217063904 \t 18\t\n",
      "36 0.6392427682876587 \t 27\t\n",
      "37 0.6324108242988586 \t 32\t\n",
      "38 0.6316590905189514 \t 20\t\n",
      "39 0.6251860857009888 \t 21\t\n",
      "40 0.6327833533287048 \t 30\t\n",
      "41 0.6367542743682861 \t 22\t\n",
      "42 0.6256266832351685 \t 23\t\n",
      "43 0.6441572308540344 \t 28\t\n",
      "44 0.6332496404647827 \t 32\t\n",
      "45 0.6296461820602417 \t 18\t\n",
      "46 0.6410207152366638 \t 29\t\n",
      "47 0.6234330534934998 \t 21\t\n",
      "48 0.6370786428451538 \t 25\t\n",
      "49 0.6254344582557678 \t 19\t\n",
      "50 0.6398974657058716 \t 23\t\n",
      "51 0.6361767053604126 \t 21\t\n",
      "52 0.63812255859375 \t 22\t\n",
      "53 0.6343259215354919 \t 28\t\n",
      "54 0.619536280632019 \t 25\t\n",
      "55 0.6296439170837402 \t 20\t\n",
      "56 0.632016122341156 \t 28\t\n",
      "57 0.6398107409477234 \t 23\t\n",
      "58 0.6438387632369995 \t 22\t\n",
      "59 0.6358059644699097 \t 24\t\n",
      "60 0.6254759430885315 \t 25\t\n",
      "61 0.626513659954071 \t 23\t\n",
      "62 0.6299804449081421 \t 22\t\n",
      "63 0.6312261819839478 \t 19\t\n",
      "64 0.6359591484069824 \t 38\t\n",
      "65 0.6476545333862305 \t 19\t\n",
      "66 0.6317407488822937 \t 29\t\n",
      "67 0.6295847296714783 \t 20\t\n",
      "68 0.6386283040046692 \t 20\t\n",
      "69 0.6321872472763062 \t 24\t\n",
      "70 0.6170649528503418 \t 35\t\n",
      "71 0.6296983361244202 \t 20\t\n",
      "72 0.6327931880950928 \t 27\t\n",
      "73 0.640516459941864 \t 23\t\n",
      "74 0.6446596384048462 \t 31\t\n",
      "75 0.6260227560997009 \t 20\t\n",
      "76 0.6346306204795837 \t 33\t\n",
      "77 0.6360145211219788 \t 24\t\n",
      "78 0.6521380543708801 \t 25\t\n",
      "79 0.6344636678695679 \t 24\t\n",
      "80 0.632315456867218 \t 22\t\n",
      "81 0.6322817206382751 \t 21\t\n",
      "82 0.625903844833374 \t 22\t\n",
      "83 0.6194499731063843 \t 28\t\n",
      "84 0.624226450920105 \t 25\t\n",
      "85 0.6372271776199341 \t 21\t\n",
      "86 0.6211719512939453 \t 25\t\n",
      "87 0.6392719149589539 \t 23\t\n",
      "88 0.6239962577819824 \t 25\t\n",
      "89 0.6310061812400818 \t 19\t\n",
      "90 0.6333414316177368 \t 29\t\n",
      "91 0.6248311400413513 \t 29\t\n",
      "92 0.6277614831924438 \t 47\t\n",
      "93 0.6245312690734863 \t 19\t\n",
      "94 0.6340160965919495 \t 23\t\n",
      "95 0.6258096098899841 \t 26\t\n",
      "96 0.6309432983398438 \t 22\t\n",
      "97 0.6292186379432678 \t 23\t\n",
      "98 0.625302255153656 \t 32\t\n",
      "99 0.6352430582046509 \t 20\t\n",
      "\n",
      "===================================================\n",
      "10000\n",
      "0.45482013131691346 \t 72\n",
      "0 0.3375754952430725 \t 100\t\n",
      "1 0.34345996379852295 \t 100\t\n",
      "2 0.35310736298561096 \t 100\t\n",
      "3 0.3409672975540161 \t 100\t\n",
      "4 0.34305688738822937 \t 100\t\n",
      "5 0.33375462889671326 \t 100\t\n",
      "6 0.3504858613014221 \t 100\t\n",
      "7 0.345089852809906 \t 100\t\n",
      "8 0.3435576558113098 \t 100\t\n",
      "9 0.34008949995040894 \t 100\t\n",
      "10 0.33529365062713623 \t 100\t\n",
      "11 0.35062175989151 \t 100\t\n",
      "12 0.3368602991104126 \t 100\t\n",
      "13 0.3377721309661865 \t 100\t\n",
      "14 0.3486829698085785 \t 100\t\n",
      "15 0.34377673268318176 \t 100\t\n",
      "16 0.33917734026908875 \t 100\t\n",
      "17 0.354815274477005 \t 100\t\n",
      "18 0.3455086052417755 \t 100\t\n",
      "19 0.338392972946167 \t 100\t\n",
      "20 0.3413899838924408 \t 100\t\n",
      "21 0.3436417579650879 \t 100\t\n",
      "22 0.34349891543388367 \t 100\t\n",
      "23 0.3347087502479553 \t 100\t\n",
      "24 0.3598804771900177 \t 100\t\n",
      "25 0.35836976766586304 \t 100\t\n",
      "26 0.339444100856781 \t 100\t\n",
      "27 0.3476371169090271 \t 100\t\n",
      "28 0.3387044370174408 \t 100\t\n",
      "29 0.3438219726085663 \t 100\t\n",
      "30 0.3471173644065857 \t 100\t\n",
      "31 0.35294151306152344 \t 100\t\n",
      "32 0.34124755859375 \t 100\t\n",
      "33 0.3494538366794586 \t 100\t\n",
      "34 0.334171324968338 \t 100\t\n",
      "35 0.34351328015327454 \t 100\t\n",
      "36 0.3357486426830292 \t 100\t\n",
      "37 0.33958670496940613 \t 100\t\n",
      "38 0.345028281211853 \t 100\t\n",
      "39 0.3508177101612091 \t 100\t\n",
      "40 0.34833309054374695 \t 100\t\n",
      "41 0.3487376570701599 \t 100\t\n",
      "42 0.342899888753891 \t 100\t\n",
      "43 0.34222549200057983 \t 100\t\n",
      "44 0.3611273765563965 \t 100\t\n",
      "45 0.33961498737335205 \t 100\t\n",
      "46 0.33226630091667175 \t 100\t\n",
      "47 0.34033048152923584 \t 100\t\n",
      "48 0.34251850843429565 \t 100\t\n",
      "49 0.3389784097671509 \t 100\t\n",
      "50 0.34236252307891846 \t 100\t\n",
      "51 0.331944078207016 \t 100\t\n",
      "52 0.34003815054893494 \t 100\t\n",
      "53 0.3464592397212982 \t 100\t\n",
      "54 0.3474883437156677 \t 100\t\n",
      "55 0.3437809944152832 \t 100\t\n",
      "56 0.34498122334480286 \t 100\t\n",
      "57 0.3553899824619293 \t 100\t\n",
      "58 0.344035267829895 \t 100\t\n",
      "59 0.3440849483013153 \t 100\t\n",
      "60 0.35240253806114197 \t 100\t\n",
      "61 0.35063350200653076 \t 100\t\n",
      "62 0.34006938338279724 \t 100\t\n",
      "63 0.3380580544471741 \t 100\t\n",
      "64 0.3491705358028412 \t 100\t\n",
      "65 0.3551029562950134 \t 100\t\n",
      "66 0.35443028807640076 \t 100\t\n",
      "67 0.33537596464157104 \t 100\t\n",
      "68 0.34675461053848267 \t 100\t\n",
      "69 0.349773108959198 \t 100\t\n",
      "70 0.3445517122745514 \t 100\t\n",
      "71 0.3445325195789337 \t 100\t\n",
      "72 0.3521602749824524 \t 100\t\n",
      "73 0.3508756756782532 \t 100\t\n",
      "74 0.349027156829834 \t 100\t\n",
      "75 0.33847999572753906 \t 100\t\n",
      "76 0.3448728919029236 \t 100\t\n",
      "77 0.33709657192230225 \t 100\t\n",
      "78 0.3423582911491394 \t 100\t\n",
      "79 0.3513525426387787 \t 100\t\n",
      "80 0.34295713901519775 \t 100\t\n",
      "81 0.34855151176452637 \t 100\t\n",
      "82 0.3385098874568939 \t 100\t\n",
      "83 0.33887216448783875 \t 100\t\n",
      "84 0.3377937376499176 \t 100\t\n",
      "85 0.3554981052875519 \t 100\t\n",
      "86 0.34159040451049805 \t 100\t\n",
      "87 0.338562935590744 \t 100\t\n",
      "88 0.33804553747177124 \t 100\t\n",
      "89 0.3344878554344177 \t 100\t\n",
      "90 0.33962690830230713 \t 100\t\n",
      "91 0.34280550479888916 \t 100\t\n",
      "92 0.3538309335708618 \t 100\t\n",
      "93 0.3416011929512024 \t 100\t\n",
      "94 0.35289472341537476 \t 100\t\n",
      "95 0.3498065769672394 \t 100\t\n",
      "96 0.35162419080734253 \t 100\t\n",
      "97 0.35087624192237854 \t 100\t\n",
      "98 0.33630338311195374 \t 100\t\n",
      "99 0.3423784673213959 \t 100\t\n",
      "\n",
      "===================================================\n",
      "100000\n",
      "0.37043665670823495 \t 100\n",
      "0 0.27765870094299316 \t 100\t\n",
      "1 0.28142327070236206 \t 100\t\n",
      "2 0.2818315327167511 \t 100\t\n",
      "3 0.2765744626522064 \t 100\t\n",
      "4 0.282291442155838 \t 100\t\n",
      "5 0.284334659576416 \t 100\t\n",
      "6 0.27973219752311707 \t 100\t\n",
      "7 0.28218889236450195 \t 100\t\n",
      "8 0.28031110763549805 \t 100\t\n",
      "9 0.28040453791618347 \t 100\t\n",
      "10 0.27808746695518494 \t 100\t\n",
      "11 0.2829422950744629 \t 100\t\n",
      "12 0.2810603380203247 \t 100\t\n",
      "13 0.28183713555336 \t 100\t\n",
      "14 0.28496792912483215 \t 100\t\n",
      "15 0.2802692651748657 \t 100\t\n",
      "16 0.28084200620651245 \t 100\t\n",
      "17 0.2790227234363556 \t 100\t\n",
      "18 0.28015777468681335 \t 100\t\n",
      "19 0.28455522656440735 \t 100\t\n",
      "20 0.2827293872833252 \t 100\t\n",
      "21 0.2800883650779724 \t 100\t\n",
      "22 0.2789590656757355 \t 100\t\n",
      "23 0.2821722626686096 \t 100\t\n",
      "24 0.2786351144313812 \t 100\t\n",
      "25 0.28049492835998535 \t 100\t\n",
      "26 0.2861282229423523 \t 100\t\n",
      "27 0.2823595106601715 \t 100\t\n",
      "28 0.2792856693267822 \t 100\t\n",
      "29 0.28210997581481934 \t 100\t\n",
      "30 0.2823292911052704 \t 100\t\n",
      "31 0.28169652819633484 \t 100\t\n",
      "32 0.2785604000091553 \t 100\t\n",
      "33 0.27795928716659546 \t 100\t\n",
      "34 0.2823483943939209 \t 100\t\n",
      "35 0.28498828411102295 \t 100\t\n",
      "36 0.2826118469238281 \t 100\t\n",
      "37 0.2827877402305603 \t 100\t\n",
      "38 0.2816968262195587 \t 100\t\n",
      "39 0.2783501148223877 \t 100\t\n",
      "40 0.2762593626976013 \t 100\t\n",
      "41 0.28176113963127136 \t 100\t\n",
      "42 0.2783263027667999 \t 100\t\n",
      "43 0.2786933481693268 \t 100\t\n",
      "44 0.28083133697509766 \t 100\t\n",
      "45 0.28114762902259827 \t 100\t\n",
      "46 0.2800314724445343 \t 100\t\n",
      "47 0.27783530950546265 \t 100\t\n",
      "48 0.2803078591823578 \t 100\t\n",
      "49 0.2806079685688019 \t 100\t\n",
      "50 0.2782266139984131 \t 100\t\n",
      "51 0.2822965681552887 \t 100\t\n",
      "52 0.2816442847251892 \t 100\t\n",
      "53 0.2792738676071167 \t 100\t\n",
      "54 0.28194600343704224 \t 100\t\n",
      "55 0.28124645352363586 \t 100\t\n",
      "56 0.27970778942108154 \t 100\t\n",
      "57 0.28174808621406555 \t 100\t\n",
      "58 0.2775520384311676 \t 100\t\n",
      "59 0.27893656492233276 \t 100\t\n",
      "60 0.2808620035648346 \t 100\t\n",
      "61 0.27792853116989136 \t 100\t\n",
      "62 0.28551191091537476 \t 100\t\n",
      "63 0.28103575110435486 \t 100\t\n",
      "64 0.2755742073059082 \t 100\t\n",
      "65 0.28078174591064453 \t 100\t\n",
      "66 0.28127434849739075 \t 100\t\n",
      "67 0.2842487096786499 \t 100\t\n",
      "68 0.2811514139175415 \t 100\t\n",
      "69 0.2805972695350647 \t 100\t\n",
      "70 0.28218406438827515 \t 100\t\n",
      "71 0.2806485891342163 \t 100\t\n",
      "72 0.28240084648132324 \t 100\t\n",
      "73 0.2834166884422302 \t 100\t\n",
      "74 0.28053709864616394 \t 100\t\n",
      "75 0.2790660262107849 \t 100\t\n",
      "76 0.2818184196949005 \t 100\t\n",
      "77 0.2769820988178253 \t 100\t\n",
      "78 0.27952301502227783 \t 100\t\n",
      "79 0.2823329269886017 \t 100\t\n",
      "80 0.28383925557136536 \t 100\t\n",
      "81 0.2827589213848114 \t 100\t\n",
      "82 0.2826564311981201 \t 100\t\n",
      "83 0.2785206437110901 \t 100\t\n",
      "84 0.27474913001060486 \t 100\t\n",
      "85 0.2833174467086792 \t 100\t\n",
      "86 0.2821369767189026 \t 100\t\n",
      "87 0.28124475479125977 \t 100\t\n",
      "88 0.2804253101348877 \t 100\t\n",
      "89 0.2819846570491791 \t 100\t\n",
      "90 0.28123024106025696 \t 100\t\n",
      "91 0.28110212087631226 \t 100\t\n",
      "92 0.2776033282279968 \t 100\t\n",
      "93 0.28328800201416016 \t 100\t\n",
      "94 0.28273963928222656 \t 100\t\n",
      "95 0.27784276008605957 \t 100\t\n",
      "96 0.27946752309799194 \t 100\t\n",
      "97 0.2811012864112854 \t 100\t\n",
      "98 0.2815941870212555 \t 100\t\n",
      "99 0.278921514749527 \t 100\t\n",
      "\n",
      "===================================================\n",
      "1000000\n",
      "0.3563645810351724 \t 100\n",
      "0 0.26082101464271545 \t 100\t\n",
      "1 0.25919562578201294 \t 100\t\n",
      "2 0.26098132133483887 \t 100\t\n",
      "3 0.2582319676876068 \t 100\t\n",
      "4 0.26207053661346436 \t 100\t\n",
      "5 0.2613554894924164 \t 100\t\n",
      "6 0.26026812195777893 \t 100\t\n",
      "7 0.2612721920013428 \t 100\t\n",
      "8 0.26114386320114136 \t 100\t\n",
      "9 0.2628743350505829 \t 100\t\n",
      "10 0.26131874322891235 \t 100\t\n",
      "11 0.2590778172016144 \t 100\t\n",
      "12 0.2589606046676636 \t 100\t\n",
      "13 0.2601695954799652 \t 100\t\n",
      "14 0.25881534814834595 \t 100\t\n",
      "15 0.25779715180397034 \t 100\t"
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef99106-1889-4016-afdc-36c47f2bb0a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $d = 11$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa77dcda-85fc-4e15-afc9-2081a23d9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "num = 0\n",
    "reps = 100\n",
    "d = 11\n",
    "Ns = 10**np.arange(2, 8)\n",
    "\n",
    "# Model parameters\n",
    "bce_params = {'loss':bce, 'd': d}\n",
    "\n",
    "filestr = 'models/zenodo/{}/set_{}/'.format(d, num)\n",
    "bce_filestr = filestr + 'bce/model_{}_{}.h5'\n",
    "bdt_filestr = filestr + 'bdt/model_{}.h5'\n",
    "gbc_filestr = filestr + 'gbc/model_{}_{}.h5'\n",
    "\n",
    "if not os.path.isdir(filestr):\n",
    "    os.mkdir(filestr)\n",
    "\n",
    "if not os.path.isdir(filestr + 'bce/'):\n",
    "    os.mkdir(filestr + 'bce/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'bdt/'):\n",
    "    os.mkdir(filestr + 'bdt/')\n",
    "    \n",
    "if not os.path.isdir(filestr + 'gbc/'):\n",
    "    os.mkdir(filestr + 'gbc/')\n",
    "\n",
    "# Data parameters\n",
    "X = np.load('data/zenodo/{}/X_trn.npy'.format(d))\n",
    "y = np.load('data/zenodo/{}/y_trn.npy'.format(d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ba1cb-8b9c-4545-bb0d-9ddbaf89bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "100\n",
      "0.7719044119119645 \t 11\n",
      "0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 15:35:49.821434: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 15:35:50.452955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22824 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:c1:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87884521484375 \t 14\t1 0.7917284965515137 \t 16\t2 0.8255318403244019 \t 11\t3 0.9300541877746582 \t 15\t4 0.7780203819274902 \t 20\t5 0.9699823260307312 \t 12\t6 0.8516292572021484 \t 14\t7 0.7486464977264404 \t 19\t8 0.9657136797904968 \t 11\t9 0.9924226403236389 \t 12\t10 0.8113024830818176 \t 16\t11 0.9820797443389893 \t 11\t12 0.9461304545402527 \t 12\t13 1.0104331970214844 \t 11\t14 0.7584745287895203 \t 17\t15 1.0052802562713623 \t 12\t16 0.956510603427887 \t 12\t17 0.969941258430481 \t 11\t18 0.8772228360176086 \t 14\t19 0.9899536967277527 \t 14\t20 0.8368549346923828 \t 11\t21 1.0103875398635864 \t 22\t22 0.9701393842697144 \t 11\t23 0.8077855706214905 \t 17\t24 0.7590672373771667 \t 16\t25 1.1377935409545898 \t 11\t26 0.8945189118385315 \t 24\t27 0.8300597667694092 \t 11\t28 0.9364996552467346 \t 12\t29 1.0152965784072876 \t 12\t30 0.9023878574371338 \t 11\t31 0.7208293676376343 \t 16\t32 0.9746490716934204 \t 14\t33 0.8506117463111877 \t 11\t34 0.814598798751831 \t 11\t35 0.9330777525901794 \t 11\t36 0.8216873407363892 \t 11\t37 0.8917598724365234 \t 11\t38 0.7959210872650146 \t 14\t39 0.7421556711196899 \t 21\t40 0.8216590881347656 \t 12\t41 0.9617167115211487 \t 13\t42 0.7428314089775085 \t 11\t43 0.8309754729270935 \t 13\t44 0.7214946150779724 \t 14\t45 0.8015955090522766 \t 11\t46 0.9535140991210938 \t 11\t47 0.9203053116798401 \t 11\t48 0.946358323097229 \t 11\t49 0.9091984033584595 \t 16\t50 0.797420859336853 \t 14\t51 0.9010583758354187 \t 13\t52 0.702628493309021 \t 11\t53 0.9063597917556763 \t 11\t54 1.0241895914077759 \t 14\t55 0.891918957233429 \t 17\t56 0.9876717925071716 \t 11\t57 0.9686765074729919 \t 11\t58 0.8504368662834167 \t 11\t59 0.9287845492362976 \t 11\t60 0.7179742455482483 \t 11\t61 0.8636058568954468 \t 12\t62 0.8768308162689209 \t 13\t63 0.7958691120147705 \t 12\t64 0.7968878149986267 \t 13\t65 0.828499436378479 \t 11\t66 0.9344432950019836 \t 14\t67 0.9012404084205627 \t 11\t68 0.8925836086273193 \t 12\t69 0.8689378499984741 \t 11\t70 0.9517550468444824 \t 11\t71 0.9729159474372864 \t 14\t72 0.7142103314399719 \t 11\t73 0.8418023586273193 \t 12\t74 0.7639959454536438 \t 11\t75 0.9098703861236572 \t 15\t76 0.954170823097229 \t 11\t77 0.8319486975669861 \t 12\t78 0.9202926754951477 \t 15\t79 0.8907086253166199 \t 11\t80 0.9853643774986267 \t 11\t81 0.9254144430160522 \t 11\t82 0.9211791157722473 \t 11\t83 0.7729415893554688 \t 12\t84 0.8634361028671265 \t 13\t85 0.8012763857841492 \t 11\t86 1.0464211702346802 \t 12\t87 0.8520194292068481 \t 11\t88 0.7451659440994263 \t 11\t89 0.8380892276763916 \t 15\t90 1.0077908039093018 \t 19\t91 0.8903601765632629 \t 14\t92 1.0264613628387451 \t 12\t93 0.750845193862915 \t 17\t94 0.993755042552948 \t 11\t95 1.002344012260437 \t 11\t96 0.9744788408279419 \t 11\t97 0.7883859872817993 \t 11\t98 0.8356701135635376 \t 13\t99 0.8983502984046936 \t 15\t\n",
      "===================================================\n",
      "1000\n",
      "0.7094682978019118 \t 20\n",
      "0 0.6722387075424194 \t 27\t1 0.6689797043800354 \t 32\t2 0.6773018836975098 \t 28\t3 0.6606743335723877 \t 25\t4 0.6571248769760132 \t 25\t5 0.6559275388717651 \t 35\t6 0.6788261532783508 \t 26\t7 0.6498763561248779 \t 25\t8 0.6441377401351929 \t 32\t9 0.677136242389679 \t 24\t10 0.6470930576324463 \t 29\t11 0.6605169773101807 \t 24\t12 0.6469618082046509 \t 31\t13 0.6497113108634949 \t 27\t14 0.6621766090393066 \t 28\t15 0.6513429880142212 \t 36\t16 0.6731461882591248 \t 25\t17 0.6535953283309937 \t 31\t18 0.660567045211792 \t 32\t19 0.6571175456047058 \t 29\t20 0.6750013828277588 \t 53\t21 0.653853178024292 \t 26\t22 0.6662027835845947 \t 25\t23 0.6676543951034546 \t 26\t24 0.6510090231895447 \t 35\t25 0.6601638197898865 \t 23\t26 0.6614006161689758 \t 29\t27 0.6620181798934937 \t 28\t28 0.6609740257263184 \t 26\t29 0.6606072783470154 \t 26\t30 0.6631003618240356 \t 21\t31 0.6621955633163452 \t 25\t32 0.6596550941467285 \t 28\t33 0.6483243703842163 \t 25\t34 0.6574022173881531 \t 40\t35 0.6523955464363098 \t 29\t36 0.6542636752128601 \t 30\t37 0.6729111671447754 \t 23\t38 0.6719410419464111 \t 27\t39 0.6677197217941284 \t 24\t40 0.6465209126472473 \t 26\t41 0.6575194001197815 \t 20\t42 0.6476414203643799 \t 24\t43 0.6628771424293518 \t 25\t44 0.6758676171302795 \t 29\t45 0.6464366316795349 \t 31\t46 0.6580356359481812 \t 29\t47 0.6519291996955872 \t 21\t48 0.6710989475250244 \t 26\t49 0.657051146030426 \t 25\t50 0.677067756652832 \t 34\t51 0.6665804386138916 \t 26\t52 0.6728890538215637 \t 24\t53 0.6546735167503357 \t 25\t54 0.6441622376441956 \t 26\t55 0.6642394065856934 \t 29\t56 0.6744073629379272 \t 34\t57 0.6614033579826355 \t 30\t58 0.6543450951576233 \t 26\t59 0.654757559299469 \t 24\t60 0.6631303429603577 \t 28\t61 0.6741456389427185 \t 28\t62 0.6728100180625916 \t 29\t63 0.6632481813430786 \t 31\t64 0.6646341681480408 \t 32\t65 0.6542304754257202 \t 33\t66 0.6543090343475342 \t 26\t67 0.6783856153488159 \t 35\t68 0.6558132171630859 \t 44\t69 0.6690055131912231 \t 33\t70 0.6815427541732788 \t 29\t71 0.665800929069519 \t 24\t72 0.6474840044975281 \t 34\t73 0.639597475528717 \t 28\t74 0.6705564260482788 \t 29\t75 0.6560782194137573 \t 32\t76 0.6529382467269897 \t 34\t77 0.681637704372406 \t 36\t78 0.6747735738754272 \t 30\t79 0.662204384803772 \t 25\t80 0.6606557369232178 \t 27\t81 0.6862902045249939 \t 22\t82 0.6715842485427856 \t 33\t83 0.6761935949325562 \t 32\t84 0.6574466824531555 \t 29\t85 0.6568532586097717 \t 30\t86 0.6545553803443909 \t 35\t87 0.661827027797699 \t 27\t88 0.6615698337554932 \t 22\t89 0.653268575668335 \t 34\t90 0.6824020147323608 \t 28\t91 0.6580986380577087 \t 24\t92 0.6545767784118652 \t 34\t93 0.6605249047279358 \t 34\t94 0.6514653563499451 \t 27\t95 0.641165554523468 \t 32\t96 0.6508120894432068 \t 30\t97 0.6433682441711426 \t 31\t98 0.67371666431427 \t 21\t99 0.6556326746940613 \t 27\t\n",
      "===================================================\n",
      "10000\n",
      "0.5280892907662171 \t 72\n",
      "0 0.47019702196121216 \t 100\t1 0.48349112272262573 \t 100\t2 0.48299697041511536 \t 100\t3 0.48136773705482483 \t 100\t4 0.4758509695529938 \t 100\t5 0.48987188935279846 \t 100\t6 0.4785129427909851 \t 100\t7 0.486820787191391 \t 100\t8 0.4802681505680084 \t 100\t9 0.4881398379802704 \t 100\t10 0.4950389564037323 \t 100\t11 0.4922853112220764 \t 100\t12 0.4695083498954773 \t 100\t13 0.4919675886631012 \t 100\t14 0.48836368322372437 \t 100\t15 0.47646889090538025 \t 100\t16 0.4895756244659424 \t 100\t17 0.4910379946231842 \t 100\t18 0.47581616044044495 \t 100\t19 0.49123111367225647 \t 100\t20 0.4955168068408966 \t 100\t21 0.4840056598186493 \t 100\t22 0.4736069440841675 \t 100\t23 0.4673789441585541 \t 100\t24 0.4792850613594055 \t 100\t25 0.4817273020744324 \t 100\t26 0.49731209874153137 \t 100\t27 0.4966579079627991 \t 100\t28 0.4802120625972748 \t 100\t29 0.4852530360221863 \t 100\t30 0.4811705946922302 \t 100\t31 0.48770156502723694 \t 100\t32 0.5021776556968689 \t 100\t33 0.485232412815094 \t 100\t34 0.48985394835472107 \t 100\t35 0.4766692817211151 \t 100\t36 0.48397591710090637 \t 100\t37 0.4719199240207672 \t 100\t38 0.49473750591278076 \t 100\t39 0.4934055805206299 \t 100\t40 0.4914543032646179 \t 100\t41 0.4856790006160736 \t 100\t42 0.4830557107925415 \t 100\t43 0.47719061374664307 \t 100\t44 0.5005353093147278 \t 100\t45 0.4865838289260864 \t 100\t46 0.48959776759147644 \t 100\t47 0.4945559501647949 \t 100\t48 0.4858781397342682 \t 100\t49 0.4907591938972473 \t 100\t50 0.48058629035949707 \t 100\t51 0.49044427275657654 \t 100\t52 0.47405293583869934 \t 100\t53 0.4955354928970337 \t 100\t54 0.4693714380264282 \t 100\t55 0.49100762605667114 \t 100\t56 0.4916466772556305 \t 100\t57 0.4666234254837036 \t 100\t58 0.4801645576953888 \t 100\t59 0.47594505548477173 \t 100\t60 0.48841527104377747 \t 100\t61 0.48412802815437317 \t 100\t62 0.48516279458999634 \t 100\t63 0.4764009714126587 \t 100\t64 0.4803406298160553 \t 100\t65 0.48014000058174133 \t 100\t66 0.48149141669273376 \t 100\t67 0.4782984256744385 \t 100\t68 0.48618730902671814 \t 100\t69 0.4905708134174347 \t 100\t70 0.4774641692638397 \t 100\t71 0.49900126457214355 \t 100\t72 0.4843981862068176 \t 100\t73 0.4832099974155426 \t 100\t74 0.4904571771621704 \t 100\t75 0.4780483543872833 \t 100\t76 0.48221299052238464 \t 100\t77 0.4832228422164917 \t 100\t78 0.4774859845638275 \t 100\t79 0.49206602573394775 \t 100\t80 0.47258076071739197 \t 100\t81 0.4973559081554413 \t 100\t82 0.46928271651268005 \t 100\t83 0.4771725535392761 \t 100\t84 0.4964715838432312 \t 100\t85 0.4848010241985321 \t 100\t86 0.48330897092819214 \t 100\t87 0.4928881824016571 \t 100\t88 0.49070850014686584 \t 100\t89 0.48563334345817566 \t 100\t90 0.47576263546943665 \t 100\t91 0.49320244789123535 \t 100\t92 0.4935210049152374 \t 100\t93 0.5000730752944946 \t 100\t94 0.4843043088912964 \t 100\t95 0.4814314842224121 \t 100\t96 0.4671115577220917 \t 100\t97 0.48880141973495483 \t 100\t98 0.504584789276123 \t 100\t99 0.47127479314804077 \t 100\t\n",
      "===================================================\n",
      "100000\n",
      "0.4461917473495542 \t 100\n",
      "0 0.3644181787967682 \t 100\t1 0.3600011467933655 \t 100\t2 0.36531683802604675 \t 100\t3 0.3611809015274048 \t 100\t4 0.35539165139198303 \t 100\t5 0.3626059293746948 \t 100\t6 0.3639710247516632 \t 100\t7 0.3673926293849945 \t 100\t8 0.36482352018356323 \t 100\t9 0.36626967787742615 \t 100\t10 0.3660123944282532 \t 100\t11 0.36234477162361145 \t 100\t12 0.36196598410606384 \t 100\t13 0.36351606249809265 \t 100\t14 0.3625117540359497 \t 100\t15 0.367462158203125 \t 100\t16 0.36061468720436096 \t 100\t17 0.3658145070075989 \t 100\t18 0.35718896985054016 \t 100\t19 0.3653941750526428 \t 100\t20 0.3631216287612915 \t 100\t21 0.35754886269569397 \t 100\t22 0.3702569901943207 \t 100\t23 0.3559291660785675 \t 100\t24 0.35992416739463806 \t 100\t25 0.3640587031841278 \t 100\t26 0.3585160970687866 \t 100\t27 0.35852712392807007 \t 100\t28 0.3615987002849579 \t 100\t29 0.36349576711654663 \t 100\t30 0.3675290644168854 \t 100\t31 0.3647509813308716 \t 100\t32 0.3668815493583679 \t 100\t33 0.3598543703556061 \t 100\t34 0.36291202902793884 \t 100\t35 0.3574603199958801 \t 100\t36 0.3625105321407318 \t 100\t37 0.3504262864589691 \t 100\t38 0.3600781261920929 \t 100\t39 0.3590574562549591 \t 100\t40 0.36143726110458374 \t 100\t41 0.36485999822616577 \t 100\t42 0.36986956000328064 \t 100\t43 0.36275991797447205 \t 100\t44 0.36449819803237915 \t 100\t45 0.3628026247024536 \t 100\t46 0.36446449160575867 \t 100\t47 0.3599141538143158 \t 100\t48 0.3630525767803192 \t 100\t49 0.3564189374446869 \t 100\t50 0.36289188265800476 \t 100\t51 0.3575593829154968 \t 100\t52 0.36872613430023193 \t 100\t53 0.3595823049545288 \t 100\t54 0.35969406366348267 \t 100\t55 0.3594602644443512 \t 100\t56 0.361625611782074 \t 100\t57 0.3630446195602417 \t 100\t58 0.35665661096572876 \t 100\t59 0.3690457344055176 \t 100\t60 0.36171695590019226 \t 100\t61 0.36678609251976013 \t 100\t62 0.36159032583236694 \t 100\t63 0.3611771762371063 \t 100\t64 0.36484023928642273 \t 100\t65 0.3687971532344818 \t 100\t66 0.3608786463737488 \t 100\t67 0.35569772124290466 \t 100\t68 0.3604181110858917 \t 100\t69 0.36261385679244995 \t 100\t70 0.36830851435661316 \t 100\t71 0.3660088777542114 \t 100\t72 0.3636425733566284 \t 100\t73 0.3612821102142334 \t 100\t74 0.36187684535980225 \t 100\t75 0.36253222823143005 \t 100\t76 0.36121100187301636 \t 100\t77 0.3623436391353607 \t 100\t78 0.3580155372619629 \t 100\t79 0.35861554741859436 \t 100\t80 0.3592739701271057 \t 100\t81 0.3653985857963562 \t 100\t82 0.3613329827785492 \t 100\t83 0.3593426048755646 \t 100\t84 0.3641994893550873 \t 100\t85 0.3643311858177185 \t 100\t86 0.3621704578399658 \t 100\t87 0.3676147758960724 \t 100\t88 0.35715922713279724 \t 100\t89 0.3644525408744812 \t 100\t90 0.36072787642478943 \t 100\t91 0.36034703254699707 \t 100\t92 0.35830315947532654 \t 100\t93 0.35862281918525696 \t 100\t94 0.3575303256511688 \t 100\t95 0.35860905051231384 \t 100\t96 0.3620847761631012 \t 100\t97 0.36166226863861084 \t 100\t98 0.3720736801624298 \t 100\t99 0.363272100687027 \t 100\t\n",
      "===================================================\n",
      "1000000\n",
      "0.4335367039648644 \t 100\n",
      "0 0.32004302740097046 \t 100\t1 0.31597769260406494 \t 100\t2 0.317335307598114 \t 100\t3 0.31744420528411865 \t 100\t4 0.32058095932006836 \t 100\t5 0.3210573196411133 \t 100\t6 0.3171750009059906 \t 100\t7 0.32018938660621643 \t 100\t8 0.3160645663738251 \t 100\t"
     ]
    }
   ],
   "source": [
    "for N in Ns:\n",
    "    print('===================================================\\n{}'.format(N))\n",
    "    # Take the first N samples.\n",
    "    data, m, s = split_data(X[:N], y[:N])\n",
    "    \n",
    "    # Train BDT model (only need to train 1)\n",
    "    bdt_model = XGBClassifier(early_stopping_rounds = 10)\n",
    "    X_trn, X_vld, y_trn, y_vld = data\n",
    "    bdt_model.fit(X_trn, y_trn, eval_set = [(X_vld, y_vld)], verbose = 0)\n",
    "    trace = bdt_model.evals_result()['validation_0']\n",
    "    print(trace['logloss'][-1], '\\t', len(trace['logloss']), end = '\\n')\n",
    "    bdt_model.save_model(bdt_filestr.format(N))\n",
    "\n",
    "    for i in range(reps):\n",
    "        print(i, end = ' ')\n",
    "        # Train BCE model\n",
    "        bce_model, trace = train(data, **bce_params)\n",
    "        bce_model.save_weights(bce_filestr.format(N, i))\n",
    "        \n",
    "        # Train GBC model\n",
    "        gbc_model = GradientBoostingClassifier(validation_fraction = 0.25,\n",
    "                                               n_iter_no_change = 10)\n",
    "        gbc_model.fit(X[:N], y[:N])\n",
    "        dump(gbc_model, gbc_filestr.format(N, i))\n",
    "        print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multifold",
   "language": "python",
   "name": "multifold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
